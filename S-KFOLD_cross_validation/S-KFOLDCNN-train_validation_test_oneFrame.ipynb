{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "i 1\n",
      "(28, 28)\n",
      "i 2\n",
      "(28, 28)\n",
      "i 3\n",
      "(28, 28)\n",
      "i 4\n",
      "(28, 28)\n",
      "i 5\n",
      "(28, 28)\n",
      "i 6\n",
      "(28, 28)\n",
      "i 7\n",
      "(28, 28)\n",
      "i 8\n",
      "(28, 28)\n",
      "i 9\n",
      "(28, 28)\n",
      "i 10\n",
      "(28, 28)\n",
      "i 11\n",
      "(28, 28)\n",
      "i 12\n",
      "(28, 28)\n",
      "i 13\n",
      "(28, 28)\n",
      "i 14\n",
      "(28, 28)\n",
      "i 15\n",
      "(28, 28)\n",
      "i 16\n",
      "(28, 28)\n",
      "i 17\n",
      "(28, 28)\n",
      "i 18\n",
      "(28, 28)\n",
      "i 19\n",
      "(28, 28)\n",
      "i 20\n",
      "(28, 28)\n",
      "i 21\n",
      "(28, 28)\n",
      "i 22\n",
      "(28, 28)\n",
      "i 23\n",
      "(28, 28)\n",
      "i 24\n",
      "(28, 28)\n",
      "i 25\n",
      "(28, 28)\n",
      "i 26\n",
      "(28, 28)\n",
      "i 27\n",
      "(28, 28)\n",
      "i 28\n",
      "(28, 28)\n",
      "i 29\n",
      "(28, 28)\n",
      "i 30\n",
      "(28, 28)\n",
      "i 31\n",
      "(28, 28)\n",
      "i 32\n",
      "(28, 28)\n",
      "i 33\n",
      "(28, 28)\n",
      "i 34\n",
      "(28, 28)\n",
      "i 35\n",
      "(28, 28)\n",
      "i 36\n",
      "(28, 28)\n",
      "i 37\n",
      "(28, 28)\n",
      "i 38\n",
      "(28, 28)\n",
      "i 39\n",
      "(28, 28)\n",
      "i 40\n",
      "(28, 28)\n",
      "i 41\n",
      "(28, 28)\n",
      "i 42\n",
      "(28, 28)\n",
      "i 43\n",
      "(28, 28)\n",
      "i 44\n",
      "(28, 28)\n",
      "i 45\n",
      "(28, 28)\n",
      "i 46\n",
      "(28, 28)\n",
      "i 47\n",
      "(28, 28)\n",
      "i 48\n",
      "(28, 28)\n",
      "i 49\n",
      "(28, 28)\n",
      "i 50\n",
      "(28, 28)\n",
      "i 51\n",
      "(28, 28)\n",
      "i 52\n",
      "(28, 28)\n",
      "i 53\n",
      "(28, 28)\n",
      "i 54\n",
      "(28, 28)\n",
      "i 55\n",
      "(28, 28)\n",
      "i 56\n",
      "(28, 28)\n",
      "i 57\n",
      "(28, 28)\n",
      "i 58\n",
      "(28, 28)\n",
      "i 59\n",
      "(28, 28)\n",
      "i 60\n",
      "(28, 28)\n",
      "i 61\n",
      "(28, 28)\n",
      "i 62\n",
      "(28, 28)\n",
      "i 63\n",
      "(28, 28)\n",
      "i 64\n",
      "(28, 28)\n",
      "i 65\n",
      "(28, 28)\n",
      "i 66\n",
      "(28, 28)\n",
      "i 67\n",
      "(28, 28)\n",
      "i 68\n",
      "(28, 28)\n",
      "i 69\n",
      "(28, 28)\n",
      "i 70\n",
      "(28, 28)\n",
      "i 71\n",
      "(28, 28)\n",
      "i 72\n",
      "(28, 28)\n",
      "i 73\n",
      "(28, 28)\n",
      "i 74\n",
      "(28, 28)\n",
      "i 75\n",
      "(28, 28)\n",
      "i 76\n",
      "(28, 28)\n",
      "i 77\n",
      "(28, 28)\n",
      "i 78\n",
      "(28, 28)\n",
      "i 79\n",
      "(28, 28)\n",
      "i 80\n",
      "(28, 28)\n",
      "i 81\n",
      "(28, 28)\n",
      "i 82\n",
      "(28, 28)\n",
      "i 83\n",
      "(28, 28)\n",
      "i 84\n",
      "(28, 28)\n",
      "i 85\n",
      "(28, 28)\n",
      "i 86\n",
      "(28, 28)\n",
      "i 87\n",
      "(28, 28)\n",
      "i 88\n",
      "(28, 28)\n",
      "i 89\n",
      "(28, 28)\n",
      "i 90\n",
      "(28, 28)\n",
      "i 91\n",
      "(28, 28)\n",
      "i 92\n",
      "(28, 28)\n",
      "i 93\n",
      "(28, 28)\n",
      "i 94\n",
      "(28, 28)\n",
      "i 95\n",
      "(28, 28)\n",
      "i 96\n",
      "(28, 28)\n",
      "i 97\n",
      "(28, 28)\n",
      "i 98\n",
      "(28, 28)\n",
      "i 99\n",
      "(28, 28)\n",
      "i 100\n",
      "(28, 28)\n",
      "i 101\n",
      "(28, 28)\n",
      "i 102\n",
      "(28, 28)\n",
      "i 103\n",
      "(28, 28)\n",
      "i 104\n",
      "(28, 28)\n",
      "i 105\n",
      "(28, 28)\n",
      "i 106\n",
      "(28, 28)\n",
      "i 107\n",
      "(28, 28)\n",
      "i 108\n",
      "(28, 28)\n",
      "i 109\n",
      "(28, 28)\n",
      "i 110\n",
      "(28, 28)\n",
      "i 111\n",
      "(28, 28)\n",
      "i 112\n",
      "(28, 28)\n",
      "i 113\n",
      "(28, 28)\n",
      "i 114\n",
      "(28, 28)\n",
      "i 115\n",
      "(28, 28)\n",
      "i 116\n",
      "(28, 28)\n",
      "i 117\n",
      "(28, 28)\n",
      "i 118\n",
      "(28, 28)\n",
      "i 119\n",
      "(28, 28)\n",
      "i 120\n",
      "(28, 28)\n",
      "i 121\n",
      "(28, 28)\n",
      "i 122\n",
      "(28, 28)\n",
      "i 123\n",
      "(28, 28)\n",
      "i 124\n",
      "(28, 28)\n",
      "i 125\n",
      "(28, 28)\n",
      "i 126\n",
      "(28, 28)\n",
      "i 127\n",
      "(28, 28)\n",
      "i 128\n",
      "(28, 28)\n",
      "i 129\n",
      "(28, 28)\n",
      "i 130\n",
      "(28, 28)\n",
      "i 131\n",
      "(28, 28)\n",
      "i 132\n",
      "(28, 28)\n",
      "i 133\n",
      "(28, 28)\n",
      "i 134\n",
      "(28, 28)\n",
      "i 135\n",
      "(28, 28)\n",
      "i 136\n",
      "(28, 28)\n",
      "i 137\n",
      "(28, 28)\n",
      "i 138\n",
      "(28, 28)\n",
      "i 139\n",
      "(28, 28)\n",
      "i 140\n",
      "(28, 28)\n",
      "i 141\n",
      "(28, 28)\n",
      "i 142\n",
      "(28, 28)\n",
      "i 143\n",
      "(28, 28)\n",
      "i 144\n",
      "(28, 28)\n",
      "i 145\n",
      "(28, 28)\n",
      "i 146\n",
      "(28, 28)\n",
      "i 147\n",
      "(28, 28)\n",
      "i 148\n",
      "(28, 28)\n",
      "i 149\n",
      "(28, 28)\n",
      "i 150\n",
      "(28, 28)\n",
      "i 151\n",
      "(28, 28)\n",
      "i 152\n",
      "(28, 28)\n",
      "i 153\n",
      "(28, 28)\n",
      "i 154\n",
      "(28, 28)\n",
      "i 155\n",
      "(28, 28)\n",
      "i 156\n",
      "(28, 28)\n",
      "i 157\n",
      "(28, 28)\n",
      "i 158\n",
      "(28, 28)\n",
      "i 159\n",
      "(28, 28)\n",
      "i 160\n",
      "(28, 28)\n",
      "i 161\n",
      "(28, 28)\n",
      "i 162\n",
      "(28, 28)\n",
      "i 163\n",
      "(28, 28)\n",
      "i 164\n",
      "(28, 28)\n",
      "i 165\n",
      "(28, 28)\n",
      "i 166\n",
      "(28, 28)\n",
      "i 167\n",
      "(28, 28)\n",
      "i 168\n",
      "(28, 28)\n",
      "i 169\n",
      "(28, 28)\n",
      "i 170\n",
      "(28, 28)\n",
      "i 171\n",
      "(28, 28)\n",
      "i 172\n",
      "(28, 28)\n",
      "i 173\n",
      "(28, 28)\n",
      "i 174\n",
      "(28, 28)\n",
      "i 175\n",
      "(28, 28)\n",
      "i 176\n",
      "(28, 28)\n",
      "i 177\n",
      "(28, 28)\n",
      "i 178\n",
      "(28, 28)\n",
      "i 179\n",
      "(28, 28)\n",
      "i 180\n",
      "(28, 28)\n",
      "i 181\n",
      "(28, 28)\n",
      "i 182\n",
      "(28, 28)\n",
      "i 183\n",
      "(28, 28)\n",
      "i 184\n",
      "(28, 28)\n",
      "i 185\n",
      "(28, 28)\n",
      "i 186\n",
      "(28, 28)\n",
      "i 187\n",
      "(28, 28)\n",
      "i 188\n",
      "(28, 28)\n",
      "i 189\n",
      "(28, 28)\n",
      "i 190\n",
      "(28, 28)\n",
      "i 191\n",
      "(28, 28)\n",
      "i 192\n",
      "(28, 28)\n",
      "i 193\n",
      "(28, 28)\n",
      "i 194\n",
      "(28, 28)\n",
      "i 195\n",
      "(28, 28)\n",
      "i 196\n",
      "(28, 28)\n",
      "i 197\n",
      "(28, 28)\n",
      "i 198\n",
      "(28, 28)\n",
      "i 199\n",
      "(28, 28)\n",
      "i 200\n",
      "(28, 28)\n",
      "i 201\n",
      "(28, 28)\n",
      "i 202\n",
      "(28, 28)\n",
      "i 203\n",
      "(28, 28)\n",
      "i 204\n",
      "(28, 28)\n",
      "i 205\n",
      "(28, 28)\n",
      "i 206\n",
      "(28, 28)\n",
      "i 207\n",
      "(28, 28)\n",
      "i 208\n",
      "(28, 28)\n",
      "i 209\n",
      "(28, 28)\n",
      "i 210\n",
      "(28, 28)\n",
      "i 211\n",
      "(28, 28)\n",
      "i 212\n",
      "(28, 28)\n",
      "i 213\n",
      "(28, 28)\n",
      "i 214\n",
      "(28, 28)\n",
      "i 215\n",
      "(28, 28)\n",
      "i 216\n",
      "(28, 28)\n",
      "i 217\n",
      "(28, 28)\n",
      "i 218\n",
      "(28, 28)\n",
      "i 219\n",
      "(28, 28)\n",
      "i 220\n",
      "(28, 28)\n",
      "i 221\n",
      "(28, 28)\n",
      "i 222\n",
      "(28, 28)\n",
      "i 223\n",
      "(28, 28)\n",
      "i 224\n",
      "(28, 28)\n",
      "i 225\n",
      "(28, 28)\n",
      "i 226\n",
      "(28, 28)\n",
      "i 227\n",
      "(28, 28)\n",
      "i 228\n",
      "(28, 28)\n",
      "i 229\n",
      "(28, 28)\n",
      "i 230\n",
      "(28, 28)\n",
      "i 231\n",
      "(28, 28)\n",
      "i 232\n",
      "(28, 28)\n",
      "i 233\n",
      "(28, 28)\n",
      "i 234\n",
      "(28, 28)\n",
      "i 235\n",
      "(28, 28)\n",
      "i 236\n",
      "(28, 28)\n",
      "i 237\n",
      "(28, 28)\n",
      "i 238\n",
      "(28, 28)\n",
      "i 239\n",
      "(28, 28)\n",
      "i 240\n",
      "(28, 28)\n",
      "i 241\n",
      "(28, 28)\n",
      "i 242\n",
      "(28, 28)\n",
      "i 243\n",
      "(28, 28)\n",
      "i 244\n",
      "(28, 28)\n",
      "i 245\n",
      "(28, 28)\n",
      "i 246\n",
      "(28, 28)\n",
      "i 247\n",
      "(28, 28)\n",
      "i 248\n",
      "(28, 28)\n",
      "i 249\n",
      "(28, 28)\n",
      "i 250\n",
      "(28, 28)\n",
      "i 251\n",
      "(28, 28)\n",
      "i 252\n",
      "(28, 28)\n",
      "i 253\n",
      "(28, 28)\n",
      "i 254\n",
      "(28, 28)\n",
      "i 255\n",
      "(28, 28)\n",
      "i 256\n",
      "(28, 28)\n",
      "i 257\n",
      "(28, 28)\n",
      "i 258\n",
      "(28, 28)\n",
      "i 259\n",
      "(28, 28)\n",
      "i 260\n",
      "(28, 28)\n",
      "i 261\n",
      "(28, 28)\n",
      "i 262\n",
      "(28, 28)\n",
      "i 263\n",
      "(28, 28)\n",
      "i 264\n",
      "(28, 28)\n",
      "i 265\n",
      "(28, 28)\n",
      "i 266\n",
      "(28, 28)\n",
      "i 267\n",
      "(28, 28)\n",
      "i 268\n",
      "(28, 28)\n",
      "i 269\n",
      "(28, 28)\n",
      "i 270\n",
      "(28, 28)\n",
      "i 271\n",
      "(28, 28)\n",
      "i 272\n",
      "(28, 28)\n",
      "i 273\n",
      "(28, 28)\n",
      "i 274\n",
      "(28, 28)\n",
      "i 275\n",
      "(28, 28)\n",
      "i 276\n",
      "(28, 28)\n",
      "i 277\n",
      "(28, 28)\n",
      "i 278\n",
      "(28, 28)\n",
      "i 279\n",
      "(28, 28)\n",
      "i 280\n",
      "(28, 28)\n",
      "i 281\n",
      "(28, 28)\n",
      "i 282\n",
      "(28, 28)\n",
      "i 283\n",
      "(28, 28)\n",
      "i 284\n",
      "(28, 28)\n",
      "i 285\n",
      "(28, 28)\n",
      "i 286\n",
      "(28, 28)\n",
      "i 287\n",
      "(28, 28)\n",
      "i 288\n",
      "(28, 28)\n",
      "i 289\n",
      "(28, 28)\n",
      "i 290\n",
      "(28, 28)\n",
      "i 291\n",
      "(28, 28)\n",
      "i 292\n",
      "(28, 28)\n",
      "i 293\n",
      "(28, 28)\n",
      "i 294\n",
      "(28, 28)\n",
      "i 295\n",
      "(28, 28)\n",
      "i 296\n",
      "(28, 28)\n",
      "i 297\n",
      "(28, 28)\n",
      "i 298\n",
      "(28, 28)\n",
      "i 299\n",
      "(28, 28)\n",
      "i 300\n",
      "(28, 28)\n",
      "i 301\n",
      "(28, 28)\n",
      "i 302\n",
      "(28, 28)\n",
      "i 303\n",
      "(28, 28)\n",
      "i 304\n",
      "(28, 28)\n",
      "i 305\n",
      "(28, 28)\n",
      "i 306\n",
      "(28, 28)\n",
      "i 307\n",
      "(28, 28)\n",
      "i 308\n",
      "(28, 28)\n",
      "i 309\n",
      "(28, 28)\n",
      "i 310\n",
      "(28, 28)\n",
      "i 311\n",
      "(28, 28)\n",
      "i 312\n",
      "(28, 28)\n",
      "i 313\n",
      "(28, 28)\n",
      "i 314\n",
      "(28, 28)\n",
      "i 315\n",
      "(28, 28)\n",
      "i 316\n",
      "(28, 28)\n",
      "i 317\n",
      "(28, 28)\n",
      "i 318\n",
      "(28, 28)\n",
      "i 319\n",
      "(28, 28)\n",
      "i 320\n",
      "(28, 28)\n",
      "i 321\n",
      "(28, 28)\n",
      "i 322\n",
      "(28, 28)\n",
      "i 323\n",
      "(28, 28)\n",
      "i 324\n",
      "(28, 28)\n",
      "i 325\n",
      "(28, 28)\n",
      "i 326\n",
      "(28, 28)\n",
      "i 327\n",
      "(28, 28)\n",
      "i 328\n",
      "(28, 28)\n",
      "i 329\n",
      "(28, 28)\n",
      "i 330\n",
      "(28, 28)\n",
      "i 331\n",
      "(28, 28)\n",
      "i 332\n",
      "(28, 28)\n",
      "i 333\n",
      "(28, 28)\n",
      "i 334\n",
      "(28, 28)\n",
      "i 335\n",
      "(28, 28)\n",
      "i 336\n",
      "(28, 28)\n",
      "i 337\n",
      "(28, 28)\n",
      "i 338\n",
      "(28, 28)\n",
      "i 339\n",
      "(28, 28)\n",
      "i 340\n",
      "(28, 28)\n",
      "i 341\n",
      "(28, 28)\n",
      "i 342\n",
      "(28, 28)\n",
      "i 343\n",
      "(28, 28)\n",
      "i 344\n",
      "(28, 28)\n",
      "i 345\n",
      "(28, 28)\n",
      "i 346\n",
      "(28, 28)\n",
      "i 347\n",
      "(28, 28)\n",
      "i 348\n",
      "(28, 28)\n",
      "i 349\n",
      "(28, 28)\n",
      "i 350\n",
      "(28, 28)\n",
      "i 351\n",
      "(28, 28)\n",
      "i 352\n",
      "(28, 28)\n",
      "i 353\n",
      "(28, 28)\n",
      "i 354\n",
      "(28, 28)\n",
      "i 355\n",
      "(28, 28)\n",
      "i 356\n",
      "(28, 28)\n",
      "i 357\n",
      "(28, 28)\n",
      "i 358\n",
      "(28, 28)\n",
      "i 359\n",
      "(28, 28)\n",
      "i 360\n",
      "(28, 28)\n",
      "i 361\n",
      "(28, 28)\n",
      "i 362\n",
      "(28, 28)\n",
      "i 363\n",
      "(28, 28)\n",
      "i 364\n",
      "(28, 28)\n",
      "i 365\n",
      "(28, 28)\n",
      "i 366\n",
      "(28, 28)\n",
      "i 367\n",
      "(28, 28)\n",
      "i 368\n",
      "(28, 28)\n",
      "i 369\n",
      "(28, 28)\n",
      "i 370\n",
      "(28, 28)\n",
      "i 371\n",
      "(28, 28)\n",
      "i 372\n",
      "(28, 28)\n",
      "i 373\n",
      "(28, 28)\n",
      "i 374\n",
      "(28, 28)\n",
      "i 375\n",
      "(28, 28)\n",
      "i 376\n",
      "(28, 28)\n",
      "i 377\n",
      "(28, 28)\n",
      "i 378\n",
      "(28, 28)\n",
      "i 379\n",
      "(28, 28)\n",
      "i 380\n",
      "(28, 28)\n",
      "i 381\n",
      "(28, 28)\n",
      "i 382\n",
      "(28, 28)\n",
      "i 383\n",
      "(28, 28)\n",
      "i 384\n",
      "(28, 28)\n",
      "i 385\n",
      "(28, 28)\n",
      "i 386\n",
      "(28, 28)\n",
      "i 387\n",
      "(28, 28)\n",
      "i 388\n",
      "(28, 28)\n",
      "i 389\n",
      "(28, 28)\n",
      "i 390\n",
      "(28, 28)\n",
      "i 391\n",
      "(28, 28)\n",
      "i 392\n",
      "(28, 28)\n",
      "i 393\n",
      "(28, 28)\n",
      "i 394\n",
      "(28, 28)\n",
      "i 395\n",
      "(28, 28)\n",
      "i 396\n",
      "(28, 28)\n",
      "i 397\n",
      "(28, 28)\n",
      "i 398\n",
      "(28, 28)\n",
      "i 399\n",
      "(28, 28)\n",
      "i 400\n",
      "(28, 28)\n",
      "i 401\n",
      "(28, 28)\n",
      "i 402\n",
      "(28, 28)\n",
      "i 403\n",
      "(28, 28)\n",
      "i 404\n",
      "(28, 28)\n",
      "i 405\n",
      "(28, 28)\n",
      "i 406\n",
      "(28, 28)\n",
      "i 407\n",
      "(28, 28)\n",
      "i 408\n",
      "(28, 28)\n",
      "i 409\n",
      "(28, 28)\n",
      "i 410\n",
      "(28, 28)\n",
      "i 411\n",
      "(28, 28)\n",
      "i 412\n",
      "(28, 28)\n",
      "i 413\n",
      "(28, 28)\n",
      "i 414\n",
      "(28, 28)\n",
      "i 415\n",
      "(28, 28)\n",
      "i 416\n",
      "(28, 28)\n",
      "i 417\n",
      "(28, 28)\n",
      "i 418\n",
      "(28, 28)\n",
      "i 419\n",
      "(28, 28)\n",
      "i 420\n",
      "(28, 28)\n",
      "i 421\n",
      "(28, 28)\n",
      "i 422\n",
      "(28, 28)\n",
      "i 423\n",
      "(28, 28)\n",
      "i 424\n",
      "(28, 28)\n",
      "i 425\n",
      "(28, 28)\n",
      "i 426\n",
      "(28, 28)\n",
      "i 427\n",
      "(28, 28)\n",
      "i 428\n",
      "(28, 28)\n",
      "i 429\n",
      "(28, 28)\n",
      "i 430\n",
      "(28, 28)\n",
      "i 431\n",
      "(28, 28)\n",
      "i 432\n",
      "(28, 28)\n",
      "i 433\n",
      "(28, 28)\n",
      "i 434\n",
      "(28, 28)\n",
      "i 435\n",
      "(28, 28)\n",
      "i 436\n",
      "(28, 28)\n",
      "i 437\n",
      "(28, 28)\n",
      "i 438\n",
      "(28, 28)\n",
      "i 439\n",
      "(28, 28)\n",
      "i 440\n",
      "(28, 28)\n",
      "i 441\n",
      "(28, 28)\n",
      "i 442\n",
      "(28, 28)\n",
      "i 443\n",
      "(28, 28)\n",
      "i 444\n",
      "(28, 28)\n",
      "i 445\n",
      "(28, 28)\n",
      "i 446\n",
      "(28, 28)\n",
      "i 447\n",
      "(28, 28)\n",
      "i 448\n",
      "(28, 28)\n",
      "i 449\n",
      "(28, 28)\n",
      "i 450\n",
      "(28, 28)\n",
      "i 451\n",
      "(28, 28)\n",
      "i 452\n",
      "(28, 28)\n",
      "i 453\n",
      "(28, 28)\n",
      "i 454\n",
      "(28, 28)\n",
      "i 455\n",
      "(28, 28)\n",
      "i 456\n",
      "(28, 28)\n",
      "i 457\n",
      "(28, 28)\n",
      "i 458\n",
      "(28, 28)\n",
      "i 459\n",
      "(28, 28)\n",
      "i 460\n",
      "(28, 28)\n",
      "i 461\n",
      "(28, 28)\n",
      "i 462\n",
      "(28, 28)\n",
      "i 463\n",
      "(28, 28)\n",
      "i 464\n",
      "(28, 28)\n",
      "i 465\n",
      "(28, 28)\n",
      "i 466\n",
      "(28, 28)\n",
      "i 467\n",
      "(28, 28)\n",
      "i 468\n",
      "(28, 28)\n",
      "i 469\n",
      "(28, 28)\n",
      "i 470\n",
      "(28, 28)\n",
      "i 471\n",
      "(28, 28)\n",
      "i 472\n",
      "(28, 28)\n",
      "i 473\n",
      "(28, 28)\n",
      "i 474\n",
      "(28, 28)\n",
      "i 475\n",
      "(28, 28)\n",
      "i 476\n",
      "(28, 28)\n",
      "i 477\n",
      "(28, 28)\n",
      "i 478\n",
      "(28, 28)\n",
      "i 479\n",
      "(28, 28)\n",
      "i 480\n",
      "(28, 28)\n",
      "i 481\n",
      "(28, 28)\n",
      "i 482\n",
      "(28, 28)\n",
      "i 483\n",
      "(28, 28)\n",
      "i 484\n",
      "(28, 28)\n",
      "i 485\n",
      "(28, 28)\n",
      "i 486\n",
      "(28, 28)\n",
      "i 487\n",
      "(28, 28)\n",
      "i 488\n",
      "(28, 28)\n",
      "i 489\n",
      "(28, 28)\n",
      "i 490\n",
      "(28, 28)\n",
      "i 491\n",
      "(28, 28)\n",
      "i 492\n",
      "(28, 28)\n",
      "i 493\n",
      "(28, 28)\n",
      "i 494\n",
      "(28, 28)\n",
      "i 495\n",
      "(28, 28)\n",
      "i 496\n",
      "(28, 28)\n",
      "i 497\n",
      "(28, 28)\n",
      "i 498\n",
      "(28, 28)\n",
      "i 499\n",
      "(28, 28)\n",
      "i 500\n",
      "(28, 28)\n",
      "i 501\n",
      "(28, 28)\n",
      "i 502\n",
      "(28, 28)\n",
      "i 503\n",
      "(28, 28)\n",
      "i 504\n",
      "(28, 28)\n",
      "i 505\n",
      "(28, 28)\n",
      "i 506\n",
      "(28, 28)\n",
      "i 507\n",
      "(28, 28)\n",
      "i 508\n",
      "(28, 28)\n",
      "i 509\n",
      "(28, 28)\n",
      "i 510\n",
      "(28, 28)\n",
      "i 511\n",
      "(28, 28)\n",
      "i 512\n",
      "(28, 28)\n",
      "i 513\n",
      "(28, 28)\n",
      "i 514\n",
      "(28, 28)\n",
      "i 515\n",
      "(28, 28)\n",
      "i 516\n",
      "(28, 28)\n",
      "i 517\n",
      "(28, 28)\n",
      "i 518\n",
      "(28, 28)\n",
      "i 519\n",
      "(28, 28)\n",
      "i 520\n",
      "(28, 28)\n",
      "i 521\n",
      "(28, 28)\n",
      "i 522\n",
      "(28, 28)\n",
      "i 523\n",
      "(28, 28)\n",
      "i 524\n",
      "(28, 28)\n",
      "i 525\n",
      "(28, 28)\n",
      "i 526\n",
      "(28, 28)\n",
      "i 527\n",
      "(28, 28)\n",
      "i 528\n",
      "(28, 28)\n",
      "i 529\n",
      "(28, 28)\n",
      "i 530\n",
      "(28, 28)\n",
      "i 531\n",
      "(28, 28)\n",
      "i 532\n",
      "(28, 28)\n",
      "i 533\n",
      "(28, 28)\n",
      "i 534\n",
      "(28, 28)\n",
      "i 535\n",
      "(28, 28)\n",
      "i 536\n",
      "(28, 28)\n",
      "i 537\n",
      "(28, 28)\n",
      "i 538\n",
      "(28, 28)\n",
      "i 539\n",
      "(28, 28)\n",
      "i 540\n",
      "(28, 28)\n",
      "i 541\n",
      "(28, 28)\n",
      "i 542\n",
      "(28, 28)\n",
      "i 543\n",
      "(28, 28)\n",
      "i 544\n",
      "(28, 28)\n",
      "i 545\n",
      "(28, 28)\n",
      "i 546\n",
      "(28, 28)\n",
      "i 547\n",
      "(28, 28)\n",
      "i 548\n",
      "(28, 28)\n",
      "i 549\n",
      "(28, 28)\n",
      "i 550\n",
      "(28, 28)\n",
      "i 551\n",
      "(28, 28)\n",
      "i 552\n",
      "(28, 28)\n",
      "i 553\n",
      "(28, 28)\n",
      "i 554\n",
      "(28, 28)\n",
      "i 555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "i 556\n",
      "(28, 28)\n",
      "i 557\n",
      "(28, 28)\n",
      "i 558\n",
      "(28, 28)\n",
      "i 559\n",
      "(28, 28)\n",
      "i 560\n",
      "(28, 28)\n",
      "i 561\n",
      "(28, 28)\n",
      "i 562\n",
      "(28, 28)\n",
      "i 563\n",
      "(28, 28)\n",
      "i 564\n",
      "(28, 28)\n",
      "i 565\n",
      "(28, 28)\n",
      "i 566\n",
      "(28, 28)\n",
      "i 567\n",
      "(28, 28)\n",
      "i 568\n",
      "(28, 28)\n",
      "i 569\n",
      "(28, 28)\n",
      "i 570\n",
      "(28, 28)\n",
      "i 571\n",
      "(28, 28)\n",
      "i 572\n",
      "(28, 28)\n",
      "i 573\n",
      "(28, 28)\n",
      "i 574\n",
      "(28, 28)\n",
      "i 575\n",
      "(28, 28)\n",
      "i 576\n",
      "(28, 28)\n",
      "i 577\n",
      "(28, 28)\n",
      "i 578\n",
      "(28, 28)\n",
      "i 579\n",
      "(28, 28)\n",
      "i 580\n",
      "(28, 28)\n",
      "i 581\n",
      "(28, 28)\n",
      "i 582\n",
      "(28, 28)\n",
      "i 583\n",
      "(28, 28)\n",
      "i 584\n",
      "(28, 28)\n",
      "i 585\n",
      "(28, 28)\n",
      "i 586\n",
      "(28, 28)\n",
      "i 587\n",
      "(28, 28)\n",
      "i 588\n",
      "(28, 28)\n",
      "i 589\n",
      "(28, 28)\n",
      "i 590\n",
      "(28, 28)\n",
      "i 591\n",
      "(28, 28)\n",
      "i 592\n",
      "(28, 28)\n",
      "i 593\n",
      "(28, 28)\n",
      "i 594\n",
      "(28, 28)\n",
      "i 595\n",
      "(28, 28)\n",
      "i 596\n",
      "(28, 28)\n",
      "i 597\n",
      "(28, 28)\n",
      "i 598\n",
      "(28, 28)\n",
      "i 599\n",
      "(28, 28)\n",
      "i 600\n",
      "(28, 28)\n",
      "i 601\n",
      "(28, 28)\n",
      "i 602\n",
      "(28, 28)\n",
      "i 603\n",
      "(28, 28)\n",
      "i 604\n",
      "(28, 28)\n",
      "i 605\n",
      "(28, 28)\n",
      "i 606\n",
      "(28, 28)\n",
      "i 607\n",
      "(28, 28)\n",
      "i 608\n",
      "(28, 28)\n",
      "i 609\n",
      "(28, 28)\n",
      "i 610\n",
      "(28, 28)\n",
      "i 611\n",
      "(28, 28)\n",
      "i 612\n",
      "(28, 28)\n",
      "i 613\n",
      "(28, 28)\n",
      "i 614\n",
      "(28, 28)\n",
      "i 615\n",
      "(28, 28)\n",
      "i 616\n",
      "(28, 28)\n",
      "i 617\n",
      "(28, 28)\n",
      "i 618\n",
      "(28, 28)\n",
      "i 619\n",
      "(28, 28)\n",
      "i 620\n",
      "(28, 28)\n",
      "i 621\n",
      "(28, 28)\n",
      "i 622\n",
      "(28, 28)\n",
      "i 623\n",
      "(28, 28)\n",
      "i 624\n",
      "(28, 28)\n",
      "i 625\n",
      "(28, 28)\n",
      "i 626\n",
      "(28, 28)\n",
      "i 627\n",
      "(28, 28)\n",
      "i 628\n",
      "(28, 28)\n",
      "i 629\n",
      "(28, 28)\n",
      "i 630\n",
      "(28, 28)\n",
      "i 631\n",
      "(28, 28)\n",
      "i 632\n",
      "(28, 28)\n",
      "i 633\n",
      "(28, 28)\n",
      "i 634\n",
      "(28, 28)\n",
      "i 635\n",
      "(28, 28)\n",
      "i 636\n",
      "(28, 28)\n",
      "i 637\n",
      "(28, 28)\n",
      "i 638\n",
      "(28, 28)\n",
      "i 639\n",
      "(28, 28)\n",
      "i 640\n",
      "(28, 28)\n",
      "i 641\n",
      "(28, 28)\n",
      "i 642\n",
      "(28, 28)\n",
      "i 643\n",
      "(28, 28)\n",
      "i 644\n",
      "(28, 28)\n",
      "i 645\n",
      "(28, 28)\n",
      "i 646\n",
      "(28, 28)\n",
      "i 647\n",
      "(28, 28)\n",
      "i 648\n",
      "(28, 28)\n",
      "i 649\n",
      "(28, 28)\n",
      "i 650\n",
      "(28, 28)\n",
      "i 651\n",
      "(28, 28)\n",
      "i 652\n",
      "(28, 28)\n",
      "i 653\n",
      "(28, 28)\n",
      "i 654\n",
      "(28, 28)\n",
      "i 655\n",
      "(28, 28)\n",
      "i 656\n",
      "(28, 28)\n",
      "i 657\n",
      "(28, 28)\n",
      "i 658\n",
      "(28, 28)\n",
      "i 659\n",
      "(28, 28)\n",
      "i 660\n",
      "(28, 28)\n",
      "i 661\n",
      "(28, 28)\n",
      "i 662\n",
      "(28, 28)\n",
      "i 663\n",
      "(28, 28)\n",
      "i 664\n",
      "(28, 28)\n",
      "i 665\n",
      "(28, 28)\n",
      "i 666\n",
      "(28, 28)\n",
      "i 667\n",
      "(28, 28)\n",
      "i 668\n",
      "(28, 28)\n",
      "i 669\n",
      "(28, 28)\n",
      "i 670\n",
      "(28, 28)\n",
      "i 671\n",
      "(28, 28)\n",
      "i 672\n",
      "(28, 28)\n",
      "i 673\n",
      "(28, 28)\n",
      "i 674\n",
      "(28, 28)\n",
      "i 675\n",
      "(28, 28)\n",
      "i 676\n",
      "(28, 28)\n",
      "i 677\n",
      "(28, 28)\n",
      "i 678\n",
      "(28, 28)\n",
      "i 679\n",
      "(28, 28)\n",
      "i 680\n",
      "(28, 28)\n",
      "i 681\n",
      "(28, 28)\n",
      "i 682\n",
      "(28, 28)\n",
      "i 683\n",
      "(28, 28)\n",
      "i 684\n",
      "(28, 28)\n",
      "i 685\n",
      "(28, 28)\n",
      "i 686\n",
      "(28, 28)\n",
      "i 687\n",
      "(28, 28)\n",
      "i 688\n",
      "(28, 28)\n",
      "i 689\n",
      "(28, 28)\n",
      "i 690\n",
      "(28, 28)\n",
      "i 691\n",
      "(28, 28)\n",
      "i 692\n",
      "(28, 28)\n",
      "i 693\n",
      "(28, 28)\n",
      "i 694\n",
      "(28, 28)\n",
      "i 695\n",
      "(28, 28)\n",
      "i 696\n",
      "(28, 28)\n",
      "i 697\n",
      "(28, 28)\n",
      "i 698\n",
      "(28, 28)\n",
      "i 699\n",
      "(28, 28)\n",
      "i 700\n",
      "(28, 28)\n",
      "i 701\n",
      "(28, 28)\n",
      "i 702\n",
      "(28, 28)\n",
      "i 703\n",
      "(28, 28)\n",
      "i 704\n",
      "(28, 28)\n",
      "i 705\n",
      "(28, 28)\n",
      "i 706\n",
      "(28, 28)\n",
      "i 707\n",
      "(28, 28)\n",
      "i 708\n",
      "(28, 28)\n",
      "i 709\n",
      "(28, 28)\n",
      "i 710\n",
      "(28, 28)\n",
      "i 711\n",
      "(28, 28)\n",
      "i 712\n",
      "(28, 28)\n",
      "i 713\n",
      "(28, 28)\n",
      "i 714\n",
      "(28, 28)\n",
      "i 715\n",
      "(28, 28)\n",
      "i 716\n",
      "(28, 28)\n",
      "i 717\n",
      "(28, 28)\n",
      "i 718\n",
      "(28, 28)\n",
      "i 719\n",
      "(28, 28)\n",
      "i 720\n",
      "(28, 28)\n",
      "i 721\n",
      "(28, 28)\n",
      "i 722\n",
      "(28, 28)\n",
      "i 723\n",
      "(28, 28)\n",
      "i 724\n",
      "(28, 28)\n",
      "i 725\n",
      "(28, 28)\n",
      "i 726\n",
      "(28, 28)\n",
      "i 727\n",
      "(28, 28)\n",
      "i 728\n",
      "(28, 28)\n",
      "i 729\n",
      "(28, 28)\n",
      "i 730\n",
      "(28, 28)\n",
      "i 731\n",
      "(28, 28)\n",
      "i 732\n",
      "(28, 28)\n",
      "i 733\n",
      "(28, 28)\n",
      "i 734\n",
      "(28, 28)\n",
      "i 735\n",
      "(28, 28)\n",
      "i 736\n",
      "(28, 28)\n",
      "i 737\n",
      "(28, 28)\n",
      "i 738\n",
      "(28, 28)\n",
      "i 739\n",
      "(28, 28)\n",
      "i 740\n",
      "(28, 28)\n",
      "i 741\n",
      "(28, 28)\n",
      "i 742\n",
      "(28, 28)\n",
      "i 743\n",
      "(28, 28)\n",
      "i 744\n",
      "(28, 28)\n",
      "i 745\n",
      "(28, 28)\n",
      "i 746\n",
      "(28, 28)\n",
      "i 747\n",
      "(28, 28)\n",
      "i 748\n",
      "(28, 28)\n",
      "i 749\n",
      "(28, 28)\n",
      "i 750\n",
      "(28, 28)\n",
      "i 751\n",
      "(28, 28)\n",
      "i 752\n",
      "(28, 28)\n",
      "i 753\n",
      "(28, 28)\n",
      "i 754\n",
      "(28, 28)\n",
      "i 755\n",
      "(28, 28)\n",
      "i 756\n",
      "(28, 28)\n",
      "i 757\n",
      "(28, 28)\n",
      "i 758\n",
      "(28, 28)\n",
      "i 759\n",
      "(28, 28)\n",
      "j 1\n",
      "(28, 28)\n",
      "j 2\n",
      "(28, 28)\n",
      "j 3\n",
      "(28, 28)\n",
      "j 4\n",
      "(28, 28)\n",
      "j 5\n",
      "(28, 28)\n",
      "j 6\n",
      "(28, 28)\n",
      "j 7\n",
      "(28, 28)\n",
      "j 8\n",
      "(28, 28)\n",
      "j 9\n",
      "(28, 28)\n",
      "j 10\n",
      "(28, 28)\n",
      "j 11\n",
      "(28, 28)\n",
      "j 12\n",
      "(28, 28)\n",
      "j 13\n",
      "(28, 28)\n",
      "j 14\n",
      "(28, 28)\n",
      "j 15\n",
      "(28, 28)\n",
      "j 16\n",
      "(28, 28)\n",
      "j 17\n",
      "(28, 28)\n",
      "j 18\n",
      "(28, 28)\n",
      "j 19\n",
      "(28, 28)\n",
      "j 20\n",
      "(28, 28)\n",
      "j 21\n",
      "(28, 28)\n",
      "j 22\n",
      "(28, 28)\n",
      "j 23\n",
      "(28, 28)\n",
      "j 24\n",
      "(28, 28)\n",
      "j 25\n",
      "(28, 28)\n",
      "j 26\n",
      "(28, 28)\n",
      "j 27\n",
      "(28, 28)\n",
      "j 28\n",
      "(28, 28)\n",
      "j 29\n",
      "(28, 28)\n",
      "j 30\n",
      "(28, 28)\n",
      "j 31\n",
      "(28, 28)\n",
      "j 32\n",
      "(28, 28)\n",
      "j 33\n",
      "(28, 28)\n",
      "j 34\n",
      "(28, 28)\n",
      "j 35\n",
      "(28, 28)\n",
      "j 36\n",
      "(28, 28)\n",
      "j 37\n",
      "(28, 28)\n",
      "j 38\n",
      "(28, 28)\n",
      "j 39\n",
      "(28, 28)\n",
      "j 40\n",
      "(28, 28)\n",
      "j 41\n",
      "(28, 28)\n",
      "j 42\n",
      "(28, 28)\n",
      "j 43\n",
      "(28, 28)\n",
      "j 44\n",
      "(28, 28)\n",
      "j 45\n",
      "(28, 28)\n",
      "j 46\n",
      "(28, 28)\n",
      "j 47\n",
      "(28, 28)\n",
      "j 48\n",
      "(28, 28)\n",
      "j 49\n",
      "(28, 28)\n",
      "j 50\n",
      "(28, 28)\n",
      "j 51\n",
      "(28, 28)\n",
      "j 52\n",
      "(28, 28)\n",
      "j 53\n",
      "(28, 28)\n",
      "j 54\n",
      "(28, 28)\n",
      "j 55\n",
      "(28, 28)\n",
      "j 56\n",
      "(28, 28)\n",
      "j 57\n",
      "(28, 28)\n",
      "j 58\n",
      "(28, 28)\n",
      "j 59\n",
      "(28, 28)\n",
      "j 60\n",
      "(28, 28)\n",
      "j 61\n",
      "(28, 28)\n",
      "j 62\n",
      "(28, 28)\n",
      "j 63\n",
      "(28, 28)\n",
      "j 64\n",
      "(28, 28)\n",
      "j 65\n",
      "(28, 28)\n",
      "j 66\n",
      "(28, 28)\n",
      "j 67\n",
      "(28, 28)\n",
      "j 68\n",
      "(28, 28)\n",
      "j 69\n",
      "(28, 28)\n",
      "j 70\n",
      "(28, 28)\n",
      "j 71\n",
      "(28, 28)\n",
      "j 72\n",
      "(28, 28)\n",
      "j 73\n",
      "(28, 28)\n",
      "j 74\n",
      "(28, 28)\n",
      "j 75\n",
      "(28, 28)\n",
      "j 76\n",
      "(28, 28)\n",
      "j 77\n",
      "(28, 28)\n",
      "j 78\n",
      "(28, 28)\n",
      "j 79\n",
      "(28, 28)\n",
      "j 80\n",
      "(28, 28)\n",
      "j 81\n",
      "(28, 28)\n",
      "j 82\n",
      "(28, 28)\n",
      "j 83\n",
      "(28, 28)\n",
      "j 84\n",
      "(28, 28)\n",
      "j 85\n",
      "(28, 28)\n",
      "j 86\n",
      "(28, 28)\n",
      "j 87\n",
      "(28, 28)\n",
      "j 88\n",
      "(28, 28)\n",
      "j 89\n",
      "(28, 28)\n",
      "j 90\n",
      "(28, 28)\n",
      "j 91\n",
      "(28, 28)\n",
      "j 92\n",
      "(28, 28)\n",
      "j 93\n",
      "(28, 28)\n",
      "j 94\n",
      "(28, 28)\n",
      "j 95\n",
      "(28, 28)\n",
      "j 96\n",
      "(28, 28)\n",
      "j 97\n",
      "(28, 28)\n",
      "j 98\n",
      "(28, 28)\n",
      "j 99\n",
      "(28, 28)\n",
      "j 100\n",
      "(28, 28)\n",
      "j 101\n",
      "(28, 28)\n",
      "j 102\n",
      "(28, 28)\n",
      "j 103\n",
      "(28, 28)\n",
      "j 104\n",
      "(28, 28)\n",
      "j 105\n",
      "(28, 28)\n",
      "j 106\n",
      "(28, 28)\n",
      "j 107\n",
      "(28, 28)\n",
      "j 108\n",
      "(28, 28)\n",
      "j 109\n",
      "(28, 28)\n",
      "j 110\n",
      "(28, 28)\n",
      "j 111\n",
      "(28, 28)\n",
      "j 112\n",
      "(28, 28)\n",
      "j 113\n",
      "(28, 28)\n",
      "j 114\n",
      "(28, 28)\n",
      "j 115\n",
      "(28, 28)\n",
      "j 116\n",
      "(28, 28)\n",
      "j 117\n",
      "(28, 28)\n",
      "j 118\n",
      "(28, 28)\n",
      "j 119\n",
      "(28, 28)\n",
      "j 120\n",
      "(28, 28)\n",
      "j 121\n",
      "(28, 28)\n",
      "j 122\n",
      "(28, 28)\n",
      "j 123\n",
      "(28, 28)\n",
      "j 124\n",
      "(28, 28)\n",
      "j 125\n",
      "(28, 28)\n",
      "j 126\n",
      "(28, 28)\n",
      "j 127\n",
      "(28, 28)\n",
      "j 128\n",
      "(28, 28)\n",
      "j 129\n",
      "(28, 28)\n",
      "j 130\n",
      "(28, 28)\n",
      "j 131\n",
      "(28, 28)\n",
      "j 132\n",
      "(28, 28)\n",
      "j 133\n",
      "(28, 28)\n",
      "j 134\n",
      "(28, 28)\n",
      "j 135\n",
      "(28, 28)\n",
      "j 136\n",
      "(28, 28)\n",
      "j 137\n",
      "(28, 28)\n",
      "j 138\n",
      "(28, 28)\n",
      "j 139\n",
      "(28, 28)\n",
      "j 140\n",
      "(28, 28)\n",
      "j 141\n",
      "(28, 28)\n",
      "j 142\n",
      "(28, 28)\n",
      "j 143\n",
      "(28, 28)\n",
      "j 144\n",
      "(28, 28)\n",
      "j 145\n",
      "(28, 28)\n",
      "j 146\n",
      "(28, 28)\n",
      "j 147\n",
      "(28, 28)\n",
      "j 148\n",
      "(28, 28)\n",
      "j 149\n",
      "(28, 28)\n",
      "j 150\n",
      "(28, 28)\n",
      "j 151\n",
      "(28, 28)\n",
      "j 152\n",
      "(28, 28)\n",
      "j 153\n",
      "(28, 28)\n",
      "j 154\n",
      "(28, 28)\n",
      "j 155\n",
      "(28, 28)\n",
      "j 156\n",
      "(28, 28)\n",
      "j 157\n",
      "(28, 28)\n",
      "j 158\n",
      "(28, 28)\n",
      "j 159\n",
      "(28, 28)\n",
      "j 160\n",
      "(28, 28)\n",
      "j 161\n",
      "(28, 28)\n",
      "j 162\n",
      "(28, 28)\n",
      "j 163\n",
      "(28, 28)\n",
      "j 164\n",
      "(28, 28)\n",
      "j 165\n",
      "(28, 28)\n",
      "j 166\n",
      "(28, 28)\n",
      "j 167\n",
      "(28, 28)\n",
      "j 168\n",
      "(28, 28)\n",
      "j 169\n",
      "(28, 28)\n",
      "j 170\n",
      "(28, 28)\n",
      "j 171\n",
      "(28, 28)\n",
      "j 172\n",
      "(28, 28)\n",
      "j 173\n",
      "(28, 28)\n",
      "j 174\n",
      "(28, 28)\n",
      "j 175\n",
      "(28, 28)\n",
      "j 176\n",
      "(28, 28)\n",
      "j 177\n",
      "(28, 28)\n",
      "j 178\n",
      "(28, 28)\n",
      "j 179\n",
      "(28, 28)\n",
      "j 180\n",
      "(28, 28)\n",
      "j 181\n",
      "(28, 28)\n",
      "j 182\n",
      "(28, 28)\n",
      "j 183\n",
      "(28, 28)\n",
      "j 184\n",
      "(28, 28)\n",
      "j 185\n",
      "(28, 28)\n",
      "j 186\n",
      "(28, 28)\n",
      "j 187\n",
      "(28, 28)\n",
      "j 188\n",
      "(28, 28)\n",
      "j 189\n",
      "(28, 28)\n",
      "j 190\n",
      "(28, 28)\n",
      "j 191\n",
      "(28, 28)\n",
      "j 192\n",
      "(28, 28)\n",
      "j 193\n",
      "(28, 28)\n",
      "j 194\n",
      "(28, 28)\n",
      "j 195\n",
      "(28, 28)\n",
      "j 196\n",
      "(28, 28)\n",
      "j 197\n",
      "(28, 28)\n",
      "j 198\n",
      "(28, 28)\n",
      "j 199\n",
      "(28, 28)\n",
      "j 200\n",
      "(28, 28)\n",
      "j 201\n",
      "(28, 28)\n",
      "j 202\n",
      "(28, 28)\n",
      "j 203\n",
      "(28, 28)\n",
      "j 204\n",
      "(28, 28)\n",
      "j 205\n",
      "(28, 28)\n",
      "j 206\n",
      "(28, 28)\n",
      "j 207\n",
      "(28, 28)\n",
      "j 208\n",
      "(28, 28)\n",
      "j 209\n",
      "(28, 28)\n",
      "j 210\n",
      "(28, 28)\n",
      "j 211\n",
      "(28, 28)\n",
      "j 212\n",
      "(28, 28)\n",
      "j 213\n",
      "(28, 28)\n",
      "j 214\n",
      "(28, 28)\n",
      "j 215\n",
      "(28, 28)\n",
      "j 216\n",
      "(28, 28)\n",
      "j 217\n",
      "(28, 28)\n",
      "j 218\n",
      "(28, 28)\n",
      "j 219\n",
      "(28, 28)\n",
      "j 220\n",
      "(28, 28)\n",
      "j 221\n",
      "(28, 28)\n",
      "j 222\n",
      "(28, 28)\n",
      "j 223\n",
      "(28, 28)\n",
      "j 224\n",
      "(28, 28)\n",
      "j 225\n",
      "(28, 28)\n",
      "j 226\n",
      "(28, 28)\n",
      "j 227\n",
      "(28, 28)\n",
      "j 228\n",
      "(28, 28)\n",
      "j 229\n",
      "(28, 28)\n",
      "j 230\n",
      "(28, 28)\n",
      "j 231\n",
      "(28, 28)\n",
      "j 232\n",
      "(28, 28)\n",
      "j 233\n",
      "(28, 28)\n",
      "j 234\n",
      "(28, 28)\n",
      "j 235\n",
      "(28, 28)\n",
      "j 236\n",
      "(28, 28)\n",
      "j 237\n",
      "(28, 28)\n",
      "j 238\n",
      "(28, 28)\n",
      "j 239\n",
      "(28, 28)\n",
      "j 240\n",
      "(28, 28)\n",
      "j 241\n",
      "(28, 28)\n",
      "j 242\n",
      "(28, 28)\n",
      "j 243\n",
      "(28, 28)\n",
      "j 244\n",
      "(28, 28)\n",
      "j 245\n",
      "(28, 28)\n",
      "j 246\n",
      "(28, 28)\n",
      "j 247\n",
      "(28, 28)\n",
      "j 248\n",
      "(28, 28)\n",
      "j 249\n",
      "(28, 28)\n",
      "j 250\n",
      "(28, 28)\n",
      "j 251\n",
      "(28, 28)\n",
      "j 252\n",
      "(28, 28)\n",
      "j 253\n",
      "(28, 28)\n",
      "j 254\n",
      "(28, 28)\n",
      "j 255\n",
      "(28, 28)\n",
      "j 256\n",
      "(28, 28)\n",
      "j 257\n",
      "(28, 28)\n",
      "j 258\n",
      "(28, 28)\n",
      "j 259\n",
      "(28, 28)\n",
      "j 260\n",
      "(28, 28)\n",
      "j 261\n",
      "(28, 28)\n",
      "j 262\n",
      "(28, 28)\n",
      "j 263\n",
      "(28, 28)\n",
      "j 264\n",
      "(28, 28)\n",
      "j 265\n",
      "(28, 28)\n",
      "j 266\n",
      "(28, 28)\n",
      "j 267\n",
      "(28, 28)\n",
      "j 268\n",
      "(28, 28)\n",
      "j 269\n",
      "(28, 28)\n",
      "j 270\n",
      "(28, 28)\n",
      "j 271\n",
      "(28, 28)\n",
      "j 272\n",
      "(28, 28)\n",
      "j 273\n",
      "(28, 28)\n",
      "j 274\n",
      "(28, 28)\n",
      "j 275\n",
      "(28, 28)\n",
      "j 276\n",
      "(28, 28)\n",
      "j 277\n",
      "(28, 28)\n",
      "j 278\n",
      "(28, 28)\n",
      "j 279\n",
      "(28, 28)\n",
      "j 280\n",
      "(28, 28)\n",
      "j 281\n",
      "(28, 28)\n",
      "j 282\n",
      "(28, 28)\n",
      "j 283\n",
      "(28, 28)\n",
      "j 284\n",
      "(28, 28)\n",
      "j 285\n",
      "(28, 28)\n",
      "j 286\n",
      "(28, 28)\n",
      "j 287\n",
      "(28, 28)\n",
      "j 288\n",
      "(28, 28)\n",
      "j 289\n",
      "(28, 28)\n",
      "j 290\n",
      "(28, 28)\n",
      "j 291\n",
      "(28, 28)\n",
      "j 292\n",
      "(28, 28)\n",
      "j 293\n",
      "(28, 28)\n",
      "j 294\n",
      "(28, 28)\n",
      "j 295\n",
      "(28, 28)\n",
      "j 296\n",
      "(28, 28)\n",
      "j 297\n",
      "(28, 28)\n",
      "j 298\n",
      "(28, 28)\n",
      "j 299\n",
      "(28, 28)\n",
      "j 300\n",
      "(28, 28)\n",
      "j 301\n",
      "(28, 28)\n",
      "j 302\n",
      "(28, 28)\n",
      "j 303\n",
      "(28, 28)\n",
      "j 304\n",
      "(28, 28)\n",
      "j 305\n",
      "(28, 28)\n",
      "j 306\n",
      "(28, 28)\n",
      "j 307\n",
      "(28, 28)\n",
      "j 308\n",
      "(28, 28)\n",
      "j 309\n",
      "(28, 28)\n",
      "j 310\n",
      "(28, 28)\n",
      "j 311\n",
      "(28, 28)\n",
      "j 312\n",
      "(28, 28)\n",
      "j 313\n",
      "(28, 28)\n",
      "j 314\n",
      "(28, 28)\n",
      "j 315\n",
      "(28, 28)\n",
      "j 316\n",
      "(28, 28)\n",
      "j 317\n",
      "(28, 28)\n",
      "j 318\n",
      "(28, 28)\n",
      "j 319\n",
      "(28, 28)\n",
      "j 320\n",
      "(28, 28)\n",
      "j 321\n",
      "(28, 28)\n",
      "j 322\n",
      "(28, 28)\n",
      "j 323\n",
      "(28, 28)\n",
      "j 324\n",
      "(28, 28)\n",
      "j 325\n",
      "(28, 28)\n",
      "j 326\n",
      "(28, 28)\n",
      "j 327\n",
      "(28, 28)\n",
      "j 328\n",
      "(28, 28)\n",
      "j 329\n",
      "(28, 28)\n",
      "j 330\n",
      "(28, 28)\n",
      "j 331\n",
      "(28, 28)\n",
      "j 332\n",
      "(28, 28)\n",
      "j 333\n",
      "(28, 28)\n",
      "j 334\n",
      "(28, 28)\n",
      "j 335\n",
      "(28, 28)\n",
      "j 336\n",
      "(28, 28)\n",
      "j 337\n",
      "(28, 28)\n",
      "j 338\n",
      "(28, 28)\n",
      "j 339\n",
      "(28, 28)\n",
      "j 340\n",
      "(28, 28)\n",
      "j 341\n",
      "(28, 28)\n",
      "j 342\n",
      "(28, 28)\n",
      "j 343\n",
      "(28, 28)\n",
      "j 344\n",
      "(28, 28)\n",
      "j 345\n",
      "(28, 28)\n",
      "j 346\n",
      "(28, 28)\n",
      "j 347\n",
      "(28, 28)\n",
      "j 348\n",
      "(28, 28)\n",
      "j 349\n",
      "(28, 28)\n",
      "j 350\n",
      "(28, 28)\n",
      "j 351\n",
      "(28, 28)\n",
      "j 352\n",
      "(28, 28)\n",
      "j 353\n",
      "(28, 28)\n",
      "j 354\n",
      "(28, 28)\n",
      "j 355\n",
      "(28, 28)\n",
      "j 356\n",
      "(28, 28)\n",
      "j 357\n",
      "(28, 28)\n",
      "j 358\n",
      "(28, 28)\n",
      "j 359\n",
      "(28, 28)\n",
      "j 360\n",
      "(28, 28)\n",
      "j 361\n",
      "(28, 28)\n",
      "j 362\n",
      "(28, 28)\n",
      "j 363\n",
      "(28, 28)\n",
      "j 364\n",
      "(28, 28)\n",
      "j 365\n",
      "(28, 28)\n",
      "j 366\n",
      "(28, 28)\n",
      "j 367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "j 368\n",
      "(28, 28)\n",
      "j 369\n",
      "(28, 28)\n",
      "j 370\n",
      "(28, 28)\n",
      "j 371\n",
      "(28, 28)\n",
      "j 372\n",
      "(28, 28)\n",
      "j 373\n",
      "(28, 28)\n",
      "j 374\n",
      "(28, 28)\n",
      "j 375\n",
      "(28, 28)\n",
      "j 376\n",
      "(28, 28)\n",
      "j 377\n",
      "(28, 28)\n",
      "j 378\n",
      "(28, 28)\n",
      "j 379\n",
      "(28, 28)\n",
      "j 380\n",
      "(28, 28)\n",
      "j 381\n",
      "(28, 28)\n",
      "j 382\n",
      "(28, 28)\n",
      "j 383\n",
      "(28, 28)\n",
      "j 384\n",
      "(28, 28)\n",
      "j 385\n",
      "(28, 28)\n",
      "j 386\n",
      "(28, 28)\n",
      "j 387\n",
      "(28, 28)\n",
      "j 388\n",
      "(28, 28)\n",
      "j 389\n",
      "(28, 28)\n",
      "j 390\n",
      "(28, 28)\n",
      "j 391\n",
      "(28, 28)\n",
      "j 392\n",
      "(28, 28)\n",
      "j 393\n",
      "(28, 28)\n",
      "j 394\n",
      "(28, 28)\n",
      "j 395\n",
      "(28, 28)\n",
      "j 396\n",
      "(28, 28)\n",
      "j 397\n",
      "(28, 28)\n",
      "j 398\n",
      "(28, 28)\n",
      "j 399\n",
      "(28, 28)\n",
      "j 400\n",
      "(28, 28)\n",
      "j 401\n",
      "(28, 28)\n",
      "j 402\n",
      "(28, 28)\n",
      "j 403\n",
      "(28, 28)\n",
      "j 404\n",
      "(28, 28)\n",
      "j 405\n",
      "(28, 28)\n",
      "j 406\n",
      "(28, 28)\n",
      "j 407\n",
      "(28, 28)\n",
      "j 408\n",
      "(28, 28)\n",
      "j 409\n",
      "(28, 28)\n",
      "j 410\n",
      "(28, 28)\n",
      "j 411\n",
      "(28, 28)\n",
      "j 412\n",
      "(28, 28)\n",
      "j 413\n",
      "(28, 28)\n",
      "j 414\n",
      "(28, 28)\n",
      "j 415\n",
      "(28, 28)\n",
      "j 416\n",
      "(28, 28)\n",
      "j 417\n",
      "(28, 28)\n",
      "j 418\n",
      "(28, 28)\n",
      "j 419\n",
      "(28, 28)\n",
      "j 420\n",
      "(28, 28)\n",
      "j 421\n",
      "(28, 28)\n",
      "j 422\n",
      "(28, 28)\n",
      "j 423\n",
      "(28, 28)\n",
      "j 424\n",
      "(28, 28)\n",
      "j 425\n",
      "(28, 28)\n",
      "j 426\n",
      "(28, 28)\n",
      "j 427\n",
      "(28, 28)\n",
      "j 428\n",
      "(28, 28)\n",
      "j 429\n",
      "(28, 28)\n",
      "j 430\n",
      "(28, 28)\n",
      "j 431\n",
      "(28, 28)\n",
      "j 432\n",
      "(28, 28)\n",
      "j 433\n",
      "(28, 28)\n",
      "j 434\n",
      "(28, 28)\n",
      "j 435\n",
      "(28, 28)\n",
      "j 436\n",
      "(28, 28)\n",
      "j 437\n",
      "(28, 28)\n",
      "j 438\n",
      "(28, 28)\n",
      "j 439\n",
      "(28, 28)\n",
      "j 440\n",
      "(28, 28)\n",
      "j 441\n",
      "(28, 28)\n",
      "j 442\n",
      "(28, 28)\n",
      "j 443\n",
      "(28, 28)\n",
      "j 444\n",
      "(28, 28)\n",
      "j 445\n",
      "(28, 28)\n",
      "j 446\n",
      "(28, 28)\n",
      "j 447\n",
      "(28, 28)\n",
      "j 448\n",
      "(28, 28)\n",
      "j 449\n",
      "(28, 28)\n",
      "j 450\n",
      "(28, 28)\n",
      "j 451\n",
      "(28, 28)\n",
      "j 452\n",
      "(28, 28)\n",
      "j 453\n",
      "(28, 28)\n",
      "j 454\n",
      "(28, 28)\n",
      "j 455\n",
      "(28, 28)\n",
      "j 456\n",
      "(28, 28)\n",
      "j 457\n",
      "(28, 28)\n",
      "j 458\n",
      "(28, 28)\n",
      "j 459\n",
      "(28, 28)\n",
      "j 460\n",
      "(28, 28)\n",
      "j 461\n",
      "(28, 28)\n",
      "j 462\n",
      "(28, 28)\n",
      "j 463\n",
      "(28, 28)\n",
      "j 464\n",
      "(28, 28)\n",
      "j 465\n",
      "(28, 28)\n",
      "j 466\n",
      "(28, 28)\n",
      "j 467\n",
      "(28, 28)\n",
      "j 468\n",
      "(28, 28)\n",
      "j 469\n",
      "(28, 28)\n",
      "j 470\n",
      "(28, 28)\n",
      "j 471\n",
      "(28, 28)\n",
      "j 472\n",
      "(28, 28)\n",
      "j 473\n",
      "(28, 28)\n",
      "j 474\n",
      "(28, 28)\n",
      "j 475\n",
      "(28, 28)\n",
      "j 476\n",
      "(28, 28)\n",
      "j 477\n",
      "(28, 28)\n",
      "j 478\n",
      "(28, 28)\n",
      "j 479\n",
      "(28, 28)\n",
      "j 480\n",
      "(28, 28)\n",
      "j 481\n",
      "(28, 28)\n",
      "j 482\n",
      "(28, 28)\n",
      "j 483\n",
      "(28, 28)\n",
      "j 484\n",
      "(28, 28)\n",
      "j 485\n",
      "(28, 28)\n",
      "j 486\n",
      "(28, 28)\n",
      "j 487\n",
      "(28, 28)\n",
      "j 488\n",
      "(28, 28)\n",
      "j 489\n",
      "(28, 28)\n",
      "j 490\n",
      "(28, 28)\n",
      "j 491\n",
      "(28, 28)\n",
      "j 492\n",
      "(28, 28)\n",
      "j 493\n",
      "(28, 28)\n",
      "j 494\n",
      "(28, 28)\n",
      "j 495\n",
      "(28, 28)\n",
      "j 496\n",
      "(28, 28)\n",
      "j 497\n",
      "(28, 28)\n",
      "j 498\n",
      "(28, 28)\n",
      "j 499\n",
      "(28, 28)\n",
      "j 500\n",
      "(28, 28)\n",
      "j 501\n",
      "(28, 28)\n",
      "j 502\n",
      "(28, 28)\n",
      "j 503\n",
      "(28, 28)\n",
      "j 504\n",
      "(28, 28)\n",
      "j 505\n",
      "(28, 28)\n",
      "j 506\n",
      "(28, 28)\n",
      "j 507\n",
      "(28, 28)\n",
      "j 508\n",
      "(28, 28)\n",
      "j 509\n",
      "(28, 28)\n",
      "j 510\n",
      "(28, 28)\n",
      "j 511\n",
      "(28, 28)\n",
      "j 512\n",
      "(28, 28)\n",
      "j 513\n",
      "(28, 28)\n",
      "j 514\n",
      "(28, 28)\n",
      "j 515\n",
      "(28, 28)\n",
      "j 516\n",
      "(28, 28)\n",
      "j 517\n",
      "(28, 28)\n",
      "j 518\n",
      "(28, 28)\n",
      "j 519\n",
      "(28, 28)\n",
      "j 520\n",
      "(28, 28)\n",
      "j 521\n",
      "(28, 28)\n",
      "j 522\n",
      "(28, 28)\n",
      "j 523\n",
      "(28, 28)\n",
      "j 524\n",
      "(28, 28)\n",
      "j 525\n",
      "(28, 28)\n",
      "j 526\n",
      "(28, 28)\n",
      "j 527\n",
      "(28, 28)\n",
      "j 528\n",
      "(28, 28)\n",
      "j 529\n",
      "(28, 28)\n",
      "j 530\n",
      "(28, 28)\n",
      "j 531\n",
      "(28, 28)\n",
      "j 532\n",
      "(28, 28)\n",
      "j 533\n",
      "(28, 28)\n",
      "j 534\n",
      "(28, 28)\n",
      "j 535\n",
      "(28, 28)\n",
      "j 536\n",
      "(28, 28)\n",
      "j 537\n",
      "(28, 28)\n",
      "j 538\n",
      "(28, 28)\n",
      "j 539\n",
      "(28, 28)\n",
      "j 540\n",
      "(28, 28)\n",
      "j 541\n",
      "(28, 28)\n",
      "j 542\n",
      "(28, 28)\n",
      "j 543\n",
      "(28, 28)\n",
      "j 544\n",
      "(28, 28)\n",
      "j 545\n",
      "(28, 28)\n",
      "j 546\n",
      "(28, 28)\n",
      "j 547\n",
      "(28, 28)\n",
      "j 548\n",
      "(28, 28)\n",
      "j 549\n",
      "(28, 28)\n",
      "j 550\n",
      "(28, 28)\n",
      "j 551\n",
      "(28, 28)\n",
      "j 552\n",
      "(28, 28)\n",
      "j 553\n",
      "(28, 28)\n",
      "j 554\n",
      "(28, 28)\n",
      "j 555\n",
      "(28, 28)\n",
      "j 556\n",
      "(28, 28)\n",
      "j 557\n",
      "(28, 28)\n",
      "j 558\n",
      "(28, 28)\n",
      "j 559\n",
      "(28, 28)\n",
      "j 560\n",
      "(28, 28)\n",
      "j 561\n",
      "(28, 28)\n",
      "j 562\n",
      "(28, 28)\n",
      "j 563\n",
      "(28, 28)\n",
      "j 564\n",
      "(28, 28)\n",
      "j 565\n",
      "(28, 28)\n",
      "j 566\n",
      "(28, 28)\n",
      "j 567\n",
      "(28, 28)\n",
      "j 568\n",
      "(28, 28)\n",
      "j 569\n",
      "(28, 28)\n",
      "j 570\n",
      "(28, 28)\n",
      "j 571\n",
      "(28, 28)\n",
      "j 572\n",
      "(28, 28)\n",
      "j 573\n",
      "(28, 28)\n",
      "j 574\n",
      "(28, 28)\n",
      "j 575\n",
      "(28, 28)\n",
      "j 576\n",
      "(28, 28)\n",
      "j 577\n",
      "(28, 28)\n",
      "j 578\n",
      "(28, 28)\n",
      "j 579\n",
      "(28, 28)\n",
      "j 580\n",
      "(28, 28)\n",
      "j 581\n",
      "(28, 28)\n",
      "j 582\n",
      "(28, 28)\n",
      "j 583\n",
      "(28, 28)\n",
      "j 584\n",
      "(28, 28)\n",
      "j 585\n",
      "(28, 28)\n",
      "j 586\n",
      "(28, 28)\n",
      "j 587\n",
      "(28, 28)\n",
      "j 588\n",
      "(28, 28)\n",
      "j 589\n",
      "(28, 28)\n",
      "j 590\n",
      "(28, 28)\n",
      "j 591\n",
      "(28, 28)\n",
      "j 592\n",
      "(28, 28)\n",
      "j 593\n",
      "(28, 28)\n",
      "j 594\n",
      "(28, 28)\n",
      "j 595\n",
      "(28, 28)\n",
      "j 596\n",
      "(28, 28)\n",
      "j 597\n",
      "(28, 28)\n",
      "j 598\n",
      "(28, 28)\n",
      "j 599\n",
      "(28, 28)\n",
      "j 600\n",
      "(28, 28)\n",
      "j 601\n",
      "(28, 28)\n",
      "j 602\n",
      "(28, 28)\n",
      "j 603\n",
      "(28, 28)\n",
      "j 604\n",
      "(28, 28)\n",
      "j 605\n",
      "(28, 28)\n",
      "j 606\n",
      "(28, 28)\n",
      "j 607\n",
      "(28, 28)\n",
      "j 608\n",
      "(28, 28)\n",
      "j 609\n",
      "(28, 28)\n",
      "j 610\n",
      "(28, 28)\n",
      "j 611\n",
      "(28, 28)\n",
      "j 612\n",
      "(28, 28)\n",
      "j 613\n",
      "(28, 28)\n",
      "j 614\n",
      "(28, 28)\n",
      "j 615\n",
      "(28, 28)\n",
      "j 616\n",
      "(28, 28)\n",
      "j 617\n",
      "(28, 28)\n",
      "j 618\n",
      "(28, 28)\n",
      "j 619\n",
      "(28, 28)\n",
      "j 620\n",
      "(28, 28)\n",
      "j 621\n",
      "(28, 28)\n",
      "j 622\n",
      "(28, 28)\n",
      "j 623\n",
      "(28, 28)\n",
      "j 624\n",
      "(28, 28)\n",
      "j 625\n",
      "(28, 28)\n",
      "j 626\n",
      "(28, 28)\n",
      "j 627\n",
      "(28, 28)\n",
      "j 628\n",
      "(28, 28)\n",
      "j 629\n",
      "(28, 28)\n",
      "j 630\n",
      "(28, 28)\n",
      "j 631\n",
      "(28, 28)\n",
      "j 632\n",
      "(28, 28)\n",
      "j 633\n",
      "(28, 28)\n",
      "j 634\n",
      "(28, 28)\n",
      "j 635\n",
      "(28, 28)\n",
      "j 636\n",
      "(28, 28)\n",
      "j 637\n",
      "(28, 28)\n",
      "j 638\n",
      "(28, 28)\n",
      "j 639\n",
      "(28, 28)\n",
      "j 640\n",
      "(28, 28)\n",
      "j 641\n",
      "(28, 28)\n",
      "j 642\n",
      "(28, 28)\n",
      "j 643\n",
      "(28, 28)\n",
      "j 644\n",
      "(28, 28)\n",
      "j 645\n",
      "(28, 28)\n",
      "j 646\n",
      "(28, 28)\n",
      "j 647\n",
      "(28, 28)\n",
      "j 648\n",
      "(28, 28)\n",
      "j 649\n",
      "(28, 28)\n",
      "j 650\n",
      "(28, 28)\n",
      "j 651\n",
      "(28, 28)\n",
      "j 652\n",
      "(28, 28)\n",
      "j 653\n",
      "(28, 28)\n",
      "j 654\n",
      "(28, 28)\n",
      "j 655\n",
      "(28, 28)\n",
      "j 656\n",
      "(28, 28)\n",
      "j 657\n",
      "(28, 28)\n",
      "j 658\n",
      "(28, 28)\n",
      "j 659\n",
      "(28, 28)\n",
      "j 660\n",
      "(28, 28)\n",
      "j 661\n",
      "(28, 28)\n",
      "j 662\n",
      "(28, 28)\n",
      "j 663\n",
      "(28, 28)\n",
      "j 664\n",
      "(28, 28)\n",
      "j 665\n",
      "(28, 28)\n",
      "j 666\n",
      "(28, 28)\n",
      "j 667\n",
      "(28, 28)\n",
      "j 668\n",
      "(28, 28)\n",
      "j 669\n",
      "(28, 28)\n",
      "j 670\n",
      "(28, 28)\n",
      "j 671\n",
      "(28, 28)\n",
      "j 672\n",
      "(28, 28)\n",
      "j 673\n",
      "(28, 28)\n",
      "j 674\n",
      "(28, 28)\n",
      "j 675\n",
      "(28, 28)\n",
      "j 676\n",
      "(28, 28)\n",
      "j 677\n",
      "(28, 28)\n",
      "j 678\n",
      "(28, 28)\n",
      "j 679\n",
      "(28, 28)\n",
      "j 680\n",
      "(28, 28)\n",
      "j 681\n",
      "(28, 28)\n",
      "j 682\n",
      "(28, 28)\n",
      "j 683\n",
      "(28, 28)\n",
      "j 684\n",
      "(28, 28)\n",
      "j 685\n",
      "(28, 28)\n",
      "j 686\n",
      "(28, 28)\n",
      "j 687\n",
      "(28, 28)\n",
      "j 688\n",
      "(28, 28)\n",
      "j 689\n",
      "(28, 28)\n",
      "j 690\n",
      "(28, 28)\n",
      "j 691\n",
      "(28, 28)\n",
      "j 692\n",
      "(28, 28)\n",
      "j 693\n",
      "(28, 28)\n",
      "j 694\n",
      "(28, 28)\n",
      "j 695\n",
      "(28, 28)\n",
      "j 696\n",
      "(28, 28)\n",
      "j 697\n",
      "(28, 28)\n",
      "j 698\n",
      "(28, 28)\n",
      "j 699\n",
      "(28, 28)\n",
      "j 700\n",
      "(28, 28)\n",
      "j 701\n",
      "(28, 28)\n",
      "j 702\n",
      "(28, 28)\n",
      "j 703\n",
      "(28, 28)\n",
      "j 704\n",
      "(28, 28)\n",
      "j 705\n",
      "(28, 28)\n",
      "j 706\n",
      "(28, 28)\n",
      "j 707\n",
      "(28, 28)\n",
      "j 708\n",
      "(28, 28)\n",
      "j 709\n",
      "(28, 28)\n",
      "j 710\n",
      "(28, 28)\n",
      "j 711\n",
      "(28, 28)\n",
      "j 712\n",
      "(28, 28)\n",
      "j 713\n",
      "(28, 28)\n",
      "j 714\n",
      "(28, 28)\n",
      "j 715\n",
      "(28, 28)\n",
      "j 716\n",
      "(28, 28)\n",
      "j 717\n",
      "(28, 28)\n",
      "j 718\n",
      "(28, 28)\n",
      "j 719\n",
      "(28, 28)\n",
      "j 720\n",
      "(28, 28)\n",
      "j 721\n",
      "(28, 28)\n",
      "j 722\n",
      "(28, 28)\n",
      "j 723\n",
      "(28, 28)\n",
      "j 724\n",
      "(28, 28)\n",
      "j 725\n",
      "(28, 28)\n",
      "j 726\n",
      "(28, 28)\n",
      "j 727\n",
      "(28, 28)\n",
      "j 728\n",
      "(28, 28)\n",
      "j 729\n",
      "(28, 28)\n",
      "j 730\n",
      "(28, 28)\n",
      "j 731\n",
      "(28, 28)\n",
      "j 732\n",
      "(28, 28)\n",
      "j 733\n",
      "(28, 28)\n",
      "j 734\n",
      "(28, 28)\n",
      "j 735\n",
      "(28, 28)\n",
      "j 736\n",
      "(28, 28)\n",
      "j 737\n",
      "(28, 28)\n",
      "j 738\n",
      "(28, 28)\n",
      "j 739\n",
      "(28, 28)\n",
      "j 740\n",
      "(28, 28)\n",
      "j 741\n",
      "(28, 28)\n",
      "j 742\n",
      "(28, 28)\n",
      "j 743\n",
      "(28, 28)\n",
      "j 744\n",
      "(28, 28)\n",
      "j 745\n",
      "(28, 28)\n",
      "j 746\n",
      "(28, 28)\n",
      "j 747\n",
      "(28, 28)\n",
      "j 748\n",
      "(28, 28)\n",
      "j 749\n",
      "(28, 28)\n",
      "j 750\n",
      "(28, 28)\n",
      "j 751\n",
      "(28, 28)\n",
      "j 752\n",
      "(28, 28)\n",
      "j 753\n",
      "(28, 28)\n",
      "j 754\n",
      "(28, 28)\n",
      "j 755\n",
      "(28, 28)\n",
      "j 756\n",
      "[INFO] compiling model fold1.....\n",
      "[INFO] training network...\n",
      "(969, 28, 28, 1) (303, 28, 28, 1) (969, 2) (303, 2)\n",
      "Train on 969 samples, validate on 243 samples\n",
      "Epoch 1/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6941 - accuracy: 0.5015 - val_loss: 0.6927 - val_accuracy: 0.5391\n",
      "Epoch 2/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6925 - accuracy: 0.5191 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
      "Epoch 3/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6912 - accuracy: 0.5356 - val_loss: 0.6922 - val_accuracy: 0.4856\n",
      "Epoch 4/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5439 - val_loss: 0.6921 - val_accuracy: 0.4609\n",
      "Epoch 5/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6896 - accuracy: 0.5098 - val_loss: 0.6916 - val_accuracy: 0.4650\n",
      "Epoch 6/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6889 - accuracy: 0.5645 - val_loss: 0.6918 - val_accuracy: 0.4774\n",
      "Epoch 7/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5263 - val_loss: 0.6913 - val_accuracy: 0.4815\n",
      "Epoch 8/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5263 - val_loss: 0.6908 - val_accuracy: 0.4815\n",
      "Epoch 9/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5273 - val_loss: 0.6904 - val_accuracy: 0.4856\n",
      "Epoch 10/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5377 - val_loss: 0.6900 - val_accuracy: 0.4815\n",
      "Epoch 11/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5501 - val_loss: 0.6897 - val_accuracy: 0.4774\n",
      "Epoch 12/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5304 - val_loss: 0.6886 - val_accuracy: 0.5267\n",
      "Epoch 13/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5635 - val_loss: 0.6884 - val_accuracy: 0.5267\n",
      "Epoch 14/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6833 - accuracy: 0.5882 - val_loss: 0.6885 - val_accuracy: 0.4856\n",
      "Epoch 15/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6827 - accuracy: 0.5707 - val_loss: 0.6881 - val_accuracy: 0.5021\n",
      "Epoch 16/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6821 - accuracy: 0.5882 - val_loss: 0.6879 - val_accuracy: 0.4897\n",
      "Epoch 17/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6812 - accuracy: 0.5604 - val_loss: 0.6873 - val_accuracy: 0.5432\n",
      "Epoch 18/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6808 - accuracy: 0.5831 - val_loss: 0.6875 - val_accuracy: 0.4938\n",
      "Epoch 19/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6803 - accuracy: 0.5759 - val_loss: 0.6871 - val_accuracy: 0.5267\n",
      "Epoch 20/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6800 - accuracy: 0.5748 - val_loss: 0.6870 - val_accuracy: 0.5267\n",
      "Epoch 21/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6790 - accuracy: 0.5728 - val_loss: 0.6867 - val_accuracy: 0.5391\n",
      "Epoch 22/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6783 - accuracy: 0.5820 - val_loss: 0.6861 - val_accuracy: 0.5473\n",
      "Epoch 23/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6773 - accuracy: 0.5789 - val_loss: 0.6851 - val_accuracy: 0.5473\n",
      "Epoch 24/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6767 - accuracy: 0.5841 - val_loss: 0.6849 - val_accuracy: 0.5473\n",
      "Epoch 25/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6767 - accuracy: 0.5810 - val_loss: 0.6837 - val_accuracy: 0.6008\n",
      "Epoch 26/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6758 - accuracy: 0.6006 - val_loss: 0.6838 - val_accuracy: 0.5967\n",
      "Epoch 27/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6749 - accuracy: 0.5882 - val_loss: 0.6830 - val_accuracy: 0.6008\n",
      "Epoch 28/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6743 - accuracy: 0.6047 - val_loss: 0.6830 - val_accuracy: 0.5926\n",
      "Epoch 29/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6738 - accuracy: 0.5893 - val_loss: 0.6821 - val_accuracy: 0.5967\n",
      "Epoch 30/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.6047 - val_loss: 0.6823 - val_accuracy: 0.5926\n",
      "Epoch 31/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6728 - accuracy: 0.6037 - val_loss: 0.6830 - val_accuracy: 0.5802\n",
      "Epoch 32/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6722 - accuracy: 0.5872 - val_loss: 0.6814 - val_accuracy: 0.5967\n",
      "Epoch 33/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.5944 - val_loss: 0.6812 - val_accuracy: 0.5926\n",
      "Epoch 34/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6707 - accuracy: 0.6006 - val_loss: 0.6807 - val_accuracy: 0.5967\n",
      "Epoch 35/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6699 - accuracy: 0.6006 - val_loss: 0.6806 - val_accuracy: 0.5926\n",
      "Epoch 36/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6696 - accuracy: 0.6017 - val_loss: 0.6808 - val_accuracy: 0.5967\n",
      "Epoch 37/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.6037 - val_loss: 0.6808 - val_accuracy: 0.6008\n",
      "Epoch 38/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6683 - accuracy: 0.5986 - val_loss: 0.6801 - val_accuracy: 0.5885\n",
      "Epoch 39/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6679 - accuracy: 0.6006 - val_loss: 0.6801 - val_accuracy: 0.6008\n",
      "Epoch 40/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6677 - accuracy: 0.5862 - val_loss: 0.6787 - val_accuracy: 0.6091\n",
      "Epoch 41/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6664 - accuracy: 0.6017 - val_loss: 0.6789 - val_accuracy: 0.6008\n",
      "Epoch 42/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6661 - accuracy: 0.5965 - val_loss: 0.6790 - val_accuracy: 0.5885\n",
      "Epoch 43/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6652 - accuracy: 0.5986 - val_loss: 0.6790 - val_accuracy: 0.5926\n",
      "Epoch 44/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6645 - accuracy: 0.5955 - val_loss: 0.6774 - val_accuracy: 0.5926\n",
      "Epoch 45/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6640 - accuracy: 0.6120 - val_loss: 0.6789 - val_accuracy: 0.6008\n",
      "Epoch 46/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6638 - accuracy: 0.5996 - val_loss: 0.6789 - val_accuracy: 0.6008\n",
      "Epoch 47/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6630 - accuracy: 0.5893 - val_loss: 0.6766 - val_accuracy: 0.5967\n",
      "Epoch 48/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6623 - accuracy: 0.6027 - val_loss: 0.6770 - val_accuracy: 0.6049\n",
      "Epoch 49/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6617 - accuracy: 0.6078 - val_loss: 0.6775 - val_accuracy: 0.5967\n",
      "Epoch 50/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6611 - accuracy: 0.6058 - val_loss: 0.6760 - val_accuracy: 0.5967\n",
      "Epoch 51/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6607 - accuracy: 0.6078 - val_loss: 0.6755 - val_accuracy: 0.5967\n",
      "Epoch 52/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.6047 - val_loss: 0.6748 - val_accuracy: 0.6008\n",
      "Epoch 53/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6601 - accuracy: 0.6037 - val_loss: 0.6756 - val_accuracy: 0.5967\n",
      "Epoch 54/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6599 - accuracy: 0.5965 - val_loss: 0.6755 - val_accuracy: 0.6008\n",
      "Epoch 55/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6588 - accuracy: 0.6037 - val_loss: 0.6752 - val_accuracy: 0.6008\n",
      "Epoch 56/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6583 - accuracy: 0.6120 - val_loss: 0.6753 - val_accuracy: 0.6008\n",
      "Epoch 57/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6576 - accuracy: 0.5955 - val_loss: 0.6732 - val_accuracy: 0.6132\n",
      "Epoch 58/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6568 - accuracy: 0.6192 - val_loss: 0.6757 - val_accuracy: 0.6049\n",
      "Epoch 59/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6058 - val_loss: 0.6751 - val_accuracy: 0.6091\n",
      "Epoch 60/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6557 - accuracy: 0.6099 - val_loss: 0.6731 - val_accuracy: 0.5967\n",
      "Epoch 61/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6552 - accuracy: 0.6109 - val_loss: 0.6746 - val_accuracy: 0.6132\n",
      "Epoch 62/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6553 - accuracy: 0.6027 - val_loss: 0.6727 - val_accuracy: 0.6008\n",
      "Epoch 63/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6549 - accuracy: 0.6233 - val_loss: 0.6762 - val_accuracy: 0.5967\n",
      "Epoch 64/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6553 - accuracy: 0.5913 - val_loss: 0.6727 - val_accuracy: 0.6049\n",
      "Epoch 65/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6534 - accuracy: 0.6109 - val_loss: 0.6714 - val_accuracy: 0.6173\n",
      "Epoch 66/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6533 - accuracy: 0.6130 - val_loss: 0.6716 - val_accuracy: 0.6049\n",
      "Epoch 67/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6534 - accuracy: 0.6058 - val_loss: 0.6703 - val_accuracy: 0.6091\n",
      "Epoch 68/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6523 - accuracy: 0.6192 - val_loss: 0.6712 - val_accuracy: 0.6091\n",
      "Epoch 69/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6510 - accuracy: 0.6223 - val_loss: 0.6720 - val_accuracy: 0.6049\n",
      "Epoch 70/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6518 - accuracy: 0.6140 - val_loss: 0.6757 - val_accuracy: 0.5926\n",
      "Epoch 71/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6507 - accuracy: 0.6192 - val_loss: 0.6717 - val_accuracy: 0.6008\n",
      "Epoch 72/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6509 - accuracy: 0.6213 - val_loss: 0.6714 - val_accuracy: 0.6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6493 - accuracy: 0.6244 - val_loss: 0.6704 - val_accuracy: 0.6049\n",
      "Epoch 74/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6515 - accuracy: 0.6202 - val_loss: 0.6700 - val_accuracy: 0.6173\n",
      "Epoch 75/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6484 - accuracy: 0.6099 - val_loss: 0.6683 - val_accuracy: 0.6132\n",
      "Epoch 76/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6495 - accuracy: 0.6316 - val_loss: 0.6684 - val_accuracy: 0.6049\n",
      "Epoch 77/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6479 - accuracy: 0.6305 - val_loss: 0.6683 - val_accuracy: 0.6132\n",
      "Epoch 78/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6305 - val_loss: 0.6695 - val_accuracy: 0.6049\n",
      "Epoch 79/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6471 - accuracy: 0.6202 - val_loss: 0.6673 - val_accuracy: 0.6132\n",
      "Epoch 80/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6305 - val_loss: 0.6693 - val_accuracy: 0.6091\n",
      "Epoch 81/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6456 - accuracy: 0.6233 - val_loss: 0.6674 - val_accuracy: 0.6337\n",
      "Epoch 82/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6454 - accuracy: 0.6347 - val_loss: 0.6710 - val_accuracy: 0.6132\n",
      "Epoch 83/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6446 - accuracy: 0.6357 - val_loss: 0.6701 - val_accuracy: 0.6214\n",
      "Epoch 84/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6443 - accuracy: 0.6233 - val_loss: 0.6667 - val_accuracy: 0.6296\n",
      "Epoch 85/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6440 - accuracy: 0.6398 - val_loss: 0.6689 - val_accuracy: 0.6173\n",
      "Epoch 86/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6427 - accuracy: 0.6367 - val_loss: 0.6691 - val_accuracy: 0.6173\n",
      "Epoch 87/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6424 - accuracy: 0.6336 - val_loss: 0.6668 - val_accuracy: 0.6214\n",
      "Epoch 88/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.6388 - val_loss: 0.6689 - val_accuracy: 0.6173\n",
      "Epoch 89/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6414 - accuracy: 0.6326 - val_loss: 0.6658 - val_accuracy: 0.6214\n",
      "Epoch 90/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6405 - accuracy: 0.6419 - val_loss: 0.6652 - val_accuracy: 0.6214\n",
      "Epoch 91/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6450 - val_loss: 0.6659 - val_accuracy: 0.6173\n",
      "Epoch 92/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6394 - accuracy: 0.6419 - val_loss: 0.6637 - val_accuracy: 0.6255\n",
      "Epoch 93/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6395 - accuracy: 0.6563 - val_loss: 0.6644 - val_accuracy: 0.6173\n",
      "Epoch 94/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6402 - accuracy: 0.6388 - val_loss: 0.6657 - val_accuracy: 0.6214\n",
      "Epoch 95/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6385 - accuracy: 0.6440 - val_loss: 0.6630 - val_accuracy: 0.6255\n",
      "Epoch 96/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6372 - accuracy: 0.6574 - val_loss: 0.6634 - val_accuracy: 0.6173\n",
      "Epoch 97/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6385 - accuracy: 0.6491 - val_loss: 0.6633 - val_accuracy: 0.6296\n",
      "Epoch 98/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6360 - accuracy: 0.6563 - val_loss: 0.6622 - val_accuracy: 0.6255\n",
      "Epoch 99/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6370 - accuracy: 0.6450 - val_loss: 0.6628 - val_accuracy: 0.6255\n",
      "Epoch 100/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6398 - accuracy: 0.6326 - val_loss: 0.6660 - val_accuracy: 0.6173\n",
      "Epoch 101/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6371 - accuracy: 0.6481 - val_loss: 0.6712 - val_accuracy: 0.6214\n",
      "Epoch 102/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6338 - accuracy: 0.6409 - val_loss: 0.6608 - val_accuracy: 0.6296\n",
      "Epoch 103/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6344 - accuracy: 0.6512 - val_loss: 0.6602 - val_accuracy: 0.6379\n",
      "Epoch 104/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6332 - accuracy: 0.6594 - val_loss: 0.6614 - val_accuracy: 0.6214\n",
      "Epoch 105/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6333 - accuracy: 0.6574 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
      "Epoch 106/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6322 - accuracy: 0.6615 - val_loss: 0.6616 - val_accuracy: 0.6337\n",
      "Epoch 107/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6317 - accuracy: 0.6584 - val_loss: 0.6615 - val_accuracy: 0.6379\n",
      "Epoch 108/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6311 - accuracy: 0.6543 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
      "Epoch 109/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6677 - val_loss: 0.6584 - val_accuracy: 0.6296\n",
      "Epoch 110/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6288 - accuracy: 0.6718 - val_loss: 0.6621 - val_accuracy: 0.6214\n",
      "Epoch 111/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6294 - accuracy: 0.6625 - val_loss: 0.6578 - val_accuracy: 0.6337\n",
      "Epoch 112/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6356 - accuracy: 0.6450 - val_loss: 0.6567 - val_accuracy: 0.6337\n",
      "Epoch 113/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6312 - accuracy: 0.6718 - val_loss: 0.6675 - val_accuracy: 0.6255\n",
      "Epoch 114/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6284 - accuracy: 0.6687 - val_loss: 0.6556 - val_accuracy: 0.6543\n",
      "Epoch 115/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6266 - accuracy: 0.6770 - val_loss: 0.6567 - val_accuracy: 0.6337\n",
      "Epoch 116/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6258 - accuracy: 0.6760 - val_loss: 0.6550 - val_accuracy: 0.6461\n",
      "Epoch 117/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6252 - accuracy: 0.6667 - val_loss: 0.6544 - val_accuracy: 0.6502\n",
      "Epoch 118/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6252 - accuracy: 0.6780 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
      "Epoch 119/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6263 - accuracy: 0.6563 - val_loss: 0.6623 - val_accuracy: 0.6379\n",
      "Epoch 120/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6240 - accuracy: 0.6543 - val_loss: 0.6547 - val_accuracy: 0.6337\n",
      "Epoch 121/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6256 - accuracy: 0.6729 - val_loss: 0.6548 - val_accuracy: 0.6420\n",
      "Epoch 122/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6213 - accuracy: 0.6770 - val_loss: 0.6560 - val_accuracy: 0.6337\n",
      "Epoch 123/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6209 - accuracy: 0.6801 - val_loss: 0.6528 - val_accuracy: 0.6337\n",
      "Epoch 124/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6218 - accuracy: 0.6842 - val_loss: 0.6598 - val_accuracy: 0.6420\n",
      "Epoch 125/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6197 - accuracy: 0.6760 - val_loss: 0.6544 - val_accuracy: 0.6337\n",
      "Epoch 126/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6184 - accuracy: 0.6832 - val_loss: 0.6529 - val_accuracy: 0.6461\n",
      "Epoch 127/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6204 - accuracy: 0.6780 - val_loss: 0.6517 - val_accuracy: 0.6420\n",
      "Epoch 128/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6179 - accuracy: 0.6780 - val_loss: 0.6720 - val_accuracy: 0.5885\n",
      "Epoch 129/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6184 - accuracy: 0.6811 - val_loss: 0.6628 - val_accuracy: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6168 - accuracy: 0.6842 - val_loss: 0.6511 - val_accuracy: 0.6502\n",
      "Epoch 131/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6152 - accuracy: 0.6791 - val_loss: 0.6512 - val_accuracy: 0.6420\n",
      "Epoch 132/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6225 - accuracy: 0.6687 - val_loss: 0.6480 - val_accuracy: 0.6708\n",
      "Epoch 133/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6152 - accuracy: 0.6801 - val_loss: 0.6481 - val_accuracy: 0.6626\n",
      "Epoch 134/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6139 - accuracy: 0.6883 - val_loss: 0.6488 - val_accuracy: 0.6502\n",
      "Epoch 135/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6112 - accuracy: 0.6811 - val_loss: 0.6529 - val_accuracy: 0.6337\n",
      "Epoch 136/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6170 - accuracy: 0.6667 - val_loss: 0.6480 - val_accuracy: 0.6502\n",
      "Epoch 137/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6109 - accuracy: 0.6894 - val_loss: 0.6471 - val_accuracy: 0.6584\n",
      "Epoch 138/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6086 - accuracy: 0.6925 - val_loss: 0.6460 - val_accuracy: 0.6502\n",
      "Epoch 139/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6082 - accuracy: 0.6873 - val_loss: 0.6752 - val_accuracy: 0.5926\n",
      "Epoch 140/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6177 - accuracy: 0.6605 - val_loss: 0.6615 - val_accuracy: 0.5967\n",
      "Epoch 141/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6136 - accuracy: 0.6708 - val_loss: 0.6657 - val_accuracy: 0.6091\n",
      "Epoch 142/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6144 - accuracy: 0.6636 - val_loss: 0.6462 - val_accuracy: 0.6502\n",
      "Epoch 143/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6170 - accuracy: 0.6770 - val_loss: 0.6645 - val_accuracy: 0.6091\n",
      "Epoch 144/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6073 - accuracy: 0.6729 - val_loss: 0.6437 - val_accuracy: 0.6749\n",
      "Epoch 145/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6079 - accuracy: 0.6925 - val_loss: 0.6414 - val_accuracy: 0.6584\n",
      "Epoch 146/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6194 - accuracy: 0.6718 - val_loss: 0.6586 - val_accuracy: 0.6049\n",
      "Epoch 147/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6079 - accuracy: 0.6852 - val_loss: 0.6550 - val_accuracy: 0.6091\n",
      "Epoch 148/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6060 - accuracy: 0.6770 - val_loss: 0.6497 - val_accuracy: 0.6296\n",
      "Epoch 149/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6010 - accuracy: 0.6904 - val_loss: 0.6497 - val_accuracy: 0.6255\n",
      "Epoch 150/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6018 - accuracy: 0.6914 - val_loss: 0.6404 - val_accuracy: 0.6708\n",
      "Epoch 151/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6135 - accuracy: 0.6863 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 152/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5994 - accuracy: 0.7049 - val_loss: 0.6380 - val_accuracy: 0.6749\n",
      "Epoch 153/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6003 - accuracy: 0.6852 - val_loss: 0.6377 - val_accuracy: 0.6708\n",
      "Epoch 154/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5953 - accuracy: 0.7079 - val_loss: 0.6381 - val_accuracy: 0.6790\n",
      "Epoch 155/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5949 - accuracy: 0.7038 - val_loss: 0.6672 - val_accuracy: 0.5967\n",
      "Epoch 156/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6101 - accuracy: 0.6698 - val_loss: 0.6422 - val_accuracy: 0.6502\n",
      "Epoch 157/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5962 - accuracy: 0.6966 - val_loss: 0.6808 - val_accuracy: 0.5885\n",
      "Epoch 158/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5961 - accuracy: 0.6956 - val_loss: 0.6341 - val_accuracy: 0.6667\n",
      "Epoch 159/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5995 - accuracy: 0.6935 - val_loss: 0.6356 - val_accuracy: 0.6626\n",
      "Epoch 160/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5995 - accuracy: 0.6801 - val_loss: 0.6330 - val_accuracy: 0.6708\n",
      "Epoch 161/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5927 - accuracy: 0.6945 - val_loss: 0.6347 - val_accuracy: 0.6831\n",
      "Epoch 162/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5888 - accuracy: 0.7152 - val_loss: 0.6556 - val_accuracy: 0.6091\n",
      "Epoch 163/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6020 - accuracy: 0.6698 - val_loss: 0.6906 - val_accuracy: 0.5556\n",
      "Epoch 164/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6062 - accuracy: 0.6780 - val_loss: 0.6354 - val_accuracy: 0.6708\n",
      "Epoch 165/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5870 - accuracy: 0.6956 - val_loss: 0.6303 - val_accuracy: 0.6708\n",
      "Epoch 166/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5858 - accuracy: 0.7110 - val_loss: 0.6346 - val_accuracy: 0.6543\n",
      "Epoch 167/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6093 - accuracy: 0.6656 - val_loss: 0.6681 - val_accuracy: 0.5926\n",
      "Epoch 168/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5889 - accuracy: 0.6945 - val_loss: 0.6363 - val_accuracy: 0.6626\n",
      "Epoch 169/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.7121 - val_loss: 0.6316 - val_accuracy: 0.6749\n",
      "Epoch 170/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.7193 - val_loss: 0.6285 - val_accuracy: 0.6914\n",
      "Epoch 171/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5889 - accuracy: 0.6987 - val_loss: 0.6252 - val_accuracy: 0.7037\n",
      "Epoch 172/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5871 - accuracy: 0.6925 - val_loss: 0.6258 - val_accuracy: 0.6790\n",
      "Epoch 173/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5770 - accuracy: 0.7245 - val_loss: 0.6257 - val_accuracy: 0.6914\n",
      "Epoch 174/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5749 - accuracy: 0.7162 - val_loss: 0.6286 - val_accuracy: 0.6584\n",
      "Epoch 175/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5774 - accuracy: 0.7110 - val_loss: 0.6368 - val_accuracy: 0.6337\n",
      "Epoch 176/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5753 - accuracy: 0.7028 - val_loss: 0.6535 - val_accuracy: 0.6049\n",
      "Epoch 177/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5873 - accuracy: 0.6894 - val_loss: 0.6654 - val_accuracy: 0.5761\n",
      "Epoch 178/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5771 - accuracy: 0.7069 - val_loss: 0.6505 - val_accuracy: 0.6049\n",
      "Epoch 179/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5829 - accuracy: 0.6894 - val_loss: 0.6243 - val_accuracy: 0.6626\n",
      "Epoch 180/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5794 - accuracy: 0.6925 - val_loss: 0.6294 - val_accuracy: 0.6790\n",
      "Epoch 181/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5719 - accuracy: 0.7110 - val_loss: 0.6329 - val_accuracy: 0.6502\n",
      "Epoch 182/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5678 - accuracy: 0.7245 - val_loss: 0.6272 - val_accuracy: 0.6790\n",
      "Epoch 183/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5778 - accuracy: 0.6956 - val_loss: 0.6978 - val_accuracy: 0.5720\n",
      "Epoch 184/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6049 - accuracy: 0.6522 - val_loss: 0.6172 - val_accuracy: 0.7160\n",
      "Epoch 185/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5671 - accuracy: 0.7379 - val_loss: 0.6188 - val_accuracy: 0.6584\n",
      "Epoch 186/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6376 - accuracy: 0.6223 - val_loss: 0.7268 - val_accuracy: 0.5597\n",
      "Epoch 187/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5889 - accuracy: 0.6811 - val_loss: 0.6208 - val_accuracy: 0.6955\n",
      "Epoch 188/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5799 - accuracy: 0.6852 - val_loss: 0.6971 - val_accuracy: 0.5761\n",
      "Epoch 189/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5901 - accuracy: 0.6791 - val_loss: 0.6162 - val_accuracy: 0.6626\n",
      "Epoch 190/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6029 - accuracy: 0.6615 - val_loss: 0.6534 - val_accuracy: 0.6049\n",
      "Epoch 191/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5629 - accuracy: 0.7399 - val_loss: 0.6141 - val_accuracy: 0.6831\n",
      "Epoch 192/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5811 - accuracy: 0.6925 - val_loss: 0.7014 - val_accuracy: 0.5761\n",
      "Epoch 193/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5764 - accuracy: 0.6935 - val_loss: 0.6123 - val_accuracy: 0.7160\n",
      "Epoch 194/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5570 - accuracy: 0.7234 - val_loss: 0.6110 - val_accuracy: 0.7119\n",
      "Epoch 195/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5965 - accuracy: 0.6729 - val_loss: 0.6555 - val_accuracy: 0.5885\n",
      "Epoch 196/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5859 - accuracy: 0.6904 - val_loss: 0.6120 - val_accuracy: 0.7243\n",
      "Epoch 197/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5636 - accuracy: 0.7121 - val_loss: 0.6167 - val_accuracy: 0.6584\n",
      "Epoch 198/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5737 - accuracy: 0.6945 - val_loss: 0.6458 - val_accuracy: 0.6132\n",
      "Epoch 199/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5802 - accuracy: 0.7079 - val_loss: 0.6106 - val_accuracy: 0.7160\n",
      "Epoch 200/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.7193 - val_loss: 0.6070 - val_accuracy: 0.7202\n",
      "Epoch 201/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5615 - accuracy: 0.7172 - val_loss: 0.6222 - val_accuracy: 0.6584\n",
      "Epoch 202/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5601 - accuracy: 0.7049 - val_loss: 0.6355 - val_accuracy: 0.6420\n",
      "Epoch 203/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7307 - val_loss: 0.6152 - val_accuracy: 0.6831\n",
      "Epoch 204/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7317 - val_loss: 0.6104 - val_accuracy: 0.6996\n",
      "Epoch 205/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7430 - val_loss: 0.6721 - val_accuracy: 0.5967\n",
      "Epoch 206/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7430 - val_loss: 0.6019 - val_accuracy: 0.7284\n",
      "Epoch 207/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7441 - val_loss: 0.6002 - val_accuracy: 0.7119\n",
      "Epoch 208/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5517 - accuracy: 0.7121 - val_loss: 0.6009 - val_accuracy: 0.7325\n",
      "Epoch 209/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5510 - accuracy: 0.7276 - val_loss: 0.6183 - val_accuracy: 0.6379\n",
      "Epoch 210/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6142 - accuracy: 0.6563 - val_loss: 0.6778 - val_accuracy: 0.6049\n",
      "Epoch 211/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7503 - val_loss: 0.6218 - val_accuracy: 0.6584\n",
      "Epoch 212/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7307 - val_loss: 0.6852 - val_accuracy: 0.5926\n",
      "Epoch 213/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5620 - accuracy: 0.7059 - val_loss: 0.6419 - val_accuracy: 0.6173\n",
      "Epoch 214/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7296 - val_loss: 0.6634 - val_accuracy: 0.6049\n",
      "Epoch 215/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7131 - val_loss: 0.6855 - val_accuracy: 0.5720\n",
      "Epoch 216/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5898 - accuracy: 0.6646 - val_loss: 0.6587 - val_accuracy: 0.6132\n",
      "Epoch 217/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5761 - accuracy: 0.6780 - val_loss: 0.5995 - val_accuracy: 0.7037\n",
      "Epoch 218/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7296 - val_loss: 0.6528 - val_accuracy: 0.6049\n",
      "Epoch 219/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7358 - val_loss: 0.5923 - val_accuracy: 0.7325\n",
      "Epoch 220/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7461 - val_loss: 0.5921 - val_accuracy: 0.7325\n",
      "Epoch 221/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5238 - accuracy: 0.7637 - val_loss: 0.5923 - val_accuracy: 0.7407\n",
      "Epoch 222/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5274 - accuracy: 0.7523 - val_loss: 0.6542 - val_accuracy: 0.6255\n",
      "Epoch 223/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.6791 - val_loss: 0.6602 - val_accuracy: 0.5967\n",
      "Epoch 224/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6335 - accuracy: 0.6244 - val_loss: 0.6864 - val_accuracy: 0.5967\n",
      "Epoch 225/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7678 - val_loss: 0.5901 - val_accuracy: 0.7366\n",
      "Epoch 226/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5258 - accuracy: 0.7513 - val_loss: 0.6464 - val_accuracy: 0.6214\n",
      "Epoch 227/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5210 - accuracy: 0.7647 - val_loss: 0.5858 - val_accuracy: 0.7325\n",
      "Epoch 228/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5257 - accuracy: 0.7482 - val_loss: 0.6625 - val_accuracy: 0.6173\n",
      "Epoch 229/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7203 - val_loss: 0.5846 - val_accuracy: 0.7366\n",
      "Epoch 230/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7317 - val_loss: 0.6434 - val_accuracy: 0.6337\n",
      "Epoch 231/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7214 - val_loss: 0.5861 - val_accuracy: 0.7243\n",
      "Epoch 232/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5258 - accuracy: 0.7523 - val_loss: 0.6656 - val_accuracy: 0.6091\n",
      "Epoch 233/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5724 - accuracy: 0.6956 - val_loss: 0.5920 - val_accuracy: 0.6749\n",
      "Epoch 234/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7451 - val_loss: 0.5798 - val_accuracy: 0.7366\n",
      "Epoch 235/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5251 - accuracy: 0.7492 - val_loss: 0.6044 - val_accuracy: 0.6379\n",
      "Epoch 236/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5105 - accuracy: 0.7699 - val_loss: 0.5798 - val_accuracy: 0.7325\n",
      "Epoch 237/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5183 - accuracy: 0.7513 - val_loss: 0.5917 - val_accuracy: 0.6543\n",
      "Epoch 238/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7224 - val_loss: 0.6107 - val_accuracy: 0.6420\n",
      "Epoch 239/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7255 - val_loss: 0.6078 - val_accuracy: 0.6872\n",
      "Epoch 240/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5087 - accuracy: 0.7626 - val_loss: 0.6165 - val_accuracy: 0.6831\n",
      "Epoch 241/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5605 - accuracy: 0.7059 - val_loss: 0.6434 - val_accuracy: 0.6214\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6188 - accuracy: 0.6316 - val_loss: 0.5775 - val_accuracy: 0.7407\n",
      "Epoch 243/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5150 - accuracy: 0.7554 - val_loss: 0.5731 - val_accuracy: 0.7449\n",
      "Epoch 244/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5641 - accuracy: 0.7059 - val_loss: 0.5877 - val_accuracy: 0.7037\n",
      "Epoch 245/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5035 - accuracy: 0.7688 - val_loss: 0.5736 - val_accuracy: 0.7407\n",
      "Epoch 246/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7358 - val_loss: 0.6069 - val_accuracy: 0.6461\n",
      "Epoch 247/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5320 - accuracy: 0.7172 - val_loss: 0.6450 - val_accuracy: 0.6337\n",
      "Epoch 248/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.7234 - val_loss: 0.5726 - val_accuracy: 0.7325\n",
      "Epoch 249/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5173 - accuracy: 0.7513 - val_loss: 0.5684 - val_accuracy: 0.7613\n",
      "Epoch 250/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5022 - accuracy: 0.7843 - val_loss: 0.5671 - val_accuracy: 0.7613\n",
      "Epoch 251/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4953 - accuracy: 0.7895 - val_loss: 0.6139 - val_accuracy: 0.6872\n",
      "Epoch 252/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7307 - val_loss: 0.5647 - val_accuracy: 0.7531\n",
      "Epoch 253/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4875 - accuracy: 0.7988 - val_loss: 0.5736 - val_accuracy: 0.7119\n",
      "Epoch 254/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5038 - accuracy: 0.7472 - val_loss: 0.6167 - val_accuracy: 0.6790\n",
      "Epoch 255/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5035 - accuracy: 0.7637 - val_loss: 0.5645 - val_accuracy: 0.7366\n",
      "Epoch 256/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5028 - accuracy: 0.7678 - val_loss: 0.6082 - val_accuracy: 0.6955\n",
      "Epoch 257/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4897 - accuracy: 0.7822 - val_loss: 0.5686 - val_accuracy: 0.7202\n",
      "Epoch 258/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4855 - accuracy: 0.7936 - val_loss: 0.6110 - val_accuracy: 0.6914\n",
      "Epoch 259/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5227 - accuracy: 0.7389 - val_loss: 0.6173 - val_accuracy: 0.6255\n",
      "Epoch 260/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7059 - val_loss: 0.5661 - val_accuracy: 0.7449\n",
      "Epoch 261/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4802 - accuracy: 0.7895 - val_loss: 0.6179 - val_accuracy: 0.6790\n",
      "Epoch 262/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4883 - accuracy: 0.7699 - val_loss: 0.5689 - val_accuracy: 0.6831\n",
      "Epoch 263/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4926 - accuracy: 0.7595 - val_loss: 0.5801 - val_accuracy: 0.7202\n",
      "Epoch 264/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5099 - accuracy: 0.7441 - val_loss: 0.5548 - val_accuracy: 0.7613\n",
      "Epoch 265/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4696 - accuracy: 0.8039 - val_loss: 0.5927 - val_accuracy: 0.7202\n",
      "Epoch 266/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4663 - accuracy: 0.8122 - val_loss: 0.5487 - val_accuracy: 0.7654\n",
      "Epoch 267/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4618 - accuracy: 0.8039 - val_loss: 0.5570 - val_accuracy: 0.7284\n",
      "Epoch 268/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.8050 - val_loss: 0.5439 - val_accuracy: 0.7654\n",
      "Epoch 269/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5647 - accuracy: 0.6914 - val_loss: 0.8582 - val_accuracy: 0.5350\n",
      "Epoch 270/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.6914 - val_loss: 0.5761 - val_accuracy: 0.6626\n",
      "Epoch 271/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4715 - accuracy: 0.8050 - val_loss: 0.5994 - val_accuracy: 0.6996\n",
      "Epoch 272/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4664 - accuracy: 0.8019 - val_loss: 0.5884 - val_accuracy: 0.7284\n",
      "Epoch 273/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4665 - accuracy: 0.7946 - val_loss: 0.5597 - val_accuracy: 0.6955\n",
      "Epoch 274/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.6997 - val_loss: 0.6166 - val_accuracy: 0.6790\n",
      "Epoch 275/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4631 - accuracy: 0.8019 - val_loss: 0.5363 - val_accuracy: 0.7613\n",
      "Epoch 276/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4761 - accuracy: 0.7833 - val_loss: 0.7186 - val_accuracy: 0.5967\n",
      "Epoch 277/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5079 - accuracy: 0.7523 - val_loss: 0.5423 - val_accuracy: 0.7531\n",
      "Epoch 278/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4612 - accuracy: 0.8008 - val_loss: 0.5388 - val_accuracy: 0.7572\n",
      "Epoch 279/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4699 - accuracy: 0.7781 - val_loss: 0.6239 - val_accuracy: 0.6749\n",
      "Epoch 280/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.7131 - val_loss: 0.6005 - val_accuracy: 0.6461\n",
      "Epoch 281/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4919 - accuracy: 0.7564 - val_loss: 0.6332 - val_accuracy: 0.6502\n",
      "Epoch 282/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.8122 - val_loss: 0.5338 - val_accuracy: 0.7654\n",
      "Epoch 283/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4496 - accuracy: 0.8153 - val_loss: 0.5295 - val_accuracy: 0.7695\n",
      "Epoch 284/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8328 - val_loss: 0.5413 - val_accuracy: 0.7572\n",
      "Epoch 285/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4495 - accuracy: 0.8173 - val_loss: 0.7296 - val_accuracy: 0.5885\n",
      "Epoch 286/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5597 - accuracy: 0.6760 - val_loss: 0.5944 - val_accuracy: 0.6502\n",
      "Epoch 287/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4646 - accuracy: 0.7905 - val_loss: 0.5329 - val_accuracy: 0.7654\n",
      "Epoch 288/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4343 - accuracy: 0.8225 - val_loss: 0.5701 - val_accuracy: 0.7325\n",
      "Epoch 289/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4404 - accuracy: 0.8328 - val_loss: 0.5227 - val_accuracy: 0.7778\n",
      "Epoch 290/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7100 - val_loss: 0.8111 - val_accuracy: 0.5638\n",
      "Epoch 291/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5269 - accuracy: 0.7214 - val_loss: 0.5520 - val_accuracy: 0.7078\n",
      "Epoch 292/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4733 - accuracy: 0.7709 - val_loss: 0.5840 - val_accuracy: 0.7202\n",
      "Epoch 293/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.8256 - val_loss: 0.5409 - val_accuracy: 0.7654\n",
      "Epoch 294/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4880 - accuracy: 0.7657 - val_loss: 0.5908 - val_accuracy: 0.6420\n",
      "Epoch 295/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.7781 - val_loss: 0.5639 - val_accuracy: 0.7366\n",
      "Epoch 296/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4235 - accuracy: 0.8442 - val_loss: 0.5239 - val_accuracy: 0.7695\n",
      "Epoch 297/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4208 - accuracy: 0.8452 - val_loss: 0.5258 - val_accuracy: 0.7695\n",
      "Epoch 298/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8442 - val_loss: 0.5262 - val_accuracy: 0.7490\n",
      "Epoch 299/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4609 - accuracy: 0.7781 - val_loss: 0.6120 - val_accuracy: 0.7078\n",
      "Epoch 300/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4614 - accuracy: 0.7915 - val_loss: 0.5501 - val_accuracy: 0.7037\n",
      "Epoch 301/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.5120 - accuracy: 0.7317 - val_loss: 0.5893 - val_accuracy: 0.7119\n",
      "Epoch 302/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8019 - val_loss: 0.5503 - val_accuracy: 0.7572\n",
      "Epoch 303/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.8029 - val_loss: 0.5090 - val_accuracy: 0.7901\n",
      "Epoch 304/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.4173 - accuracy: 0.8266 - val_loss: 0.5199 - val_accuracy: 0.7366\n",
      "Epoch 305/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4206 - accuracy: 0.8380 - val_loss: 0.5143 - val_accuracy: 0.7819\n",
      "Epoch 306/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4068 - accuracy: 0.8514 - val_loss: 0.5017 - val_accuracy: 0.7819\n",
      "Epoch 307/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.8442 - val_loss: 0.5124 - val_accuracy: 0.7860\n",
      "Epoch 308/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.7616 - val_loss: 0.5774 - val_accuracy: 0.6502\n",
      "Epoch 309/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5066 - accuracy: 0.7203 - val_loss: 0.6006 - val_accuracy: 0.6996\n",
      "Epoch 310/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4220 - accuracy: 0.8473 - val_loss: 0.4970 - val_accuracy: 0.7901\n",
      "Epoch 311/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4092 - accuracy: 0.8473 - val_loss: 0.5253 - val_accuracy: 0.7860\n",
      "Epoch 312/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4076 - accuracy: 0.8380 - val_loss: 0.5084 - val_accuracy: 0.7490\n",
      "Epoch 313/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4452 - accuracy: 0.7884 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
      "Epoch 314/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4608 - accuracy: 0.7699 - val_loss: 0.5263 - val_accuracy: 0.7119\n",
      "Epoch 315/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4319 - accuracy: 0.8091 - val_loss: 0.6682 - val_accuracy: 0.6379\n",
      "Epoch 316/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4640 - accuracy: 0.7709 - val_loss: 0.4989 - val_accuracy: 0.7942\n",
      "Epoch 317/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8658 - val_loss: 0.5093 - val_accuracy: 0.8025\n",
      "Epoch 318/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3924 - accuracy: 0.8617 - val_loss: 0.5305 - val_accuracy: 0.7737\n",
      "Epoch 319/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.8008 - val_loss: 0.5239 - val_accuracy: 0.7119\n",
      "Epoch 320/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4383 - accuracy: 0.7802 - val_loss: 0.5533 - val_accuracy: 0.7407\n",
      "Epoch 321/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4164 - accuracy: 0.8225 - val_loss: 0.4985 - val_accuracy: 0.7613\n",
      "Epoch 322/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4020 - accuracy: 0.8421 - val_loss: 0.5610 - val_accuracy: 0.7407\n",
      "Epoch 323/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3788 - accuracy: 0.8607 - val_loss: 0.4918 - val_accuracy: 0.8025\n",
      "Epoch 324/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3740 - accuracy: 0.8731 - val_loss: 0.4766 - val_accuracy: 0.8148\n",
      "Epoch 325/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4400 - accuracy: 0.7822 - val_loss: 0.8251 - val_accuracy: 0.5679\n",
      "Epoch 326/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4910 - accuracy: 0.7616 - val_loss: 0.4985 - val_accuracy: 0.7613\n",
      "Epoch 327/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.7647 - val_loss: 0.5749 - val_accuracy: 0.7243\n",
      "Epoch 328/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4022 - accuracy: 0.8338 - val_loss: 0.4720 - val_accuracy: 0.8148\n",
      "Epoch 329/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8535 - val_loss: 0.5304 - val_accuracy: 0.7078\n",
      "Epoch 330/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4192 - accuracy: 0.8225 - val_loss: 0.4944 - val_accuracy: 0.8025\n",
      "Epoch 331/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3677 - accuracy: 0.8803 - val_loss: 0.4951 - val_accuracy: 0.8107\n",
      "Epoch 332/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3971 - accuracy: 0.8390 - val_loss: 0.5203 - val_accuracy: 0.7160\n",
      "Epoch 333/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4122 - accuracy: 0.8184 - val_loss: 0.5900 - val_accuracy: 0.7284\n",
      "Epoch 334/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.8586 - val_loss: 0.4682 - val_accuracy: 0.8066\n",
      "Epoch 335/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3743 - accuracy: 0.8638 - val_loss: 0.4970 - val_accuracy: 0.7325\n",
      "Epoch 336/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4614 - accuracy: 0.7585 - val_loss: 0.5712 - val_accuracy: 0.7490\n",
      "Epoch 337/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4600 - accuracy: 0.7637 - val_loss: 0.4723 - val_accuracy: 0.8025\n",
      "Epoch 338/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3981 - accuracy: 0.8442 - val_loss: 0.4607 - val_accuracy: 0.8313\n",
      "Epoch 339/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3847 - accuracy: 0.8535 - val_loss: 0.4959 - val_accuracy: 0.7942\n",
      "Epoch 340/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3557 - accuracy: 0.8824 - val_loss: 0.4644 - val_accuracy: 0.8272\n",
      "Epoch 341/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3516 - accuracy: 0.8865 - val_loss: 0.4533 - val_accuracy: 0.8313\n",
      "Epoch 342/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3596 - accuracy: 0.8689 - val_loss: 0.5324 - val_accuracy: 0.7490\n",
      "Epoch 343/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4445 - accuracy: 0.7833 - val_loss: 0.5438 - val_accuracy: 0.6955\n",
      "Epoch 344/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3892 - accuracy: 0.8431 - val_loss: 0.4620 - val_accuracy: 0.8272\n",
      "Epoch 345/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3442 - accuracy: 0.8875 - val_loss: 0.4518 - val_accuracy: 0.8230\n",
      "Epoch 346/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8318 - val_loss: 0.5637 - val_accuracy: 0.7449\n",
      "Epoch 347/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3434 - accuracy: 0.8813 - val_loss: 0.5213 - val_accuracy: 0.7737\n",
      "Epoch 348/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3797 - accuracy: 0.8318 - val_loss: 0.4909 - val_accuracy: 0.7366\n",
      "Epoch 349/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3506 - accuracy: 0.8689 - val_loss: 0.4471 - val_accuracy: 0.8272\n",
      "Epoch 350/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8586 - val_loss: 0.4682 - val_accuracy: 0.7531\n",
      "Epoch 351/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3715 - accuracy: 0.8266 - val_loss: 0.5498 - val_accuracy: 0.7490\n",
      "Epoch 352/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4012 - accuracy: 0.8101 - val_loss: 0.4379 - val_accuracy: 0.8395\n",
      "Epoch 353/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3609 - accuracy: 0.8586 - val_loss: 0.5168 - val_accuracy: 0.7778\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3449 - accuracy: 0.8679 - val_loss: 0.4395 - val_accuracy: 0.8313\n",
      "Epoch 355/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4282 - accuracy: 0.7884 - val_loss: 0.6455 - val_accuracy: 0.6996\n",
      "Epoch 356/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3735 - accuracy: 0.8462 - val_loss: 0.4703 - val_accuracy: 0.8230\n",
      "Epoch 357/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.8999 - val_loss: 0.4639 - val_accuracy: 0.8230\n",
      "Epoch 358/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3905 - accuracy: 0.8287 - val_loss: 0.5914 - val_accuracy: 0.6420\n",
      "Epoch 359/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3956 - accuracy: 0.8029 - val_loss: 0.4657 - val_accuracy: 0.8189\n",
      "Epoch 360/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8772 - val_loss: 0.4326 - val_accuracy: 0.8148\n",
      "Epoch 361/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8782 - val_loss: 0.4743 - val_accuracy: 0.7366\n",
      "Epoch 362/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3372 - accuracy: 0.8638 - val_loss: 0.4416 - val_accuracy: 0.8395\n",
      "Epoch 363/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3181 - accuracy: 0.9020 - val_loss: 0.4788 - val_accuracy: 0.7366\n",
      "Epoch 364/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3975 - accuracy: 0.7988 - val_loss: 0.6087 - val_accuracy: 0.7078\n",
      "Epoch 365/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4054 - accuracy: 0.8050 - val_loss: 0.4257 - val_accuracy: 0.8477\n",
      "Epoch 366/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3343 - accuracy: 0.8772 - val_loss: 0.4587 - val_accuracy: 0.8230\n",
      "Epoch 367/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3062 - accuracy: 0.9205 - val_loss: 0.4161 - val_accuracy: 0.8477\n",
      "Epoch 368/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3346 - accuracy: 0.8700 - val_loss: 0.5011 - val_accuracy: 0.7901\n",
      "Epoch 369/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3834 - accuracy: 0.8173 - val_loss: 0.4185 - val_accuracy: 0.8601\n",
      "Epoch 370/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.8772 - val_loss: 0.5027 - val_accuracy: 0.7860\n",
      "Epoch 371/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3680 - accuracy: 0.8431 - val_loss: 0.4602 - val_accuracy: 0.7531\n",
      "Epoch 372/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3248 - accuracy: 0.8782 - val_loss: 0.4195 - val_accuracy: 0.8560\n",
      "Epoch 373/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3117 - accuracy: 0.8989 - val_loss: 0.4091 - val_accuracy: 0.8477\n",
      "Epoch 374/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8596 - val_loss: 0.6670 - val_accuracy: 0.6872\n",
      "Epoch 375/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3767 - accuracy: 0.8194 - val_loss: 0.4155 - val_accuracy: 0.8354\n",
      "Epoch 376/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3483 - accuracy: 0.8483 - val_loss: 0.5155 - val_accuracy: 0.7572\n",
      "Epoch 377/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.9009 - val_loss: 0.4626 - val_accuracy: 0.8148\n",
      "Epoch 378/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3033 - accuracy: 0.8927 - val_loss: 0.4788 - val_accuracy: 0.8066\n",
      "Epoch 379/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2906 - accuracy: 0.9020 - val_loss: 0.3942 - val_accuracy: 0.8724\n",
      "Epoch 380/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3101 - accuracy: 0.8854 - val_loss: 0.5828 - val_accuracy: 0.7407\n",
      "Epoch 381/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3660 - accuracy: 0.8359 - val_loss: 0.5036 - val_accuracy: 0.7160\n",
      "Epoch 382/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4829 - accuracy: 0.7451 - val_loss: 0.4927 - val_accuracy: 0.8066\n",
      "Epoch 383/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2979 - accuracy: 0.9154 - val_loss: 0.3971 - val_accuracy: 0.8765\n",
      "Epoch 384/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2868 - accuracy: 0.9185 - val_loss: 0.4121 - val_accuracy: 0.8724\n",
      "Epoch 385/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2815 - accuracy: 0.9319 - val_loss: 0.4083 - val_accuracy: 0.8807\n",
      "Epoch 386/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2780 - accuracy: 0.9226 - val_loss: 0.4599 - val_accuracy: 0.8107\n",
      "Epoch 387/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4291 - accuracy: 0.7915 - val_loss: 0.4538 - val_accuracy: 0.7778\n",
      "Epoch 388/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3252 - accuracy: 0.8803 - val_loss: 0.4008 - val_accuracy: 0.8724\n",
      "Epoch 389/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2845 - accuracy: 0.9164 - val_loss: 0.4810 - val_accuracy: 0.8025\n",
      "Epoch 390/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2860 - accuracy: 0.9123 - val_loss: 0.3904 - val_accuracy: 0.8765\n",
      "Epoch 391/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2735 - accuracy: 0.9257 - val_loss: 0.4708 - val_accuracy: 0.8066\n",
      "Epoch 392/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4151 - accuracy: 0.8019 - val_loss: 0.5227 - val_accuracy: 0.7037\n",
      "Epoch 393/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8555 - val_loss: 0.4394 - val_accuracy: 0.8354\n",
      "Epoch 394/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2849 - accuracy: 0.9154 - val_loss: 0.3805 - val_accuracy: 0.8930\n",
      "Epoch 395/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2808 - accuracy: 0.9112 - val_loss: 0.6091 - val_accuracy: 0.7078\n",
      "Epoch 396/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3308 - accuracy: 0.8596 - val_loss: 0.4046 - val_accuracy: 0.8148\n",
      "Epoch 397/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4452 - accuracy: 0.7740 - val_loss: 0.6904 - val_accuracy: 0.6708\n",
      "Epoch 398/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3499 - accuracy: 0.8607 - val_loss: 0.3798 - val_accuracy: 0.8848\n",
      "Epoch 399/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3035 - accuracy: 0.8896 - val_loss: 0.4457 - val_accuracy: 0.8272\n",
      "Epoch 400/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2757 - accuracy: 0.9278 - val_loss: 0.3902 - val_accuracy: 0.8930\n",
      "Epoch 401/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2600 - accuracy: 0.9298 - val_loss: 0.4050 - val_accuracy: 0.8724\n",
      "Epoch 402/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2663 - accuracy: 0.9329 - val_loss: 0.3893 - val_accuracy: 0.8354\n",
      "Epoch 403/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3610 - accuracy: 0.8328 - val_loss: 0.4821 - val_accuracy: 0.8025\n",
      "Epoch 404/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2779 - accuracy: 0.9185 - val_loss: 0.4384 - val_accuracy: 0.7325\n",
      "Epoch 405/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2838 - accuracy: 0.8989 - val_loss: 0.3839 - val_accuracy: 0.8971\n",
      "Epoch 406/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2640 - accuracy: 0.9247 - val_loss: 0.3735 - val_accuracy: 0.8477\n",
      "Epoch 407/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.3544 - accuracy: 0.8431 - val_loss: 0.8019 - val_accuracy: 0.6296\n",
      "Epoch 408/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.3879 - accuracy: 0.8277 - val_loss: 0.3644 - val_accuracy: 0.9095\n",
      "Epoch 409/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2521 - accuracy: 0.9370 - val_loss: 0.3604 - val_accuracy: 0.9012\n",
      "Epoch 410/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2503 - accuracy: 0.9360 - val_loss: 0.3562 - val_accuracy: 0.8971\n",
      "Epoch 411/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.9257 - val_loss: 0.3622 - val_accuracy: 0.8765\n",
      "Epoch 412/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2844 - accuracy: 0.8854 - val_loss: 0.4667 - val_accuracy: 0.8025\n",
      "Epoch 413/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3180 - accuracy: 0.8493 - val_loss: 0.4443 - val_accuracy: 0.7325\n",
      "Epoch 414/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5052 - accuracy: 0.7255 - val_loss: 0.5819 - val_accuracy: 0.7284\n",
      "Epoch 415/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2775 - accuracy: 0.9164 - val_loss: 0.3635 - val_accuracy: 0.9095\n",
      "Epoch 416/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2565 - accuracy: 0.9340 - val_loss: 0.3685 - val_accuracy: 0.9053\n",
      "Epoch 417/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2502 - accuracy: 0.9288 - val_loss: 0.3581 - val_accuracy: 0.9095\n",
      "Epoch 418/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2402 - accuracy: 0.9370 - val_loss: 0.3707 - val_accuracy: 0.9012\n",
      "Epoch 419/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2400 - accuracy: 0.9443 - val_loss: 0.3523 - val_accuracy: 0.9095\n",
      "Epoch 420/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2313 - accuracy: 0.9412 - val_loss: 0.3648 - val_accuracy: 0.8971\n",
      "Epoch 421/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2845 - accuracy: 0.8885 - val_loss: 0.5160 - val_accuracy: 0.7037\n",
      "Epoch 422/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.7957 - val_loss: 0.4050 - val_accuracy: 0.8642\n",
      "Epoch 423/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2521 - accuracy: 0.9319 - val_loss: 0.3466 - val_accuracy: 0.9136\n",
      "Epoch 424/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2367 - accuracy: 0.9350 - val_loss: 0.3444 - val_accuracy: 0.9053\n",
      "Epoch 425/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2312 - accuracy: 0.9370 - val_loss: 0.4412 - val_accuracy: 0.8230\n",
      "Epoch 426/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2685 - accuracy: 0.8989 - val_loss: 0.3712 - val_accuracy: 0.8354\n",
      "Epoch 427/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3895 - accuracy: 0.8039 - val_loss: 0.6378 - val_accuracy: 0.6914\n",
      "Epoch 428/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3102 - accuracy: 0.8669 - val_loss: 0.3392 - val_accuracy: 0.9136\n",
      "Epoch 429/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2320 - accuracy: 0.9443 - val_loss: 0.3578 - val_accuracy: 0.9053\n",
      "Epoch 430/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2211 - accuracy: 0.9494 - val_loss: 0.3442 - val_accuracy: 0.9095\n",
      "Epoch 431/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2267 - accuracy: 0.9360 - val_loss: 0.3903 - val_accuracy: 0.8765\n",
      "Epoch 432/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2263 - accuracy: 0.9401 - val_loss: 0.3364 - val_accuracy: 0.9053\n",
      "Epoch 433/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2302 - accuracy: 0.9319 - val_loss: 0.5531 - val_accuracy: 0.7654\n",
      "Epoch 434/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3738 - accuracy: 0.8235 - val_loss: 0.3909 - val_accuracy: 0.8395\n",
      "Epoch 435/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2629 - accuracy: 0.8989 - val_loss: 0.4227 - val_accuracy: 0.8519\n",
      "Epoch 436/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2310 - accuracy: 0.9412 - val_loss: 0.3358 - val_accuracy: 0.9136\n",
      "Epoch 437/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2099 - accuracy: 0.9505 - val_loss: 0.3390 - val_accuracy: 0.9095\n",
      "Epoch 438/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2374 - accuracy: 0.9257 - val_loss: 0.4819 - val_accuracy: 0.7984\n",
      "Epoch 439/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2386 - accuracy: 0.9309 - val_loss: 0.3513 - val_accuracy: 0.8560\n",
      "Epoch 440/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2905 - accuracy: 0.8679 - val_loss: 0.6032 - val_accuracy: 0.7202\n",
      "Epoch 441/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2815 - accuracy: 0.8772 - val_loss: 0.3255 - val_accuracy: 0.9095\n",
      "Epoch 442/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2260 - accuracy: 0.9319 - val_loss: 0.3486 - val_accuracy: 0.9053\n",
      "Epoch 443/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2070 - accuracy: 0.9484 - val_loss: 0.3308 - val_accuracy: 0.9136\n",
      "Epoch 444/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2142 - accuracy: 0.9422 - val_loss: 0.4217 - val_accuracy: 0.8436\n",
      "Epoch 445/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2420 - accuracy: 0.9236 - val_loss: 0.3824 - val_accuracy: 0.8148\n",
      "Epoch 446/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4906 - accuracy: 0.7575 - val_loss: 0.7103 - val_accuracy: 0.6790\n",
      "Epoch 447/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2657 - accuracy: 0.9082 - val_loss: 0.3263 - val_accuracy: 0.9300\n",
      "Epoch 448/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2301 - accuracy: 0.9298 - val_loss: 0.3400 - val_accuracy: 0.9095\n",
      "Epoch 449/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2149 - accuracy: 0.9381 - val_loss: 0.3562 - val_accuracy: 0.8971\n",
      "Epoch 450/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2042 - accuracy: 0.9484 - val_loss: 0.3481 - val_accuracy: 0.9053\n",
      "Epoch 451/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1944 - accuracy: 0.9567 - val_loss: 0.3531 - val_accuracy: 0.9012\n",
      "Epoch 452/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1949 - accuracy: 0.9546 - val_loss: 0.3093 - val_accuracy: 0.9383\n",
      "Epoch 453/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1939 - accuracy: 0.9536 - val_loss: 0.4303 - val_accuracy: 0.8354\n",
      "Epoch 454/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2521 - accuracy: 0.9071 - val_loss: 0.4156 - val_accuracy: 0.7531\n",
      "Epoch 455/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7286 - val_loss: 0.3815 - val_accuracy: 0.8765\n",
      "Epoch 456/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2106 - accuracy: 0.9474 - val_loss: 0.3446 - val_accuracy: 0.9053\n",
      "Epoch 457/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1970 - accuracy: 0.9556 - val_loss: 0.3502 - val_accuracy: 0.9095\n",
      "Epoch 458/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1939 - accuracy: 0.9577 - val_loss: 0.3836 - val_accuracy: 0.8765\n",
      "Epoch 459/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2111 - accuracy: 0.9432 - val_loss: 0.3029 - val_accuracy: 0.9136\n",
      "Epoch 460/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2079 - accuracy: 0.9422 - val_loss: 0.4398 - val_accuracy: 0.8436\n",
      "Epoch 461/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1949 - accuracy: 0.9505 - val_loss: 0.3042 - val_accuracy: 0.9259\n",
      "Epoch 462/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2038 - accuracy: 0.9391 - val_loss: 0.4363 - val_accuracy: 0.8354\n",
      "Epoch 463/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9185 - val_loss: 0.3900 - val_accuracy: 0.8066\n",
      "Epoch 464/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2998 - accuracy: 0.8545 - val_loss: 0.6222 - val_accuracy: 0.7243\n",
      "Epoch 465/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9020 - val_loss: 0.3052 - val_accuracy: 0.9095\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1882 - accuracy: 0.9556 - val_loss: 0.3299 - val_accuracy: 0.9095\n",
      "Epoch 467/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1763 - accuracy: 0.9628 - val_loss: 0.3184 - val_accuracy: 0.9218\n",
      "Epoch 468/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2033 - accuracy: 0.9453 - val_loss: 0.4843 - val_accuracy: 0.7942\n",
      "Epoch 469/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3198 - accuracy: 0.8462 - val_loss: 0.4982 - val_accuracy: 0.7160\n",
      "Epoch 470/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3044 - accuracy: 0.8566 - val_loss: 0.3660 - val_accuracy: 0.8930\n",
      "Epoch 471/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1829 - accuracy: 0.9556 - val_loss: 0.3571 - val_accuracy: 0.8930\n",
      "Epoch 472/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1797 - accuracy: 0.9577 - val_loss: 0.3876 - val_accuracy: 0.8765\n",
      "Epoch 473/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1934 - accuracy: 0.9453 - val_loss: 0.3002 - val_accuracy: 0.9342\n",
      "Epoch 474/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1726 - accuracy: 0.9587 - val_loss: 0.3139 - val_accuracy: 0.9136\n",
      "Epoch 475/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1665 - accuracy: 0.9598 - val_loss: 0.3057 - val_accuracy: 0.9300\n",
      "Epoch 476/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1691 - accuracy: 0.9587 - val_loss: 0.4534 - val_accuracy: 0.8354\n",
      "Epoch 477/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2471 - accuracy: 0.8885 - val_loss: 0.3403 - val_accuracy: 0.8436\n",
      "Epoch 478/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1930 - accuracy: 0.9401 - val_loss: 0.3443 - val_accuracy: 0.8930\n",
      "Epoch 479/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1646 - accuracy: 0.9598 - val_loss: 0.2986 - val_accuracy: 0.9342\n",
      "Epoch 480/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1711 - accuracy: 0.9567 - val_loss: 0.2842 - val_accuracy: 0.9424\n",
      "Epoch 481/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1582 - accuracy: 0.9639 - val_loss: 0.2988 - val_accuracy: 0.9300\n",
      "Epoch 482/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1581 - accuracy: 0.9608 - val_loss: 0.2818 - val_accuracy: 0.9465\n",
      "Epoch 483/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.9567 - val_loss: 0.5386 - val_accuracy: 0.7819\n",
      "Epoch 484/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4699 - accuracy: 0.7668 - val_loss: 0.5268 - val_accuracy: 0.7078\n",
      "Epoch 485/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2980 - accuracy: 0.8514 - val_loss: 0.3488 - val_accuracy: 0.9012\n",
      "Epoch 486/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1701 - accuracy: 0.9608 - val_loss: 0.2810 - val_accuracy: 0.9465\n",
      "Epoch 487/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1685 - accuracy: 0.9577 - val_loss: 0.2733 - val_accuracy: 0.9342\n",
      "Epoch 488/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1604 - accuracy: 0.9639 - val_loss: 0.3179 - val_accuracy: 0.9095\n",
      "Epoch 489/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1683 - accuracy: 0.9587 - val_loss: 0.2870 - val_accuracy: 0.9053\n",
      "Epoch 490/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9133 - val_loss: 0.4760 - val_accuracy: 0.8189\n",
      "Epoch 491/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2108 - accuracy: 0.9329 - val_loss: 0.2791 - val_accuracy: 0.9300\n",
      "Epoch 492/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1601 - accuracy: 0.9577 - val_loss: 0.2785 - val_accuracy: 0.9259\n",
      "Epoch 493/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1677 - accuracy: 0.9598 - val_loss: 0.2913 - val_accuracy: 0.9218\n",
      "Epoch 494/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1758 - accuracy: 0.9494 - val_loss: 0.2733 - val_accuracy: 0.9177\n",
      "Epoch 495/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2085 - accuracy: 0.9205 - val_loss: 0.4025 - val_accuracy: 0.8765\n",
      "Epoch 496/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1589 - accuracy: 0.9659 - val_loss: 0.3296 - val_accuracy: 0.9053\n",
      "Epoch 497/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1459 - accuracy: 0.9680 - val_loss: 0.3682 - val_accuracy: 0.8848\n",
      "Epoch 498/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1644 - accuracy: 0.9567 - val_loss: 0.2834 - val_accuracy: 0.9053\n",
      "Epoch 499/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4258 - accuracy: 0.7988 - val_loss: 0.6573 - val_accuracy: 0.7366\n",
      "Epoch 500/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2405 - accuracy: 0.9071 - val_loss: 0.2776 - val_accuracy: 0.9424\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sleepy       0.94      0.94      0.94       152\n",
      "    vigilant       0.94      0.94      0.94       151\n",
      "\n",
      "    accuracy                           0.94       303\n",
      "   macro avg       0.94      0.94      0.94       303\n",
      "weighted avg       0.94      0.94      0.94       303\n",
      "\n",
      "[INFO] compiling model fold2.....\n",
      "[INFO] training network...\n",
      "(969, 28, 28, 1) (303, 28, 28, 1) (969, 2) (303, 2)\n",
      "Train on 969 samples, validate on 243 samples\n",
      "Epoch 1/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6921 - accuracy: 0.5036 - val_loss: 0.6933 - val_accuracy: 0.4733\n",
      "Epoch 2/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6913 - accuracy: 0.5057 - val_loss: 0.6927 - val_accuracy: 0.4733\n",
      "Epoch 3/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6906 - accuracy: 0.5057 - val_loss: 0.6923 - val_accuracy: 0.4733\n",
      "Epoch 4/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6899 - accuracy: 0.5057 - val_loss: 0.6918 - val_accuracy: 0.4733\n",
      "Epoch 5/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5077 - val_loss: 0.6915 - val_accuracy: 0.4733\n",
      "Epoch 6/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5057 - val_loss: 0.6910 - val_accuracy: 0.4815\n",
      "Epoch 7/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6883 - accuracy: 0.5057 - val_loss: 0.6904 - val_accuracy: 0.4897\n",
      "Epoch 8/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5077 - val_loss: 0.6900 - val_accuracy: 0.4897\n",
      "Epoch 9/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6876 - accuracy: 0.5077 - val_loss: 0.6896 - val_accuracy: 0.4897\n",
      "Epoch 10/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5129 - val_loss: 0.6892 - val_accuracy: 0.4897\n",
      "Epoch 11/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5150 - val_loss: 0.6888 - val_accuracy: 0.4856\n",
      "Epoch 12/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5232 - val_loss: 0.6885 - val_accuracy: 0.4897\n",
      "Epoch 13/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5253 - val_loss: 0.6880 - val_accuracy: 0.4897\n",
      "Epoch 14/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.5212 - val_loss: 0.6875 - val_accuracy: 0.4897\n",
      "Epoch 15/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5387 - val_loss: 0.6871 - val_accuracy: 0.4938\n",
      "Epoch 16/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5315 - val_loss: 0.6866 - val_accuracy: 0.5144\n",
      "Epoch 17/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6835 - accuracy: 0.5645 - val_loss: 0.6864 - val_accuracy: 0.4938\n",
      "Epoch 18/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6829 - accuracy: 0.5366 - val_loss: 0.6858 - val_accuracy: 0.5309\n",
      "Epoch 19/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6825 - accuracy: 0.5645 - val_loss: 0.6854 - val_accuracy: 0.5391\n",
      "Epoch 20/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6819 - accuracy: 0.5655 - val_loss: 0.6849 - val_accuracy: 0.5514\n",
      "Epoch 21/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6815 - accuracy: 0.5759 - val_loss: 0.6845 - val_accuracy: 0.5638\n",
      "Epoch 22/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5810 - val_loss: 0.6841 - val_accuracy: 0.5638\n",
      "Epoch 23/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6806 - accuracy: 0.5769 - val_loss: 0.6836 - val_accuracy: 0.5761\n",
      "Epoch 24/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6801 - accuracy: 0.5934 - val_loss: 0.6830 - val_accuracy: 0.5967\n",
      "Epoch 25/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6799 - accuracy: 0.5913 - val_loss: 0.6827 - val_accuracy: 0.5844\n",
      "Epoch 26/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6791 - accuracy: 0.6017 - val_loss: 0.6822 - val_accuracy: 0.5926\n",
      "Epoch 27/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6788 - accuracy: 0.5965 - val_loss: 0.6817 - val_accuracy: 0.6008\n",
      "Epoch 28/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6781 - accuracy: 0.6017 - val_loss: 0.6812 - val_accuracy: 0.5967\n",
      "Epoch 29/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5924 - val_loss: 0.6809 - val_accuracy: 0.5967\n",
      "Epoch 30/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6771 - accuracy: 0.5996 - val_loss: 0.6806 - val_accuracy: 0.6008\n",
      "Epoch 31/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6766 - accuracy: 0.6006 - val_loss: 0.6799 - val_accuracy: 0.6091\n",
      "Epoch 32/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6765 - accuracy: 0.5851 - val_loss: 0.6794 - val_accuracy: 0.5926\n",
      "Epoch 33/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6761 - accuracy: 0.5955 - val_loss: 0.6788 - val_accuracy: 0.6049\n",
      "Epoch 34/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6752 - accuracy: 0.5841 - val_loss: 0.6787 - val_accuracy: 0.5967\n",
      "Epoch 35/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6747 - accuracy: 0.5893 - val_loss: 0.6785 - val_accuracy: 0.6049\n",
      "Epoch 36/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6741 - accuracy: 0.5903 - val_loss: 0.6778 - val_accuracy: 0.5926\n",
      "Epoch 37/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6738 - accuracy: 0.5903 - val_loss: 0.6779 - val_accuracy: 0.6049\n",
      "Epoch 38/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6734 - accuracy: 0.5986 - val_loss: 0.6775 - val_accuracy: 0.6008\n",
      "Epoch 39/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6726 - accuracy: 0.6058 - val_loss: 0.6766 - val_accuracy: 0.5885\n",
      "Epoch 40/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.5862 - val_loss: 0.6764 - val_accuracy: 0.6008\n",
      "Epoch 41/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6715 - accuracy: 0.5913 - val_loss: 0.6758 - val_accuracy: 0.5926\n",
      "Epoch 42/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.5831 - val_loss: 0.6753 - val_accuracy: 0.5967\n",
      "Epoch 43/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6708 - accuracy: 0.5872 - val_loss: 0.6747 - val_accuracy: 0.6091\n",
      "Epoch 44/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6703 - accuracy: 0.5862 - val_loss: 0.6740 - val_accuracy: 0.6049\n",
      "Epoch 45/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6695 - accuracy: 0.5986 - val_loss: 0.6736 - val_accuracy: 0.6008\n",
      "Epoch 46/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.5955 - val_loss: 0.6732 - val_accuracy: 0.6008\n",
      "Epoch 47/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6683 - accuracy: 0.6027 - val_loss: 0.6731 - val_accuracy: 0.6049\n",
      "Epoch 48/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6680 - accuracy: 0.5893 - val_loss: 0.6728 - val_accuracy: 0.6049\n",
      "Epoch 49/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6672 - accuracy: 0.5903 - val_loss: 0.6723 - val_accuracy: 0.6049\n",
      "Epoch 50/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6668 - accuracy: 0.5831 - val_loss: 0.6714 - val_accuracy: 0.6008\n",
      "Epoch 51/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6667 - accuracy: 0.5944 - val_loss: 0.6711 - val_accuracy: 0.6008\n",
      "Epoch 52/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6657 - accuracy: 0.5944 - val_loss: 0.6709 - val_accuracy: 0.6049\n",
      "Epoch 53/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6651 - accuracy: 0.5944 - val_loss: 0.6703 - val_accuracy: 0.6049\n",
      "Epoch 54/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.5924 - val_loss: 0.6700 - val_accuracy: 0.6008\n",
      "Epoch 55/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.5996 - val_loss: 0.6694 - val_accuracy: 0.6008\n",
      "Epoch 56/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6636 - accuracy: 0.6047 - val_loss: 0.6692 - val_accuracy: 0.6008\n",
      "Epoch 57/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6630 - accuracy: 0.5944 - val_loss: 0.6693 - val_accuracy: 0.5967\n",
      "Epoch 58/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6628 - accuracy: 0.5955 - val_loss: 0.6690 - val_accuracy: 0.5967\n",
      "Epoch 59/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.5955 - val_loss: 0.6689 - val_accuracy: 0.6091\n",
      "Epoch 60/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6619 - accuracy: 0.5955 - val_loss: 0.6677 - val_accuracy: 0.6008\n",
      "Epoch 61/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6609 - accuracy: 0.5996 - val_loss: 0.6672 - val_accuracy: 0.6008\n",
      "Epoch 62/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6608 - accuracy: 0.5975 - val_loss: 0.6666 - val_accuracy: 0.6049\n",
      "Epoch 63/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6601 - accuracy: 0.6047 - val_loss: 0.6667 - val_accuracy: 0.5967\n",
      "Epoch 64/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6600 - accuracy: 0.5955 - val_loss: 0.6658 - val_accuracy: 0.6049\n",
      "Epoch 65/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6594 - accuracy: 0.6027 - val_loss: 0.6653 - val_accuracy: 0.6214\n",
      "Epoch 66/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6587 - accuracy: 0.6068 - val_loss: 0.6658 - val_accuracy: 0.6049\n",
      "Epoch 67/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6583 - accuracy: 0.6006 - val_loss: 0.6647 - val_accuracy: 0.6008\n",
      "Epoch 68/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6576 - accuracy: 0.6017 - val_loss: 0.6645 - val_accuracy: 0.6091\n",
      "Epoch 69/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6572 - accuracy: 0.6047 - val_loss: 0.6640 - val_accuracy: 0.6091\n",
      "Epoch 70/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6569 - accuracy: 0.6058 - val_loss: 0.6635 - val_accuracy: 0.6337\n",
      "Epoch 71/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6566 - accuracy: 0.6017 - val_loss: 0.6630 - val_accuracy: 0.6379\n",
      "Epoch 72/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6161 - val_loss: 0.6630 - val_accuracy: 0.6049\n",
      "Epoch 73/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6047 - val_loss: 0.6628 - val_accuracy: 0.6049\n",
      "Epoch 74/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.6027 - val_loss: 0.6622 - val_accuracy: 0.6173\n",
      "Epoch 75/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6130 - val_loss: 0.6622 - val_accuracy: 0.6049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6540 - accuracy: 0.6037 - val_loss: 0.6615 - val_accuracy: 0.6255\n",
      "Epoch 77/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6537 - accuracy: 0.6109 - val_loss: 0.6619 - val_accuracy: 0.6091\n",
      "Epoch 78/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6531 - accuracy: 0.6047 - val_loss: 0.6608 - val_accuracy: 0.6296\n",
      "Epoch 79/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6078 - val_loss: 0.6603 - val_accuracy: 0.6420\n",
      "Epoch 80/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6523 - accuracy: 0.6202 - val_loss: 0.6607 - val_accuracy: 0.6091\n",
      "Epoch 81/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6542 - accuracy: 0.6109 - val_loss: 0.6621 - val_accuracy: 0.6091\n",
      "Epoch 82/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6523 - accuracy: 0.5996 - val_loss: 0.6595 - val_accuracy: 0.6379\n",
      "Epoch 83/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6515 - accuracy: 0.6182 - val_loss: 0.6592 - val_accuracy: 0.6296\n",
      "Epoch 84/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6516 - accuracy: 0.6058 - val_loss: 0.6586 - val_accuracy: 0.6461\n",
      "Epoch 85/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6507 - accuracy: 0.6254 - val_loss: 0.6590 - val_accuracy: 0.6132\n",
      "Epoch 86/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6501 - accuracy: 0.6068 - val_loss: 0.6580 - val_accuracy: 0.6461\n",
      "Epoch 87/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6496 - accuracy: 0.6336 - val_loss: 0.6586 - val_accuracy: 0.6091\n",
      "Epoch 88/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6496 - accuracy: 0.6130 - val_loss: 0.6580 - val_accuracy: 0.6173\n",
      "Epoch 89/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6491 - accuracy: 0.6047 - val_loss: 0.6569 - val_accuracy: 0.6420\n",
      "Epoch 90/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6481 - accuracy: 0.6295 - val_loss: 0.6567 - val_accuracy: 0.6337\n",
      "Epoch 91/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6336 - val_loss: 0.6569 - val_accuracy: 0.6214\n",
      "Epoch 92/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6213 - val_loss: 0.6566 - val_accuracy: 0.6214\n",
      "Epoch 93/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6474 - accuracy: 0.6140 - val_loss: 0.6557 - val_accuracy: 0.6337\n",
      "Epoch 94/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6463 - accuracy: 0.6202 - val_loss: 0.6552 - val_accuracy: 0.6420\n",
      "Epoch 95/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6326 - val_loss: 0.6555 - val_accuracy: 0.6337\n",
      "Epoch 96/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6456 - accuracy: 0.6223 - val_loss: 0.6545 - val_accuracy: 0.6502\n",
      "Epoch 97/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6467 - accuracy: 0.6264 - val_loss: 0.6544 - val_accuracy: 0.6296\n",
      "Epoch 98/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6455 - accuracy: 0.6419 - val_loss: 0.6542 - val_accuracy: 0.6420\n",
      "Epoch 99/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6470 - accuracy: 0.6285 - val_loss: 0.6535 - val_accuracy: 0.6420\n",
      "Epoch 100/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6440 - accuracy: 0.6481 - val_loss: 0.6533 - val_accuracy: 0.6543\n",
      "Epoch 101/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6434 - accuracy: 0.6440 - val_loss: 0.6530 - val_accuracy: 0.6543\n",
      "Epoch 102/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6434 - accuracy: 0.6316 - val_loss: 0.6525 - val_accuracy: 0.6461\n",
      "Epoch 103/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6425 - accuracy: 0.6429 - val_loss: 0.6521 - val_accuracy: 0.6543\n",
      "Epoch 104/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6424 - accuracy: 0.6409 - val_loss: 0.6518 - val_accuracy: 0.6461\n",
      "Epoch 105/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6419 - accuracy: 0.6429 - val_loss: 0.6518 - val_accuracy: 0.6543\n",
      "Epoch 106/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6418 - accuracy: 0.6378 - val_loss: 0.6516 - val_accuracy: 0.6543\n",
      "Epoch 107/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6367 - val_loss: 0.6508 - val_accuracy: 0.6420\n",
      "Epoch 108/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6406 - accuracy: 0.6429 - val_loss: 0.6504 - val_accuracy: 0.6461\n",
      "Epoch 109/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6408 - accuracy: 0.6460 - val_loss: 0.6516 - val_accuracy: 0.6420\n",
      "Epoch 110/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6397 - accuracy: 0.6419 - val_loss: 0.6500 - val_accuracy: 0.6543\n",
      "Epoch 111/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6394 - accuracy: 0.6429 - val_loss: 0.6497 - val_accuracy: 0.6420\n",
      "Epoch 112/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6394 - accuracy: 0.6471 - val_loss: 0.6504 - val_accuracy: 0.6502\n",
      "Epoch 113/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6381 - accuracy: 0.6450 - val_loss: 0.6485 - val_accuracy: 0.6420\n",
      "Epoch 114/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6383 - accuracy: 0.6481 - val_loss: 0.6483 - val_accuracy: 0.6543\n",
      "Epoch 115/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6386 - accuracy: 0.6522 - val_loss: 0.6499 - val_accuracy: 0.6461\n",
      "Epoch 116/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6371 - accuracy: 0.6481 - val_loss: 0.6474 - val_accuracy: 0.6502\n",
      "Epoch 117/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6359 - accuracy: 0.6543 - val_loss: 0.6471 - val_accuracy: 0.6543\n",
      "Epoch 118/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6373 - accuracy: 0.6491 - val_loss: 0.6477 - val_accuracy: 0.6584\n",
      "Epoch 119/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6359 - accuracy: 0.6450 - val_loss: 0.6475 - val_accuracy: 0.6584\n",
      "Epoch 120/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6352 - accuracy: 0.6502 - val_loss: 0.6458 - val_accuracy: 0.6461\n",
      "Epoch 121/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6346 - accuracy: 0.6471 - val_loss: 0.6463 - val_accuracy: 0.6667\n",
      "Epoch 122/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6354 - accuracy: 0.6502 - val_loss: 0.6454 - val_accuracy: 0.6626\n",
      "Epoch 123/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6337 - accuracy: 0.6460 - val_loss: 0.6447 - val_accuracy: 0.6502\n",
      "Epoch 124/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6331 - accuracy: 0.6512 - val_loss: 0.6466 - val_accuracy: 0.6626\n",
      "Epoch 125/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6330 - accuracy: 0.6450 - val_loss: 0.6438 - val_accuracy: 0.6584\n",
      "Epoch 126/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6335 - accuracy: 0.6450 - val_loss: 0.6476 - val_accuracy: 0.6502\n",
      "Epoch 127/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6319 - accuracy: 0.6533 - val_loss: 0.6434 - val_accuracy: 0.6584\n",
      "Epoch 128/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6349 - accuracy: 0.6594 - val_loss: 0.6426 - val_accuracy: 0.6584\n",
      "Epoch 129/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6305 - accuracy: 0.6502 - val_loss: 0.6433 - val_accuracy: 0.6749\n",
      "Epoch 130/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6553 - val_loss: 0.6464 - val_accuracy: 0.6543\n",
      "Epoch 131/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6313 - accuracy: 0.6594 - val_loss: 0.6416 - val_accuracy: 0.6584\n",
      "Epoch 132/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6667 - val_loss: 0.6412 - val_accuracy: 0.6502\n",
      "Epoch 133/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6282 - accuracy: 0.6502 - val_loss: 0.6423 - val_accuracy: 0.6626\n",
      "Epoch 134/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6276 - accuracy: 0.6636 - val_loss: 0.6403 - val_accuracy: 0.6502\n",
      "Epoch 135/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6269 - accuracy: 0.6533 - val_loss: 0.6400 - val_accuracy: 0.6626\n",
      "Epoch 136/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6471 - val_loss: 0.6394 - val_accuracy: 0.6502\n",
      "Epoch 137/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6269 - accuracy: 0.6574 - val_loss: 0.6398 - val_accuracy: 0.6749\n",
      "Epoch 138/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6260 - accuracy: 0.6636 - val_loss: 0.6407 - val_accuracy: 0.6584\n",
      "Epoch 139/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6266 - accuracy: 0.6553 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 140/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6249 - accuracy: 0.6739 - val_loss: 0.6386 - val_accuracy: 0.6461\n",
      "Epoch 141/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6257 - accuracy: 0.6698 - val_loss: 0.6368 - val_accuracy: 0.6626\n",
      "Epoch 142/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6261 - accuracy: 0.6584 - val_loss: 0.6365 - val_accuracy: 0.6626\n",
      "Epoch 143/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6248 - accuracy: 0.6594 - val_loss: 0.6363 - val_accuracy: 0.6749\n",
      "Epoch 144/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6223 - accuracy: 0.6605 - val_loss: 0.6377 - val_accuracy: 0.6626\n",
      "Epoch 145/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6265 - accuracy: 0.6512 - val_loss: 0.6353 - val_accuracy: 0.6790\n",
      "Epoch 146/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6224 - accuracy: 0.6636 - val_loss: 0.6352 - val_accuracy: 0.6461\n",
      "Epoch 147/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6210 - accuracy: 0.6636 - val_loss: 0.6340 - val_accuracy: 0.6708\n",
      "Epoch 148/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6197 - accuracy: 0.6605 - val_loss: 0.6347 - val_accuracy: 0.6749\n",
      "Epoch 149/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6205 - accuracy: 0.6729 - val_loss: 0.6336 - val_accuracy: 0.6872\n",
      "Epoch 150/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6188 - accuracy: 0.6656 - val_loss: 0.6356 - val_accuracy: 0.6667\n",
      "Epoch 151/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.6749 - val_loss: 0.6319 - val_accuracy: 0.6708\n",
      "Epoch 152/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6177 - accuracy: 0.6677 - val_loss: 0.6318 - val_accuracy: 0.6502\n",
      "Epoch 153/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6207 - accuracy: 0.6625 - val_loss: 0.6314 - val_accuracy: 0.6831\n",
      "Epoch 154/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6174 - accuracy: 0.6780 - val_loss: 0.6315 - val_accuracy: 0.6790\n",
      "Epoch 155/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6171 - accuracy: 0.6760 - val_loss: 0.6299 - val_accuracy: 0.6872\n",
      "Epoch 156/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6151 - accuracy: 0.6811 - val_loss: 0.6297 - val_accuracy: 0.6790\n",
      "Epoch 157/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6172 - accuracy: 0.6656 - val_loss: 0.6294 - val_accuracy: 0.6790\n",
      "Epoch 158/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6147 - accuracy: 0.6873 - val_loss: 0.6325 - val_accuracy: 0.6543\n",
      "Epoch 159/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6141 - accuracy: 0.6780 - val_loss: 0.6282 - val_accuracy: 0.6790\n",
      "Epoch 160/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6168 - accuracy: 0.6852 - val_loss: 0.6286 - val_accuracy: 0.6831\n",
      "Epoch 161/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6115 - accuracy: 0.6873 - val_loss: 0.6271 - val_accuracy: 0.6708\n",
      "Epoch 162/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6110 - accuracy: 0.6791 - val_loss: 0.6275 - val_accuracy: 0.6872\n",
      "Epoch 163/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6097 - accuracy: 0.6904 - val_loss: 0.6283 - val_accuracy: 0.6955\n",
      "Epoch 164/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6101 - accuracy: 0.6801 - val_loss: 0.6262 - val_accuracy: 0.6790\n",
      "Epoch 165/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6093 - accuracy: 0.6904 - val_loss: 0.6260 - val_accuracy: 0.6872\n",
      "Epoch 166/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6091 - accuracy: 0.6852 - val_loss: 0.6247 - val_accuracy: 0.6667\n",
      "Epoch 167/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6099 - accuracy: 0.6801 - val_loss: 0.6234 - val_accuracy: 0.6831\n",
      "Epoch 168/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6085 - accuracy: 0.6791 - val_loss: 0.6227 - val_accuracy: 0.6831\n",
      "Epoch 169/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6087 - accuracy: 0.6801 - val_loss: 0.6263 - val_accuracy: 0.6914\n",
      "Epoch 170/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6051 - accuracy: 0.6904 - val_loss: 0.6234 - val_accuracy: 0.6914\n",
      "Epoch 171/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6054 - accuracy: 0.6945 - val_loss: 0.6253 - val_accuracy: 0.6461\n",
      "Epoch 172/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6045 - accuracy: 0.6925 - val_loss: 0.6218 - val_accuracy: 0.6872\n",
      "Epoch 173/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6040 - accuracy: 0.6956 - val_loss: 0.6207 - val_accuracy: 0.6831\n",
      "Epoch 174/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6016 - accuracy: 0.6997 - val_loss: 0.6189 - val_accuracy: 0.6872\n",
      "Epoch 175/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6053 - accuracy: 0.6883 - val_loss: 0.6199 - val_accuracy: 0.6790\n",
      "Epoch 176/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5991 - accuracy: 0.6997 - val_loss: 0.6178 - val_accuracy: 0.6831\n",
      "Epoch 177/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6011 - accuracy: 0.7079 - val_loss: 0.6178 - val_accuracy: 0.6831\n",
      "Epoch 178/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5981 - accuracy: 0.6873 - val_loss: 0.6183 - val_accuracy: 0.6914\n",
      "Epoch 179/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5981 - accuracy: 0.6935 - val_loss: 0.6186 - val_accuracy: 0.6914\n",
      "Epoch 180/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5950 - accuracy: 0.7007 - val_loss: 0.6148 - val_accuracy: 0.6914\n",
      "Epoch 181/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5956 - accuracy: 0.6966 - val_loss: 0.6160 - val_accuracy: 0.6872\n",
      "Epoch 182/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5966 - accuracy: 0.6997 - val_loss: 0.6370 - val_accuracy: 0.6173\n",
      "Epoch 183/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6022 - accuracy: 0.6925 - val_loss: 0.6134 - val_accuracy: 0.6872\n",
      "Epoch 184/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6125 - accuracy: 0.6594 - val_loss: 0.6165 - val_accuracy: 0.6996\n",
      "Epoch 185/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5948 - accuracy: 0.6894 - val_loss: 0.6119 - val_accuracy: 0.6914\n",
      "Epoch 186/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5909 - accuracy: 0.7007 - val_loss: 0.6264 - val_accuracy: 0.6296\n",
      "Epoch 187/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6051 - accuracy: 0.6811 - val_loss: 0.6160 - val_accuracy: 0.6461\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5886 - accuracy: 0.6997 - val_loss: 0.6115 - val_accuracy: 0.6831\n",
      "Epoch 189/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5910 - accuracy: 0.6997 - val_loss: 0.6088 - val_accuracy: 0.6955\n",
      "Epoch 190/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5860 - accuracy: 0.7069 - val_loss: 0.6112 - val_accuracy: 0.6626\n",
      "Epoch 191/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6083 - accuracy: 0.6615 - val_loss: 0.6262 - val_accuracy: 0.6255\n",
      "Epoch 192/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5890 - accuracy: 0.7059 - val_loss: 0.6068 - val_accuracy: 0.6996\n",
      "Epoch 193/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5899 - accuracy: 0.7007 - val_loss: 0.6056 - val_accuracy: 0.6955\n",
      "Epoch 194/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5859 - accuracy: 0.7069 - val_loss: 0.6061 - val_accuracy: 0.6914\n",
      "Epoch 195/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5809 - accuracy: 0.7172 - val_loss: 0.6174 - val_accuracy: 0.7037\n",
      "Epoch 196/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5841 - accuracy: 0.7193 - val_loss: 0.6051 - val_accuracy: 0.6749\n",
      "Epoch 197/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5909 - accuracy: 0.7100 - val_loss: 0.6069 - val_accuracy: 0.7037\n",
      "Epoch 198/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5842 - accuracy: 0.7152 - val_loss: 0.6061 - val_accuracy: 0.6708\n",
      "Epoch 199/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5821 - accuracy: 0.7224 - val_loss: 0.6020 - val_accuracy: 0.6831\n",
      "Epoch 200/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5772 - accuracy: 0.7152 - val_loss: 0.6009 - val_accuracy: 0.6955\n",
      "Epoch 201/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5810 - accuracy: 0.7069 - val_loss: 0.6097 - val_accuracy: 0.7160\n",
      "Epoch 202/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5778 - accuracy: 0.7203 - val_loss: 0.6022 - val_accuracy: 0.6996\n",
      "Epoch 203/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5811 - accuracy: 0.7049 - val_loss: 0.6312 - val_accuracy: 0.6173\n",
      "Epoch 204/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5820 - accuracy: 0.6987 - val_loss: 0.6059 - val_accuracy: 0.6831\n",
      "Epoch 205/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5860 - accuracy: 0.6811 - val_loss: 0.6064 - val_accuracy: 0.6749\n",
      "Epoch 206/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5924 - accuracy: 0.6791 - val_loss: 0.5972 - val_accuracy: 0.6996\n",
      "Epoch 207/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5693 - accuracy: 0.7162 - val_loss: 0.6026 - val_accuracy: 0.7202\n",
      "Epoch 208/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5815 - accuracy: 0.7152 - val_loss: 0.6309 - val_accuracy: 0.5967\n",
      "Epoch 209/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5862 - accuracy: 0.6791 - val_loss: 0.5941 - val_accuracy: 0.7078\n",
      "Epoch 210/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7296 - val_loss: 0.5942 - val_accuracy: 0.6872\n",
      "Epoch 211/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5646 - accuracy: 0.7255 - val_loss: 0.6002 - val_accuracy: 0.6872\n",
      "Epoch 212/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5709 - accuracy: 0.7162 - val_loss: 0.5912 - val_accuracy: 0.6872\n",
      "Epoch 213/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7121 - val_loss: 0.5904 - val_accuracy: 0.6872\n",
      "Epoch 214/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5618 - accuracy: 0.7410 - val_loss: 0.5937 - val_accuracy: 0.7119\n",
      "Epoch 215/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5742 - accuracy: 0.7152 - val_loss: 0.6230 - val_accuracy: 0.6749\n",
      "Epoch 216/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7162 - val_loss: 0.6039 - val_accuracy: 0.6955\n",
      "Epoch 217/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5921 - accuracy: 0.6780 - val_loss: 0.5960 - val_accuracy: 0.6914\n",
      "Epoch 218/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5548 - accuracy: 0.7441 - val_loss: 0.5879 - val_accuracy: 0.7160\n",
      "Epoch 219/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5698 - accuracy: 0.7162 - val_loss: 0.6468 - val_accuracy: 0.5885\n",
      "Epoch 220/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5812 - accuracy: 0.6925 - val_loss: 0.5839 - val_accuracy: 0.7037\n",
      "Epoch 221/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5539 - accuracy: 0.7245 - val_loss: 0.5946 - val_accuracy: 0.7202\n",
      "Epoch 222/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5870 - accuracy: 0.6966 - val_loss: 0.6237 - val_accuracy: 0.6173\n",
      "Epoch 223/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5847 - accuracy: 0.6770 - val_loss: 0.6400 - val_accuracy: 0.6337\n",
      "Epoch 224/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5785 - accuracy: 0.6914 - val_loss: 0.5817 - val_accuracy: 0.6955\n",
      "Epoch 225/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5604 - accuracy: 0.7296 - val_loss: 0.6217 - val_accuracy: 0.6790\n",
      "Epoch 226/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5569 - accuracy: 0.7224 - val_loss: 0.5826 - val_accuracy: 0.6955\n",
      "Epoch 227/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5843 - accuracy: 0.6852 - val_loss: 0.6289 - val_accuracy: 0.6584\n",
      "Epoch 228/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5533 - accuracy: 0.7430 - val_loss: 0.5867 - val_accuracy: 0.7037\n",
      "Epoch 229/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.7451 - val_loss: 0.5934 - val_accuracy: 0.7037\n",
      "Epoch 230/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5620 - accuracy: 0.7193 - val_loss: 0.6305 - val_accuracy: 0.6008\n",
      "Epoch 231/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5602 - accuracy: 0.7152 - val_loss: 0.5780 - val_accuracy: 0.7366\n",
      "Epoch 232/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7513 - val_loss: 0.5923 - val_accuracy: 0.6955\n",
      "Epoch 233/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7430 - val_loss: 0.5724 - val_accuracy: 0.7243\n",
      "Epoch 234/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7606 - val_loss: 0.5708 - val_accuracy: 0.7078\n",
      "Epoch 235/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5731 - accuracy: 0.6945 - val_loss: 0.6429 - val_accuracy: 0.5926\n",
      "Epoch 236/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5698 - accuracy: 0.7018 - val_loss: 0.6374 - val_accuracy: 0.6379\n",
      "Epoch 237/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7585 - val_loss: 0.5817 - val_accuracy: 0.7119\n",
      "Epoch 238/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7482 - val_loss: 0.6352 - val_accuracy: 0.6379\n",
      "Epoch 239/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7224 - val_loss: 0.5754 - val_accuracy: 0.7202\n",
      "Epoch 240/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5307 - accuracy: 0.7575 - val_loss: 0.5694 - val_accuracy: 0.7160\n",
      "Epoch 241/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.7141 - val_loss: 0.5784 - val_accuracy: 0.7160\n",
      "Epoch 242/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7585 - val_loss: 0.5758 - val_accuracy: 0.7202\n",
      "Epoch 243/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5281 - accuracy: 0.7709 - val_loss: 0.5620 - val_accuracy: 0.7160\n",
      "Epoch 244/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5317 - accuracy: 0.7503 - val_loss: 0.5656 - val_accuracy: 0.7449\n",
      "Epoch 245/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5872 - accuracy: 0.6821 - val_loss: 0.5812 - val_accuracy: 0.6955\n",
      "Epoch 246/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5531 - accuracy: 0.7069 - val_loss: 0.5759 - val_accuracy: 0.7160\n",
      "Epoch 247/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7503 - val_loss: 0.5594 - val_accuracy: 0.7449\n",
      "Epoch 248/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7503 - val_loss: 0.6431 - val_accuracy: 0.5926\n",
      "Epoch 249/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6406 - accuracy: 0.6275 - val_loss: 0.6294 - val_accuracy: 0.6502\n",
      "Epoch 250/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7451 - val_loss: 0.5670 - val_accuracy: 0.7366\n",
      "Epoch 251/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7564 - val_loss: 0.5669 - val_accuracy: 0.7119\n",
      "Epoch 252/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7224 - val_loss: 0.6563 - val_accuracy: 0.6173\n",
      "Epoch 253/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5616 - accuracy: 0.7100 - val_loss: 0.6313 - val_accuracy: 0.6008\n",
      "Epoch 254/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7245 - val_loss: 0.5554 - val_accuracy: 0.7531\n",
      "Epoch 255/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.5217 - accuracy: 0.7647 - val_loss: 0.6020 - val_accuracy: 0.6255\n",
      "Epoch 256/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5539 - accuracy: 0.7090 - val_loss: 0.5973 - val_accuracy: 0.6831\n",
      "Epoch 257/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7327 - val_loss: 0.5543 - val_accuracy: 0.7490\n",
      "Epoch 258/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5166 - accuracy: 0.7657 - val_loss: 0.5513 - val_accuracy: 0.7325\n",
      "Epoch 259/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5278 - accuracy: 0.7327 - val_loss: 0.5781 - val_accuracy: 0.7078\n",
      "Epoch 260/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7183 - val_loss: 0.5687 - val_accuracy: 0.7037\n",
      "Epoch 261/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7564 - val_loss: 0.5603 - val_accuracy: 0.7037\n",
      "Epoch 262/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7307 - val_loss: 0.6561 - val_accuracy: 0.6132\n",
      "Epoch 263/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5563 - accuracy: 0.7007 - val_loss: 0.5797 - val_accuracy: 0.6626\n",
      "Epoch 264/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5289 - accuracy: 0.7358 - val_loss: 0.5468 - val_accuracy: 0.7572\n",
      "Epoch 265/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5178 - accuracy: 0.7544 - val_loss: 0.5897 - val_accuracy: 0.6914\n",
      "Epoch 266/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5106 - accuracy: 0.7544 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
      "Epoch 267/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4992 - accuracy: 0.7812 - val_loss: 0.5409 - val_accuracy: 0.7613\n",
      "Epoch 268/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5252 - accuracy: 0.7389 - val_loss: 0.5554 - val_accuracy: 0.7078\n",
      "Epoch 269/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5055 - accuracy: 0.7761 - val_loss: 0.5449 - val_accuracy: 0.7407\n",
      "Epoch 270/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4929 - accuracy: 0.7895 - val_loss: 0.5367 - val_accuracy: 0.7613\n",
      "Epoch 271/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4901 - accuracy: 0.7967 - val_loss: 0.5706 - val_accuracy: 0.7078\n",
      "Epoch 272/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5125 - accuracy: 0.7420 - val_loss: 0.5406 - val_accuracy: 0.7160\n",
      "Epoch 273/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5055 - accuracy: 0.7399 - val_loss: 0.5418 - val_accuracy: 0.7325\n",
      "Epoch 274/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4869 - accuracy: 0.7988 - val_loss: 0.5360 - val_accuracy: 0.7531\n",
      "Epoch 275/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5639 - accuracy: 0.6894 - val_loss: 0.6158 - val_accuracy: 0.6173\n",
      "Epoch 276/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7234 - val_loss: 0.5536 - val_accuracy: 0.7325\n",
      "Epoch 277/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4853 - accuracy: 0.7957 - val_loss: 0.5420 - val_accuracy: 0.7366\n",
      "Epoch 278/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5055 - accuracy: 0.7503 - val_loss: 0.5441 - val_accuracy: 0.7119\n",
      "Epoch 279/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7059 - val_loss: 0.5502 - val_accuracy: 0.7490\n",
      "Epoch 280/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4926 - accuracy: 0.7884 - val_loss: 0.5340 - val_accuracy: 0.7325\n",
      "Epoch 281/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5051 - accuracy: 0.7575 - val_loss: 0.5368 - val_accuracy: 0.7325\n",
      "Epoch 282/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4881 - accuracy: 0.7781 - val_loss: 0.5680 - val_accuracy: 0.7078\n",
      "Epoch 283/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5769 - accuracy: 0.6739 - val_loss: 0.6181 - val_accuracy: 0.6132\n",
      "Epoch 284/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5021 - accuracy: 0.7688 - val_loss: 0.5646 - val_accuracy: 0.7078\n",
      "Epoch 285/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5107 - accuracy: 0.7430 - val_loss: 0.5276 - val_accuracy: 0.7572\n",
      "Epoch 286/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4737 - accuracy: 0.8039 - val_loss: 0.5308 - val_accuracy: 0.7613\n",
      "Epoch 287/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4998 - accuracy: 0.7482 - val_loss: 0.5232 - val_accuracy: 0.7490\n",
      "Epoch 288/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4692 - accuracy: 0.8039 - val_loss: 0.5182 - val_accuracy: 0.7654\n",
      "Epoch 289/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4658 - accuracy: 0.8122 - val_loss: 0.5238 - val_accuracy: 0.7449\n",
      "Epoch 290/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4639 - accuracy: 0.8194 - val_loss: 0.5173 - val_accuracy: 0.7490\n",
      "Epoch 291/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4936 - accuracy: 0.7544 - val_loss: 0.5193 - val_accuracy: 0.7572\n",
      "Epoch 292/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7028 - val_loss: 0.5254 - val_accuracy: 0.7366\n",
      "Epoch 293/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4777 - accuracy: 0.7967 - val_loss: 0.5590 - val_accuracy: 0.7037\n",
      "Epoch 294/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5592 - accuracy: 0.6925 - val_loss: 0.5235 - val_accuracy: 0.7449\n",
      "Epoch 295/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4776 - accuracy: 0.7781 - val_loss: 0.5259 - val_accuracy: 0.7613\n",
      "Epoch 296/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.7740 - val_loss: 0.5166 - val_accuracy: 0.7490\n",
      "Epoch 297/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5023 - accuracy: 0.7296 - val_loss: 0.5804 - val_accuracy: 0.6872\n",
      "Epoch 298/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4872 - accuracy: 0.7606 - val_loss: 0.5060 - val_accuracy: 0.7984\n",
      "Epoch 299/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4625 - accuracy: 0.7905 - val_loss: 0.5214 - val_accuracy: 0.7737\n",
      "Epoch 300/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4757 - accuracy: 0.7905 - val_loss: 0.5333 - val_accuracy: 0.7037\n",
      "Epoch 301/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.7957 - val_loss: 0.4998 - val_accuracy: 0.7984\n",
      "Epoch 302/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.8184 - val_loss: 0.4988 - val_accuracy: 0.8025\n",
      "Epoch 303/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4613 - accuracy: 0.7926 - val_loss: 0.4955 - val_accuracy: 0.7860\n",
      "Epoch 304/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4457 - accuracy: 0.8266 - val_loss: 0.5646 - val_accuracy: 0.6955\n",
      "Epoch 305/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4932 - accuracy: 0.7348 - val_loss: 0.5684 - val_accuracy: 0.6502\n",
      "Epoch 306/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.7998 - val_loss: 0.5015 - val_accuracy: 0.7860\n",
      "Epoch 307/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4705 - accuracy: 0.7626 - val_loss: 0.5077 - val_accuracy: 0.7407\n",
      "Epoch 308/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5614 - accuracy: 0.6935 - val_loss: 0.6056 - val_accuracy: 0.6708\n",
      "Epoch 309/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5050 - accuracy: 0.7461 - val_loss: 0.5422 - val_accuracy: 0.6996\n",
      "Epoch 310/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4756 - accuracy: 0.7853 - val_loss: 0.4907 - val_accuracy: 0.8148\n",
      "Epoch 311/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4369 - accuracy: 0.8390 - val_loss: 0.4902 - val_accuracy: 0.7860\n",
      "Epoch 312/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4400 - accuracy: 0.8297 - val_loss: 0.5292 - val_accuracy: 0.7407\n",
      "Epoch 313/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4441 - accuracy: 0.8204 - val_loss: 0.5462 - val_accuracy: 0.6708\n",
      "Epoch 314/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4391 - accuracy: 0.8235 - val_loss: 0.4915 - val_accuracy: 0.7942\n",
      "Epoch 315/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4306 - accuracy: 0.8400 - val_loss: 0.5569 - val_accuracy: 0.6584\n",
      "Epoch 316/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.6935 - val_loss: 0.7015 - val_accuracy: 0.6008\n",
      "Epoch 317/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5830 - accuracy: 0.7059 - val_loss: 0.4962 - val_accuracy: 0.7901\n",
      "Epoch 318/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4293 - accuracy: 0.8390 - val_loss: 0.5040 - val_accuracy: 0.7778\n",
      "Epoch 319/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4249 - accuracy: 0.8483 - val_loss: 0.4998 - val_accuracy: 0.7778\n",
      "Epoch 320/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4353 - accuracy: 0.8173 - val_loss: 0.4906 - val_accuracy: 0.7901\n",
      "Epoch 321/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4239 - accuracy: 0.8452 - val_loss: 0.4850 - val_accuracy: 0.7572\n",
      "Epoch 322/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4304 - accuracy: 0.8204 - val_loss: 0.4729 - val_accuracy: 0.8025\n",
      "Epoch 323/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4169 - accuracy: 0.8524 - val_loss: 0.4966 - val_accuracy: 0.7160\n",
      "Epoch 324/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4460 - accuracy: 0.7771 - val_loss: 0.4910 - val_accuracy: 0.7860\n",
      "Epoch 325/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5070 - accuracy: 0.7317 - val_loss: 0.5098 - val_accuracy: 0.7119\n",
      "Epoch 326/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4830 - accuracy: 0.7441 - val_loss: 0.5517 - val_accuracy: 0.6996\n",
      "Epoch 327/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4234 - accuracy: 0.8349 - val_loss: 0.4653 - val_accuracy: 0.8189\n",
      "Epoch 328/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4096 - accuracy: 0.8524 - val_loss: 0.4615 - val_accuracy: 0.8107\n",
      "Epoch 329/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4043 - accuracy: 0.8627 - val_loss: 0.4749 - val_accuracy: 0.7695\n",
      "Epoch 330/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4323 - accuracy: 0.7988 - val_loss: 0.5110 - val_accuracy: 0.7490\n",
      "Epoch 331/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4323 - accuracy: 0.8029 - val_loss: 0.4590 - val_accuracy: 0.8066\n",
      "Epoch 332/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4202 - accuracy: 0.8235 - val_loss: 0.4541 - val_accuracy: 0.8272\n",
      "Epoch 333/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8607 - val_loss: 0.4703 - val_accuracy: 0.8025\n",
      "Epoch 334/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4414 - accuracy: 0.7905 - val_loss: 0.6525 - val_accuracy: 0.6049\n",
      "Epoch 335/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7255 - val_loss: 0.4911 - val_accuracy: 0.7737\n",
      "Epoch 336/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4071 - accuracy: 0.8411 - val_loss: 0.4560 - val_accuracy: 0.8025\n",
      "Epoch 337/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3929 - accuracy: 0.8772 - val_loss: 0.4547 - val_accuracy: 0.7942\n",
      "Epoch 338/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4139 - accuracy: 0.8287 - val_loss: 0.4500 - val_accuracy: 0.8066\n",
      "Epoch 339/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3867 - accuracy: 0.8669 - val_loss: 0.4437 - val_accuracy: 0.8230\n",
      "Epoch 340/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3886 - accuracy: 0.8566 - val_loss: 0.4941 - val_accuracy: 0.7695\n",
      "Epoch 341/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4682 - accuracy: 0.7606 - val_loss: 0.4610 - val_accuracy: 0.7778\n",
      "Epoch 342/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4138 - accuracy: 0.8225 - val_loss: 0.4642 - val_accuracy: 0.7942\n",
      "Epoch 343/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4135 - accuracy: 0.8266 - val_loss: 0.4661 - val_accuracy: 0.7490\n",
      "Epoch 344/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4548 - accuracy: 0.7781 - val_loss: 0.4733 - val_accuracy: 0.7860\n",
      "Epoch 345/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4029 - accuracy: 0.8328 - val_loss: 0.4638 - val_accuracy: 0.7449\n",
      "Epoch 346/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3861 - accuracy: 0.8545 - val_loss: 0.4297 - val_accuracy: 0.8477\n",
      "Epoch 347/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3804 - accuracy: 0.8617 - val_loss: 0.4345 - val_accuracy: 0.8395\n",
      "Epoch 348/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4191 - accuracy: 0.8091 - val_loss: 0.5001 - val_accuracy: 0.7243\n",
      "Epoch 349/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4717 - accuracy: 0.7575 - val_loss: 0.4926 - val_accuracy: 0.7613\n",
      "Epoch 350/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3830 - accuracy: 0.8535 - val_loss: 0.4505 - val_accuracy: 0.8025\n",
      "Epoch 351/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3940 - accuracy: 0.8369 - val_loss: 0.5077 - val_accuracy: 0.7160\n",
      "Epoch 352/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5037 - accuracy: 0.7348 - val_loss: 0.6411 - val_accuracy: 0.6461\n",
      "Epoch 353/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4556 - accuracy: 0.7802 - val_loss: 0.4625 - val_accuracy: 0.7572\n",
      "Epoch 354/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3822 - accuracy: 0.8669 - val_loss: 0.4328 - val_accuracy: 0.8189\n",
      "Epoch 355/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3663 - accuracy: 0.8793 - val_loss: 0.4211 - val_accuracy: 0.8560\n",
      "Epoch 356/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3631 - accuracy: 0.8710 - val_loss: 0.4634 - val_accuracy: 0.7860\n",
      "Epoch 357/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.8504 - val_loss: 0.4136 - val_accuracy: 0.8519\n",
      "Epoch 358/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4384 - accuracy: 0.7843 - val_loss: 0.4849 - val_accuracy: 0.7531\n",
      "Epoch 359/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3655 - accuracy: 0.8658 - val_loss: 0.4302 - val_accuracy: 0.8272\n",
      "Epoch 360/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4058 - accuracy: 0.8204 - val_loss: 0.4450 - val_accuracy: 0.7572\n",
      "Epoch 361/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4743 - accuracy: 0.7492 - val_loss: 0.4820 - val_accuracy: 0.7737\n",
      "Epoch 362/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3602 - accuracy: 0.8875 - val_loss: 0.4178 - val_accuracy: 0.8601\n",
      "Epoch 363/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3789 - accuracy: 0.8535 - val_loss: 0.4597 - val_accuracy: 0.7942\n",
      "Epoch 364/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4395 - accuracy: 0.7864 - val_loss: 0.4638 - val_accuracy: 0.7613\n",
      "Epoch 365/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3615 - accuracy: 0.8720 - val_loss: 0.4072 - val_accuracy: 0.8642\n",
      "Epoch 366/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3635 - accuracy: 0.8658 - val_loss: 0.4597 - val_accuracy: 0.7901\n",
      "Epoch 367/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4595 - accuracy: 0.7678 - val_loss: 0.6067 - val_accuracy: 0.6502\n",
      "Epoch 368/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8411 - val_loss: 0.4045 - val_accuracy: 0.8724\n",
      "Epoch 369/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3641 - accuracy: 0.8596 - val_loss: 0.3973 - val_accuracy: 0.8601\n",
      "Epoch 370/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3437 - accuracy: 0.8875 - val_loss: 0.4143 - val_accuracy: 0.8395\n",
      "Epoch 371/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.8731 - val_loss: 0.3904 - val_accuracy: 0.8683\n",
      "Epoch 372/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.8865 - val_loss: 0.4334 - val_accuracy: 0.8025\n",
      "Epoch 373/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3413 - accuracy: 0.8793 - val_loss: 0.3863 - val_accuracy: 0.8601\n",
      "Epoch 374/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3977 - accuracy: 0.8184 - val_loss: 0.6170 - val_accuracy: 0.6667\n",
      "Epoch 375/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4342 - accuracy: 0.7936 - val_loss: 0.4058 - val_accuracy: 0.8107\n",
      "Epoch 376/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3365 - accuracy: 0.8875 - val_loss: 0.3849 - val_accuracy: 0.8642\n",
      "Epoch 377/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8927 - val_loss: 0.3861 - val_accuracy: 0.8519\n",
      "Epoch 378/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3465 - accuracy: 0.8596 - val_loss: 0.5189 - val_accuracy: 0.7119\n",
      "Epoch 379/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.7678 - val_loss: 0.4462 - val_accuracy: 0.7778\n",
      "Epoch 380/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4212 - accuracy: 0.7988 - val_loss: 0.4871 - val_accuracy: 0.7407\n",
      "Epoch 381/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3820 - accuracy: 0.8411 - val_loss: 0.3819 - val_accuracy: 0.8642\n",
      "Epoch 382/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8782 - val_loss: 0.3946 - val_accuracy: 0.8560\n",
      "Epoch 383/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3291 - accuracy: 0.8947 - val_loss: 0.3850 - val_accuracy: 0.8477\n",
      "Epoch 384/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.8978 - val_loss: 0.3751 - val_accuracy: 0.8724\n",
      "Epoch 385/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8813 - val_loss: 0.3744 - val_accuracy: 0.8354\n",
      "Epoch 386/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3561 - accuracy: 0.8369 - val_loss: 0.4454 - val_accuracy: 0.7984\n",
      "Epoch 387/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3771 - accuracy: 0.8297 - val_loss: 0.4463 - val_accuracy: 0.7695\n",
      "Epoch 388/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4879 - accuracy: 0.7482 - val_loss: 0.4834 - val_accuracy: 0.7449\n",
      "Epoch 389/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3622 - accuracy: 0.8545 - val_loss: 0.3695 - val_accuracy: 0.8807\n",
      "Epoch 390/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3429 - accuracy: 0.8638 - val_loss: 0.4148 - val_accuracy: 0.8354\n",
      "Epoch 391/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.3265 - accuracy: 0.8772 - val_loss: 0.3986 - val_accuracy: 0.8313\n",
      "Epoch 392/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3468 - accuracy: 0.8576 - val_loss: 0.3692 - val_accuracy: 0.8560\n",
      "Epoch 393/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3370 - accuracy: 0.8710 - val_loss: 0.4461 - val_accuracy: 0.7901\n",
      "Epoch 394/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3567 - accuracy: 0.8555 - val_loss: 0.5229 - val_accuracy: 0.6914\n",
      "Epoch 395/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4488 - accuracy: 0.7719 - val_loss: 0.4016 - val_accuracy: 0.8477\n",
      "Epoch 396/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3197 - accuracy: 0.8989 - val_loss: 0.3663 - val_accuracy: 0.8848\n",
      "Epoch 397/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3538 - accuracy: 0.8504 - val_loss: 0.3881 - val_accuracy: 0.8354\n",
      "Epoch 398/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.8576 - val_loss: 0.4546 - val_accuracy: 0.7819\n",
      "Epoch 399/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3647 - accuracy: 0.8380 - val_loss: 0.3862 - val_accuracy: 0.8313\n",
      "Epoch 400/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3155 - accuracy: 0.8896 - val_loss: 0.3486 - val_accuracy: 0.8807\n",
      "Epoch 401/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3051 - accuracy: 0.8968 - val_loss: 0.3538 - val_accuracy: 0.8848\n",
      "Epoch 402/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3374 - accuracy: 0.8535 - val_loss: 0.3874 - val_accuracy: 0.8354\n",
      "Epoch 403/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3225 - accuracy: 0.8844 - val_loss: 0.3828 - val_accuracy: 0.8148\n",
      "Epoch 404/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3804 - accuracy: 0.8297 - val_loss: 0.3807 - val_accuracy: 0.8519\n",
      "Epoch 405/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3221 - accuracy: 0.8793 - val_loss: 0.4218 - val_accuracy: 0.7778\n",
      "Epoch 406/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3237 - accuracy: 0.8658 - val_loss: 0.4502 - val_accuracy: 0.7737\n",
      "Epoch 407/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3064 - accuracy: 0.8854 - val_loss: 0.3714 - val_accuracy: 0.8477\n",
      "Epoch 408/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3010 - accuracy: 0.8803 - val_loss: 0.3330 - val_accuracy: 0.8848\n",
      "Epoch 409/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3008 - accuracy: 0.8978 - val_loss: 0.4210 - val_accuracy: 0.7737\n",
      "Epoch 410/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3487 - accuracy: 0.8380 - val_loss: 0.5393 - val_accuracy: 0.7160\n",
      "Epoch 411/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4791 - accuracy: 0.7482 - val_loss: 0.3535 - val_accuracy: 0.8724\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2994 - accuracy: 0.8937 - val_loss: 0.3382 - val_accuracy: 0.9012\n",
      "Epoch 413/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2873 - accuracy: 0.9102 - val_loss: 0.3332 - val_accuracy: 0.8971\n",
      "Epoch 414/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2932 - accuracy: 0.8978 - val_loss: 0.4078 - val_accuracy: 0.8354\n",
      "Epoch 415/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2929 - accuracy: 0.8968 - val_loss: 0.3227 - val_accuracy: 0.9053\n",
      "Epoch 416/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2726 - accuracy: 0.9164 - val_loss: 0.3300 - val_accuracy: 0.8889\n",
      "Epoch 417/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2782 - accuracy: 0.9051 - val_loss: 0.3311 - val_accuracy: 0.8889\n",
      "Epoch 418/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2907 - accuracy: 0.8937 - val_loss: 0.3271 - val_accuracy: 0.8971\n",
      "Epoch 419/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3032 - accuracy: 0.8885 - val_loss: 0.4273 - val_accuracy: 0.7984\n",
      "Epoch 420/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4325 - accuracy: 0.7719 - val_loss: 0.3503 - val_accuracy: 0.8560\n",
      "Epoch 421/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2893 - accuracy: 0.9071 - val_loss: 0.3460 - val_accuracy: 0.8683\n",
      "Epoch 422/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2807 - accuracy: 0.9102 - val_loss: 0.3195 - val_accuracy: 0.9053\n",
      "Epoch 423/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2714 - accuracy: 0.9123 - val_loss: 0.3066 - val_accuracy: 0.9053\n",
      "Epoch 424/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2674 - accuracy: 0.9185 - val_loss: 0.3103 - val_accuracy: 0.9053\n",
      "Epoch 425/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3716 - accuracy: 0.8277 - val_loss: 0.4185 - val_accuracy: 0.8066\n",
      "Epoch 426/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.8648 - val_loss: 0.3367 - val_accuracy: 0.8683\n",
      "Epoch 427/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3312 - accuracy: 0.8514 - val_loss: 0.3340 - val_accuracy: 0.8807\n",
      "Epoch 428/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2664 - accuracy: 0.9174 - val_loss: 0.3110 - val_accuracy: 0.9053\n",
      "Epoch 429/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3349 - accuracy: 0.8607 - val_loss: 0.4201 - val_accuracy: 0.7695\n",
      "Epoch 430/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3740 - accuracy: 0.8266 - val_loss: 0.3552 - val_accuracy: 0.8477\n",
      "Epoch 431/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2986 - accuracy: 0.8793 - val_loss: 0.3089 - val_accuracy: 0.9136\n",
      "Epoch 432/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2802 - accuracy: 0.8999 - val_loss: 0.3555 - val_accuracy: 0.8560\n",
      "Epoch 433/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2633 - accuracy: 0.9205 - val_loss: 0.3117 - val_accuracy: 0.8889\n",
      "Epoch 434/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2517 - accuracy: 0.9236 - val_loss: 0.3073 - val_accuracy: 0.9053\n",
      "Epoch 435/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3770 - accuracy: 0.8338 - val_loss: 0.4183 - val_accuracy: 0.7860\n",
      "Epoch 436/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8545 - val_loss: 0.3244 - val_accuracy: 0.8848\n",
      "Epoch 437/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2607 - accuracy: 0.9216 - val_loss: 0.3133 - val_accuracy: 0.9012\n",
      "Epoch 438/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2484 - accuracy: 0.9236 - val_loss: 0.3188 - val_accuracy: 0.8724\n",
      "Epoch 439/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3056 - accuracy: 0.8782 - val_loss: 0.3484 - val_accuracy: 0.8477\n",
      "Epoch 440/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3206 - accuracy: 0.8638 - val_loss: 0.3177 - val_accuracy: 0.8765\n",
      "Epoch 441/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2466 - accuracy: 0.9257 - val_loss: 0.2857 - val_accuracy: 0.9177\n",
      "Epoch 442/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2557 - accuracy: 0.9154 - val_loss: 0.3024 - val_accuracy: 0.9012\n",
      "Epoch 443/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.9236 - val_loss: 0.2947 - val_accuracy: 0.9095\n",
      "Epoch 444/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9340 - val_loss: 0.3421 - val_accuracy: 0.8189\n",
      "Epoch 445/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.7420 - val_loss: 0.4632 - val_accuracy: 0.7654\n",
      "Epoch 446/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3020 - accuracy: 0.8875 - val_loss: 0.2948 - val_accuracy: 0.9177\n",
      "Epoch 447/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.9340 - val_loss: 0.3018 - val_accuracy: 0.9053\n",
      "Epoch 448/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2408 - accuracy: 0.9298 - val_loss: 0.2996 - val_accuracy: 0.9095\n",
      "Epoch 449/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2417 - accuracy: 0.9267 - val_loss: 0.3026 - val_accuracy: 0.8889\n",
      "Epoch 450/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2472 - accuracy: 0.9267 - val_loss: 0.2845 - val_accuracy: 0.9136\n",
      "Epoch 451/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2363 - accuracy: 0.9298 - val_loss: 0.2769 - val_accuracy: 0.9218\n",
      "Epoch 452/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2400 - accuracy: 0.9319 - val_loss: 0.3417 - val_accuracy: 0.8436\n",
      "Epoch 453/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3141 - accuracy: 0.8596 - val_loss: 0.4255 - val_accuracy: 0.7737\n",
      "Epoch 454/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3149 - accuracy: 0.8700 - val_loss: 0.3486 - val_accuracy: 0.8519\n",
      "Epoch 455/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2402 - accuracy: 0.9257 - val_loss: 0.2726 - val_accuracy: 0.9259\n",
      "Epoch 456/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2247 - accuracy: 0.9432 - val_loss: 0.2693 - val_accuracy: 0.9300\n",
      "Epoch 457/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3084 - accuracy: 0.8700 - val_loss: 0.4256 - val_accuracy: 0.7860\n",
      "Epoch 458/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3011 - accuracy: 0.8689 - val_loss: 0.2859 - val_accuracy: 0.9095\n",
      "Epoch 459/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2398 - accuracy: 0.9298 - val_loss: 0.4285 - val_accuracy: 0.7819\n",
      "Epoch 460/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3237 - accuracy: 0.8442 - val_loss: 0.2658 - val_accuracy: 0.9259\n",
      "Epoch 461/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2261 - accuracy: 0.9401 - val_loss: 0.2664 - val_accuracy: 0.9259\n",
      "Epoch 462/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2190 - accuracy: 0.9381 - val_loss: 0.2805 - val_accuracy: 0.9053\n",
      "Epoch 463/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2559 - accuracy: 0.9071 - val_loss: 0.3032 - val_accuracy: 0.8807\n",
      "Epoch 464/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2717 - accuracy: 0.8916 - val_loss: 0.4396 - val_accuracy: 0.7572\n",
      "Epoch 465/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4170 - accuracy: 0.8008 - val_loss: 0.5018 - val_accuracy: 0.7366\n",
      "Epoch 466/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2925 - accuracy: 0.8906 - val_loss: 0.2707 - val_accuracy: 0.9383\n",
      "Epoch 467/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2216 - accuracy: 0.9401 - val_loss: 0.2549 - val_accuracy: 0.9383\n",
      "Epoch 468/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2140 - accuracy: 0.9453 - val_loss: 0.2513 - val_accuracy: 0.9424\n",
      "Epoch 469/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2149 - accuracy: 0.9391 - val_loss: 0.2839 - val_accuracy: 0.9136\n",
      "Epoch 470/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2179 - accuracy: 0.9329 - val_loss: 0.2630 - val_accuracy: 0.9259\n",
      "Epoch 471/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2094 - accuracy: 0.9453 - val_loss: 0.2431 - val_accuracy: 0.9383\n",
      "Epoch 472/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2137 - accuracy: 0.9391 - val_loss: 0.2893 - val_accuracy: 0.8930\n",
      "Epoch 473/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2304 - accuracy: 0.9216 - val_loss: 0.3094 - val_accuracy: 0.8436\n",
      "Epoch 474/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2728 - accuracy: 0.8782 - val_loss: 0.4364 - val_accuracy: 0.7860\n",
      "Epoch 475/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2901 - accuracy: 0.8793 - val_loss: 0.2775 - val_accuracy: 0.8889\n",
      "Epoch 476/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2681 - accuracy: 0.8813 - val_loss: 0.3973 - val_accuracy: 0.8148\n",
      "Epoch 477/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2560 - accuracy: 0.9020 - val_loss: 0.3068 - val_accuracy: 0.8519\n",
      "Epoch 478/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2322 - accuracy: 0.9092 - val_loss: 0.2665 - val_accuracy: 0.9177\n",
      "Epoch 479/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1993 - accuracy: 0.9463 - val_loss: 0.2461 - val_accuracy: 0.9383\n",
      "Epoch 480/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.9051 - val_loss: 0.2619 - val_accuracy: 0.9136\n",
      "Epoch 481/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2206 - accuracy: 0.9267 - val_loss: 0.3036 - val_accuracy: 0.8848\n",
      "Epoch 482/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2427 - accuracy: 0.9123 - val_loss: 0.3515 - val_accuracy: 0.8066\n",
      "Epoch 483/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4423 - accuracy: 0.7792 - val_loss: 0.5025 - val_accuracy: 0.7284\n",
      "Epoch 484/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2683 - accuracy: 0.8958 - val_loss: 0.2402 - val_accuracy: 0.9424\n",
      "Epoch 485/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2050 - accuracy: 0.9453 - val_loss: 0.2735 - val_accuracy: 0.9053\n",
      "Epoch 486/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2035 - accuracy: 0.9432 - val_loss: 0.2389 - val_accuracy: 0.9342\n",
      "Epoch 487/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2093 - accuracy: 0.9443 - val_loss: 0.2492 - val_accuracy: 0.9300\n",
      "Epoch 488/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2224 - accuracy: 0.9267 - val_loss: 0.2283 - val_accuracy: 0.9383\n",
      "Epoch 489/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1930 - accuracy: 0.9463 - val_loss: 0.2598 - val_accuracy: 0.9218\n",
      "Epoch 490/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2364 - accuracy: 0.9051 - val_loss: 0.2916 - val_accuracy: 0.8642\n",
      "Epoch 491/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2871 - accuracy: 0.8762 - val_loss: 0.3593 - val_accuracy: 0.8230\n",
      "Epoch 492/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2518 - accuracy: 0.9061 - val_loss: 0.2761 - val_accuracy: 0.8807\n",
      "Epoch 493/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2206 - accuracy: 0.9236 - val_loss: 0.2469 - val_accuracy: 0.9259\n",
      "Epoch 494/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2691 - accuracy: 0.8999 - val_loss: 0.5619 - val_accuracy: 0.7037\n",
      "Epoch 495/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3446 - accuracy: 0.8462 - val_loss: 0.2360 - val_accuracy: 0.9424\n",
      "Epoch 496/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1927 - accuracy: 0.9505 - val_loss: 0.2298 - val_accuracy: 0.9342\n",
      "Epoch 497/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1866 - accuracy: 0.9494 - val_loss: 0.2184 - val_accuracy: 0.9383\n",
      "Epoch 498/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1829 - accuracy: 0.9515 - val_loss: 0.2145 - val_accuracy: 0.9506\n",
      "Epoch 499/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1805 - accuracy: 0.9505 - val_loss: 0.2125 - val_accuracy: 0.9465\n",
      "Epoch 500/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1771 - accuracy: 0.9484 - val_loss: 0.2107 - val_accuracy: 0.9506\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sleepy       0.95      0.95      0.95       152\n",
      "    vigilant       0.95      0.95      0.95       151\n",
      "\n",
      "    accuracy                           0.95       303\n",
      "   macro avg       0.95      0.95      0.95       303\n",
      "weighted avg       0.95      0.95      0.95       303\n",
      "\n",
      "[INFO] compiling model fold3.....\n",
      "[INFO] training network...\n",
      "(969, 28, 28, 1) (303, 28, 28, 1) (969, 2) (303, 2)\n",
      "Train on 969 samples, validate on 243 samples\n",
      "Epoch 1/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6949 - accuracy: 0.4995 - val_loss: 0.6925 - val_accuracy: 0.5267\n",
      "Epoch 2/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.5119 - val_loss: 0.6916 - val_accuracy: 0.5226\n",
      "Epoch 3/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.5397 - val_loss: 0.6911 - val_accuracy: 0.5267\n",
      "Epoch 4/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6891 - accuracy: 0.5428 - val_loss: 0.6909 - val_accuracy: 0.5597\n",
      "Epoch 5/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.5769 - val_loss: 0.6905 - val_accuracy: 0.5679\n",
      "Epoch 6/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.5820 - val_loss: 0.6903 - val_accuracy: 0.5514\n",
      "Epoch 7/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5717 - val_loss: 0.6898 - val_accuracy: 0.5638\n",
      "Epoch 8/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5789 - val_loss: 0.6896 - val_accuracy: 0.5473\n",
      "Epoch 9/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5769 - val_loss: 0.6891 - val_accuracy: 0.5679\n",
      "Epoch 10/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5893 - val_loss: 0.6887 - val_accuracy: 0.5556\n",
      "Epoch 11/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5955 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 12/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5965 - val_loss: 0.6878 - val_accuracy: 0.5679\n",
      "Epoch 13/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6833 - accuracy: 0.5893 - val_loss: 0.6874 - val_accuracy: 0.5802\n",
      "Epoch 14/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6828 - accuracy: 0.5944 - val_loss: 0.6871 - val_accuracy: 0.5802\n",
      "Epoch 15/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6824 - accuracy: 0.5913 - val_loss: 0.6868 - val_accuracy: 0.5844\n",
      "Epoch 16/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6818 - accuracy: 0.5986 - val_loss: 0.6864 - val_accuracy: 0.5597\n",
      "Epoch 17/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6814 - accuracy: 0.5955 - val_loss: 0.6861 - val_accuracy: 0.5597\n",
      "Epoch 18/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6809 - accuracy: 0.6006 - val_loss: 0.6857 - val_accuracy: 0.5638\n",
      "Epoch 19/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6804 - accuracy: 0.5986 - val_loss: 0.6852 - val_accuracy: 0.5720\n",
      "Epoch 20/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6798 - accuracy: 0.5851 - val_loss: 0.6848 - val_accuracy: 0.5720\n",
      "Epoch 21/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6793 - accuracy: 0.5779 - val_loss: 0.6845 - val_accuracy: 0.5720\n",
      "Epoch 22/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6788 - accuracy: 0.5831 - val_loss: 0.6841 - val_accuracy: 0.5720\n",
      "Epoch 23/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6782 - accuracy: 0.5841 - val_loss: 0.6837 - val_accuracy: 0.5802\n",
      "Epoch 24/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6778 - accuracy: 0.5789 - val_loss: 0.6835 - val_accuracy: 0.5761\n",
      "Epoch 25/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6773 - accuracy: 0.5820 - val_loss: 0.6831 - val_accuracy: 0.5802\n",
      "Epoch 26/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6769 - accuracy: 0.5841 - val_loss: 0.6828 - val_accuracy: 0.5720\n",
      "Epoch 27/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6764 - accuracy: 0.5841 - val_loss: 0.6826 - val_accuracy: 0.5720\n",
      "Epoch 28/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6761 - accuracy: 0.5748 - val_loss: 0.6823 - val_accuracy: 0.5720\n",
      "Epoch 29/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6753 - accuracy: 0.5810 - val_loss: 0.6819 - val_accuracy: 0.5720\n",
      "Epoch 30/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6751 - accuracy: 0.5728 - val_loss: 0.6816 - val_accuracy: 0.5761\n",
      "Epoch 31/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6745 - accuracy: 0.5831 - val_loss: 0.6811 - val_accuracy: 0.5802\n",
      "Epoch 32/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6739 - accuracy: 0.5800 - val_loss: 0.6809 - val_accuracy: 0.5844\n",
      "Epoch 33/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6736 - accuracy: 0.5759 - val_loss: 0.6805 - val_accuracy: 0.5802\n",
      "Epoch 34/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6728 - accuracy: 0.5769 - val_loss: 0.6801 - val_accuracy: 0.5802\n",
      "Epoch 35/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6727 - accuracy: 0.5686 - val_loss: 0.6797 - val_accuracy: 0.5885\n",
      "Epoch 36/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6723 - accuracy: 0.5655 - val_loss: 0.6799 - val_accuracy: 0.5720\n",
      "Epoch 37/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6714 - accuracy: 0.5851 - val_loss: 0.6790 - val_accuracy: 0.5885\n",
      "Epoch 38/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6709 - accuracy: 0.5862 - val_loss: 0.6788 - val_accuracy: 0.5802\n",
      "Epoch 39/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6703 - accuracy: 0.5789 - val_loss: 0.6779 - val_accuracy: 0.5844\n",
      "Epoch 40/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6699 - accuracy: 0.5789 - val_loss: 0.6775 - val_accuracy: 0.5885\n",
      "Epoch 41/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6698 - accuracy: 0.5913 - val_loss: 0.6767 - val_accuracy: 0.5802\n",
      "Epoch 42/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6689 - accuracy: 0.5697 - val_loss: 0.6765 - val_accuracy: 0.5885\n",
      "Epoch 43/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6683 - accuracy: 0.5769 - val_loss: 0.6762 - val_accuracy: 0.5926\n",
      "Epoch 44/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6678 - accuracy: 0.5810 - val_loss: 0.6760 - val_accuracy: 0.5967\n",
      "Epoch 45/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6680 - accuracy: 0.5759 - val_loss: 0.6757 - val_accuracy: 0.5967\n",
      "Epoch 46/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6670 - accuracy: 0.5789 - val_loss: 0.6748 - val_accuracy: 0.5885\n",
      "Epoch 47/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6663 - accuracy: 0.5707 - val_loss: 0.6749 - val_accuracy: 0.5967\n",
      "Epoch 48/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6660 - accuracy: 0.5748 - val_loss: 0.6750 - val_accuracy: 0.5844\n",
      "Epoch 49/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6655 - accuracy: 0.5851 - val_loss: 0.6742 - val_accuracy: 0.5967\n",
      "Epoch 50/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.5779 - val_loss: 0.6739 - val_accuracy: 0.5967\n",
      "Epoch 51/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6643 - accuracy: 0.5810 - val_loss: 0.6736 - val_accuracy: 0.5967\n",
      "Epoch 52/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6643 - accuracy: 0.5748 - val_loss: 0.6730 - val_accuracy: 0.5926\n",
      "Epoch 53/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6638 - accuracy: 0.5676 - val_loss: 0.6734 - val_accuracy: 0.5844\n",
      "Epoch 54/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6630 - accuracy: 0.5851 - val_loss: 0.6726 - val_accuracy: 0.6008\n",
      "Epoch 55/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6628 - accuracy: 0.5831 - val_loss: 0.6725 - val_accuracy: 0.5926\n",
      "Epoch 56/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6625 - accuracy: 0.5676 - val_loss: 0.6729 - val_accuracy: 0.5802\n",
      "Epoch 57/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6626 - accuracy: 0.5882 - val_loss: 0.6710 - val_accuracy: 0.5926\n",
      "Epoch 58/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6613 - accuracy: 0.5779 - val_loss: 0.6709 - val_accuracy: 0.5885\n",
      "Epoch 59/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6608 - accuracy: 0.5893 - val_loss: 0.6706 - val_accuracy: 0.5885\n",
      "Epoch 60/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6605 - accuracy: 0.5841 - val_loss: 0.6707 - val_accuracy: 0.6008\n",
      "Epoch 61/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6600 - accuracy: 0.5831 - val_loss: 0.6700 - val_accuracy: 0.5885\n",
      "Epoch 62/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6599 - accuracy: 0.5882 - val_loss: 0.6692 - val_accuracy: 0.6008\n",
      "Epoch 63/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.5810 - val_loss: 0.6691 - val_accuracy: 0.5967\n",
      "Epoch 64/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6592 - accuracy: 0.5841 - val_loss: 0.6693 - val_accuracy: 0.6008\n",
      "Epoch 65/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6583 - accuracy: 0.5893 - val_loss: 0.6687 - val_accuracy: 0.5926\n",
      "Epoch 66/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.5862 - val_loss: 0.6689 - val_accuracy: 0.6008\n",
      "Epoch 67/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6588 - accuracy: 0.5779 - val_loss: 0.6683 - val_accuracy: 0.6008\n",
      "Epoch 68/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6571 - accuracy: 0.5913 - val_loss: 0.6670 - val_accuracy: 0.5885\n",
      "Epoch 69/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6569 - accuracy: 0.5862 - val_loss: 0.6671 - val_accuracy: 0.6008\n",
      "Epoch 70/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6562 - accuracy: 0.5872 - val_loss: 0.6666 - val_accuracy: 0.6008\n",
      "Epoch 71/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.5913 - val_loss: 0.6666 - val_accuracy: 0.5926\n",
      "Epoch 72/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.5882 - val_loss: 0.6662 - val_accuracy: 0.6008\n",
      "Epoch 73/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6554 - accuracy: 0.5924 - val_loss: 0.6653 - val_accuracy: 0.6049\n",
      "Epoch 74/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6549 - accuracy: 0.5893 - val_loss: 0.6650 - val_accuracy: 0.6049\n",
      "Epoch 75/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6544 - accuracy: 0.5862 - val_loss: 0.6644 - val_accuracy: 0.5885\n",
      "Epoch 76/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6539 - accuracy: 0.5986 - val_loss: 0.6652 - val_accuracy: 0.6049\n",
      "Epoch 77/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6539 - accuracy: 0.5862 - val_loss: 0.6641 - val_accuracy: 0.6049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6533 - accuracy: 0.5965 - val_loss: 0.6640 - val_accuracy: 0.6049\n",
      "Epoch 79/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6531 - accuracy: 0.5965 - val_loss: 0.6642 - val_accuracy: 0.6091\n",
      "Epoch 80/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6521 - accuracy: 0.5934 - val_loss: 0.6630 - val_accuracy: 0.6049\n",
      "Epoch 81/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6519 - accuracy: 0.5965 - val_loss: 0.6622 - val_accuracy: 0.6049\n",
      "Epoch 82/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6523 - accuracy: 0.5944 - val_loss: 0.6620 - val_accuracy: 0.6049\n",
      "Epoch 83/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6527 - accuracy: 0.5955 - val_loss: 0.6620 - val_accuracy: 0.6049\n",
      "Epoch 84/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6512 - accuracy: 0.5975 - val_loss: 0.6620 - val_accuracy: 0.6091\n",
      "Epoch 85/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.5944 - val_loss: 0.6616 - val_accuracy: 0.6091\n",
      "Epoch 86/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6505 - accuracy: 0.6078 - val_loss: 0.6607 - val_accuracy: 0.6173\n",
      "Epoch 87/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6496 - accuracy: 0.5996 - val_loss: 0.6614 - val_accuracy: 0.6049\n",
      "Epoch 88/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6493 - accuracy: 0.6027 - val_loss: 0.6595 - val_accuracy: 0.6132\n",
      "Epoch 89/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6488 - accuracy: 0.6068 - val_loss: 0.6590 - val_accuracy: 0.6132\n",
      "Epoch 90/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6486 - accuracy: 0.6037 - val_loss: 0.6585 - val_accuracy: 0.6132\n",
      "Epoch 91/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6479 - accuracy: 0.6068 - val_loss: 0.6581 - val_accuracy: 0.6132\n",
      "Epoch 92/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6483 - accuracy: 0.6068 - val_loss: 0.6590 - val_accuracy: 0.6049\n",
      "Epoch 93/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6471 - accuracy: 0.6089 - val_loss: 0.6574 - val_accuracy: 0.6173\n",
      "Epoch 94/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6473 - accuracy: 0.6027 - val_loss: 0.6570 - val_accuracy: 0.6173\n",
      "Epoch 95/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6467 - accuracy: 0.6161 - val_loss: 0.6568 - val_accuracy: 0.6214\n",
      "Epoch 96/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6161 - val_loss: 0.6566 - val_accuracy: 0.6173\n",
      "Epoch 97/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6455 - accuracy: 0.6182 - val_loss: 0.6558 - val_accuracy: 0.6214\n",
      "Epoch 98/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6472 - accuracy: 0.6130 - val_loss: 0.6571 - val_accuracy: 0.6173\n",
      "Epoch 99/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6455 - accuracy: 0.6182 - val_loss: 0.6575 - val_accuracy: 0.6132\n",
      "Epoch 100/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6442 - accuracy: 0.6099 - val_loss: 0.6546 - val_accuracy: 0.6173\n",
      "Epoch 101/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6442 - accuracy: 0.6171 - val_loss: 0.6554 - val_accuracy: 0.6091\n",
      "Epoch 102/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6431 - accuracy: 0.6151 - val_loss: 0.6541 - val_accuracy: 0.6214\n",
      "Epoch 103/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6428 - accuracy: 0.6171 - val_loss: 0.6529 - val_accuracy: 0.6296\n",
      "Epoch 104/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6426 - accuracy: 0.6223 - val_loss: 0.6529 - val_accuracy: 0.6255\n",
      "Epoch 105/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6414 - accuracy: 0.6254 - val_loss: 0.6520 - val_accuracy: 0.6214\n",
      "Epoch 106/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6413 - accuracy: 0.6285 - val_loss: 0.6511 - val_accuracy: 0.6173\n",
      "Epoch 107/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6415 - accuracy: 0.6275 - val_loss: 0.6506 - val_accuracy: 0.6296\n",
      "Epoch 108/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6403 - accuracy: 0.6244 - val_loss: 0.6500 - val_accuracy: 0.6296\n",
      "Epoch 109/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6397 - accuracy: 0.6254 - val_loss: 0.6494 - val_accuracy: 0.6255\n",
      "Epoch 110/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6390 - accuracy: 0.6347 - val_loss: 0.6502 - val_accuracy: 0.6255\n",
      "Epoch 111/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6401 - accuracy: 0.6264 - val_loss: 0.6492 - val_accuracy: 0.6255\n",
      "Epoch 112/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6384 - accuracy: 0.6305 - val_loss: 0.6499 - val_accuracy: 0.6337\n",
      "Epoch 113/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6376 - accuracy: 0.6264 - val_loss: 0.6473 - val_accuracy: 0.6379\n",
      "Epoch 114/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6377 - accuracy: 0.6398 - val_loss: 0.6499 - val_accuracy: 0.6296\n",
      "Epoch 115/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6379 - accuracy: 0.6285 - val_loss: 0.6493 - val_accuracy: 0.6296\n",
      "Epoch 116/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6368 - accuracy: 0.6244 - val_loss: 0.6460 - val_accuracy: 0.6337\n",
      "Epoch 117/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6367 - accuracy: 0.6460 - val_loss: 0.6475 - val_accuracy: 0.6337\n",
      "Epoch 118/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6351 - accuracy: 0.6419 - val_loss: 0.6463 - val_accuracy: 0.6337\n",
      "Epoch 119/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6348 - accuracy: 0.6378 - val_loss: 0.6464 - val_accuracy: 0.6337\n",
      "Epoch 120/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6342 - accuracy: 0.6347 - val_loss: 0.6457 - val_accuracy: 0.6337\n",
      "Epoch 121/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6337 - accuracy: 0.6347 - val_loss: 0.6437 - val_accuracy: 0.6255\n",
      "Epoch 122/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6333 - accuracy: 0.6409 - val_loss: 0.6432 - val_accuracy: 0.6461\n",
      "Epoch 123/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6326 - accuracy: 0.6357 - val_loss: 0.6434 - val_accuracy: 0.6337\n",
      "Epoch 124/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6333 - accuracy: 0.6367 - val_loss: 0.6410 - val_accuracy: 0.6543\n",
      "Epoch 125/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6322 - accuracy: 0.6429 - val_loss: 0.6403 - val_accuracy: 0.6502\n",
      "Epoch 126/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6323 - accuracy: 0.6522 - val_loss: 0.6404 - val_accuracy: 0.6461\n",
      "Epoch 127/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6307 - accuracy: 0.6543 - val_loss: 0.6402 - val_accuracy: 0.6337\n",
      "Epoch 128/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6305 - accuracy: 0.6522 - val_loss: 0.6391 - val_accuracy: 0.6502\n",
      "Epoch 129/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6584 - val_loss: 0.6404 - val_accuracy: 0.6379\n",
      "Epoch 130/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6287 - accuracy: 0.6594 - val_loss: 0.6406 - val_accuracy: 0.6420\n",
      "Epoch 131/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6309 - accuracy: 0.6450 - val_loss: 0.6367 - val_accuracy: 0.6502\n",
      "Epoch 132/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6281 - accuracy: 0.6543 - val_loss: 0.6369 - val_accuracy: 0.6543\n",
      "Epoch 133/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6284 - accuracy: 0.6502 - val_loss: 0.6355 - val_accuracy: 0.6708\n",
      "Epoch 134/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6271 - accuracy: 0.6502 - val_loss: 0.6349 - val_accuracy: 0.6708\n",
      "Epoch 135/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6263 - accuracy: 0.6563 - val_loss: 0.6347 - val_accuracy: 0.6502\n",
      "Epoch 136/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6250 - accuracy: 0.6615 - val_loss: 0.6367 - val_accuracy: 0.6461\n",
      "Epoch 137/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6246 - accuracy: 0.6543 - val_loss: 0.6328 - val_accuracy: 0.6708\n",
      "Epoch 138/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6245 - accuracy: 0.6625 - val_loss: 0.6347 - val_accuracy: 0.6543\n",
      "Epoch 139/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6253 - accuracy: 0.6574 - val_loss: 0.6317 - val_accuracy: 0.6461\n",
      "Epoch 140/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6218 - accuracy: 0.6677 - val_loss: 0.6310 - val_accuracy: 0.6461\n",
      "Epoch 141/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6220 - accuracy: 0.6636 - val_loss: 0.6310 - val_accuracy: 0.6584\n",
      "Epoch 142/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6212 - accuracy: 0.6698 - val_loss: 0.6299 - val_accuracy: 0.6584\n",
      "Epoch 143/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6205 - accuracy: 0.6739 - val_loss: 0.6303 - val_accuracy: 0.6626\n",
      "Epoch 144/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6193 - accuracy: 0.6656 - val_loss: 0.6275 - val_accuracy: 0.6749\n",
      "Epoch 145/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6196 - accuracy: 0.6656 - val_loss: 0.6270 - val_accuracy: 0.6667\n",
      "Epoch 146/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6192 - accuracy: 0.6708 - val_loss: 0.6271 - val_accuracy: 0.6584\n",
      "Epoch 147/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6172 - accuracy: 0.6687 - val_loss: 0.6254 - val_accuracy: 0.6749\n",
      "Epoch 148/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6177 - accuracy: 0.6760 - val_loss: 0.6262 - val_accuracy: 0.6749\n",
      "Epoch 149/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6163 - accuracy: 0.6780 - val_loss: 0.6239 - val_accuracy: 0.6749\n",
      "Epoch 150/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6152 - accuracy: 0.6770 - val_loss: 0.6239 - val_accuracy: 0.6626\n",
      "Epoch 151/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6148 - accuracy: 0.6821 - val_loss: 0.6238 - val_accuracy: 0.6708\n",
      "Epoch 152/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6142 - accuracy: 0.6718 - val_loss: 0.6236 - val_accuracy: 0.6914\n",
      "Epoch 153/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6137 - accuracy: 0.6780 - val_loss: 0.6218 - val_accuracy: 0.6872\n",
      "Epoch 154/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6131 - accuracy: 0.6698 - val_loss: 0.6238 - val_accuracy: 0.6584\n",
      "Epoch 155/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6142 - accuracy: 0.6729 - val_loss: 0.6189 - val_accuracy: 0.6708\n",
      "Epoch 156/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6110 - accuracy: 0.6863 - val_loss: 0.6185 - val_accuracy: 0.6790\n",
      "Epoch 157/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6104 - accuracy: 0.6842 - val_loss: 0.6174 - val_accuracy: 0.6749\n",
      "Epoch 158/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6088 - accuracy: 0.6770 - val_loss: 0.6164 - val_accuracy: 0.6708\n",
      "Epoch 159/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6077 - accuracy: 0.6801 - val_loss: 0.6181 - val_accuracy: 0.6543\n",
      "Epoch 160/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6083 - accuracy: 0.6739 - val_loss: 0.6148 - val_accuracy: 0.6708\n",
      "Epoch 161/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6076 - accuracy: 0.6863 - val_loss: 0.6142 - val_accuracy: 0.6955\n",
      "Epoch 162/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6052 - accuracy: 0.6976 - val_loss: 0.6127 - val_accuracy: 0.6749\n",
      "Epoch 163/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6068 - accuracy: 0.6873 - val_loss: 0.6120 - val_accuracy: 0.6708\n",
      "Epoch 164/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6054 - accuracy: 0.6811 - val_loss: 0.6146 - val_accuracy: 0.6708\n",
      "Epoch 165/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6039 - accuracy: 0.6894 - val_loss: 0.6100 - val_accuracy: 0.6831\n",
      "Epoch 166/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6067 - accuracy: 0.6821 - val_loss: 0.6095 - val_accuracy: 0.6831\n",
      "Epoch 167/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6011 - accuracy: 0.6914 - val_loss: 0.6088 - val_accuracy: 0.6872\n",
      "Epoch 168/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6018 - accuracy: 0.6925 - val_loss: 0.6081 - val_accuracy: 0.6790\n",
      "Epoch 169/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6058 - accuracy: 0.6687 - val_loss: 0.6101 - val_accuracy: 0.7119\n",
      "Epoch 170/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5986 - accuracy: 0.6832 - val_loss: 0.6157 - val_accuracy: 0.6708\n",
      "Epoch 171/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6027 - accuracy: 0.6811 - val_loss: 0.6349 - val_accuracy: 0.6255\n",
      "Epoch 172/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6013 - accuracy: 0.6863 - val_loss: 0.6066 - val_accuracy: 0.7119\n",
      "Epoch 173/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5949 - accuracy: 0.6956 - val_loss: 0.6040 - val_accuracy: 0.6872\n",
      "Epoch 174/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6011 - accuracy: 0.6749 - val_loss: 0.6129 - val_accuracy: 0.6708\n",
      "Epoch 175/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5934 - accuracy: 0.7007 - val_loss: 0.6066 - val_accuracy: 0.6914\n",
      "Epoch 176/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5937 - accuracy: 0.6914 - val_loss: 0.6124 - val_accuracy: 0.6790\n",
      "Epoch 177/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6096 - accuracy: 0.6770 - val_loss: 0.6085 - val_accuracy: 0.6790\n",
      "Epoch 178/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5947 - accuracy: 0.6966 - val_loss: 0.6136 - val_accuracy: 0.6790\n",
      "Epoch 179/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5929 - accuracy: 0.6904 - val_loss: 0.5989 - val_accuracy: 0.7119\n",
      "Epoch 180/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5989 - accuracy: 0.6801 - val_loss: 0.6194 - val_accuracy: 0.6379\n",
      "Epoch 181/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5956 - accuracy: 0.6739 - val_loss: 0.5971 - val_accuracy: 0.7078\n",
      "Epoch 182/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5862 - accuracy: 0.6997 - val_loss: 0.6086 - val_accuracy: 0.6790\n",
      "Epoch 183/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5966 - accuracy: 0.6925 - val_loss: 0.6143 - val_accuracy: 0.6502\n",
      "Epoch 184/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5940 - accuracy: 0.7069 - val_loss: 0.5989 - val_accuracy: 0.7160\n",
      "Epoch 185/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5878 - accuracy: 0.6883 - val_loss: 0.5948 - val_accuracy: 0.7037\n",
      "Epoch 186/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5838 - accuracy: 0.7131 - val_loss: 0.6041 - val_accuracy: 0.6872\n",
      "Epoch 187/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5861 - accuracy: 0.7028 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
      "Epoch 188/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5947 - accuracy: 0.6852 - val_loss: 0.6032 - val_accuracy: 0.6831\n",
      "Epoch 189/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5894 - accuracy: 0.6863 - val_loss: 0.5894 - val_accuracy: 0.7037\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5823 - accuracy: 0.7018 - val_loss: 0.5979 - val_accuracy: 0.7037\n",
      "Epoch 191/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6000 - accuracy: 0.6667 - val_loss: 0.6193 - val_accuracy: 0.6337\n",
      "Epoch 192/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5869 - accuracy: 0.6883 - val_loss: 0.6159 - val_accuracy: 0.6296\n",
      "Epoch 193/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6209 - accuracy: 0.6388 - val_loss: 0.5972 - val_accuracy: 0.7037\n",
      "Epoch 194/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5875 - accuracy: 0.6801 - val_loss: 0.5879 - val_accuracy: 0.7202\n",
      "Epoch 195/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.7007 - val_loss: 0.5926 - val_accuracy: 0.7160\n",
      "Epoch 196/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5732 - accuracy: 0.7059 - val_loss: 0.5873 - val_accuracy: 0.7202\n",
      "Epoch 197/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5701 - accuracy: 0.7059 - val_loss: 0.5860 - val_accuracy: 0.7160\n",
      "Epoch 198/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5753 - accuracy: 0.6997 - val_loss: 0.5834 - val_accuracy: 0.7078\n",
      "Epoch 199/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5744 - accuracy: 0.7028 - val_loss: 0.5841 - val_accuracy: 0.7119\n",
      "Epoch 200/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5783 - accuracy: 0.7100 - val_loss: 0.5975 - val_accuracy: 0.6749\n",
      "Epoch 201/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5841 - accuracy: 0.6966 - val_loss: 0.6116 - val_accuracy: 0.6502\n",
      "Epoch 202/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6257 - accuracy: 0.6285 - val_loss: 0.5930 - val_accuracy: 0.6872\n",
      "Epoch 203/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5734 - accuracy: 0.7090 - val_loss: 0.5783 - val_accuracy: 0.7325\n",
      "Epoch 204/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5686 - accuracy: 0.7059 - val_loss: 0.5883 - val_accuracy: 0.7037\n",
      "Epoch 205/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7234 - val_loss: 0.5772 - val_accuracy: 0.7366\n",
      "Epoch 206/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5640 - accuracy: 0.7245 - val_loss: 0.5820 - val_accuracy: 0.7119\n",
      "Epoch 207/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7049 - val_loss: 0.5891 - val_accuracy: 0.6749\n",
      "Epoch 208/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5684 - accuracy: 0.6997 - val_loss: 0.5734 - val_accuracy: 0.7449\n",
      "Epoch 209/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5593 - accuracy: 0.7234 - val_loss: 0.5816 - val_accuracy: 0.7037\n",
      "Epoch 210/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5799 - accuracy: 0.6842 - val_loss: 0.6233 - val_accuracy: 0.6255\n",
      "Epoch 211/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6260 - accuracy: 0.6254 - val_loss: 0.5806 - val_accuracy: 0.7078\n",
      "Epoch 212/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5670 - accuracy: 0.7090 - val_loss: 0.5826 - val_accuracy: 0.6914\n",
      "Epoch 213/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5587 - accuracy: 0.7307 - val_loss: 0.5726 - val_accuracy: 0.7160\n",
      "Epoch 214/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7348 - val_loss: 0.5668 - val_accuracy: 0.7449\n",
      "Epoch 215/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5621 - accuracy: 0.7079 - val_loss: 0.5825 - val_accuracy: 0.6831\n",
      "Epoch 216/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5713 - accuracy: 0.6883 - val_loss: 0.5674 - val_accuracy: 0.7490\n",
      "Epoch 217/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5516 - accuracy: 0.7337 - val_loss: 0.5652 - val_accuracy: 0.7490\n",
      "Epoch 218/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.7399 - val_loss: 0.5844 - val_accuracy: 0.6790\n",
      "Epoch 219/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5591 - accuracy: 0.7090 - val_loss: 0.5698 - val_accuracy: 0.7325\n",
      "Epoch 220/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5540 - accuracy: 0.7286 - val_loss: 0.6054 - val_accuracy: 0.6461\n",
      "Epoch 221/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7172 - val_loss: 0.6020 - val_accuracy: 0.6420\n",
      "Epoch 222/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.6863 - val_loss: 0.5752 - val_accuracy: 0.7037\n",
      "Epoch 223/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5920 - accuracy: 0.6904 - val_loss: 0.5703 - val_accuracy: 0.7284\n",
      "Epoch 224/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7389 - val_loss: 0.5665 - val_accuracy: 0.7160\n",
      "Epoch 225/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5719 - accuracy: 0.6914 - val_loss: 0.5982 - val_accuracy: 0.6420\n",
      "Epoch 226/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.6976 - val_loss: 0.5611 - val_accuracy: 0.7572\n",
      "Epoch 227/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7399 - val_loss: 0.5582 - val_accuracy: 0.7695\n",
      "Epoch 228/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7358 - val_loss: 0.5657 - val_accuracy: 0.7160\n",
      "Epoch 229/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5608 - accuracy: 0.7028 - val_loss: 0.5606 - val_accuracy: 0.7449\n",
      "Epoch 230/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7461 - val_loss: 0.6210 - val_accuracy: 0.6296\n",
      "Epoch 231/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6057 - accuracy: 0.6543 - val_loss: 0.5673 - val_accuracy: 0.7119\n",
      "Epoch 232/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7389 - val_loss: 0.5770 - val_accuracy: 0.6708\n",
      "Epoch 233/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5506 - accuracy: 0.7203 - val_loss: 0.5556 - val_accuracy: 0.7407\n",
      "Epoch 234/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5304 - accuracy: 0.7637 - val_loss: 0.5515 - val_accuracy: 0.7737\n",
      "Epoch 235/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7616 - val_loss: 0.5478 - val_accuracy: 0.7531\n",
      "Epoch 236/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5262 - accuracy: 0.7554 - val_loss: 0.5569 - val_accuracy: 0.7202\n",
      "Epoch 237/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5515 - accuracy: 0.7234 - val_loss: 0.5894 - val_accuracy: 0.6420\n",
      "Epoch 238/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7265 - val_loss: 0.5525 - val_accuracy: 0.7160\n",
      "Epoch 239/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5249 - accuracy: 0.7771 - val_loss: 0.5443 - val_accuracy: 0.7613\n",
      "Epoch 240/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7296 - val_loss: 0.5530 - val_accuracy: 0.7325\n",
      "Epoch 241/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5241 - accuracy: 0.7441 - val_loss: 0.5829 - val_accuracy: 0.6708\n",
      "Epoch 242/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7069 - val_loss: 0.5520 - val_accuracy: 0.7325\n",
      "Epoch 243/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5263 - accuracy: 0.7482 - val_loss: 0.5539 - val_accuracy: 0.7160\n",
      "Epoch 244/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6023 - accuracy: 0.6656 - val_loss: 0.5549 - val_accuracy: 0.7243\n",
      "Epoch 245/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.6687 - val_loss: 0.6047 - val_accuracy: 0.6626\n",
      "Epoch 246/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.7430 - val_loss: 0.5412 - val_accuracy: 0.7901\n",
      "Epoch 247/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5266 - accuracy: 0.7554 - val_loss: 0.6397 - val_accuracy: 0.6173\n",
      "Epoch 248/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5309 - accuracy: 0.7276 - val_loss: 0.5346 - val_accuracy: 0.7695\n",
      "Epoch 249/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5221 - accuracy: 0.7668 - val_loss: 0.5723 - val_accuracy: 0.6790\n",
      "Epoch 250/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5147 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7737\n",
      "Epoch 251/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5249 - accuracy: 0.7451 - val_loss: 0.5345 - val_accuracy: 0.7778\n",
      "Epoch 252/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5802 - accuracy: 0.6821 - val_loss: 0.5833 - val_accuracy: 0.6667\n",
      "Epoch 253/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7276 - val_loss: 0.5351 - val_accuracy: 0.7613\n",
      "Epoch 254/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5049 - accuracy: 0.7874 - val_loss: 0.5287 - val_accuracy: 0.7737\n",
      "Epoch 255/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5295 - accuracy: 0.7276 - val_loss: 0.5418 - val_accuracy: 0.7449\n",
      "Epoch 256/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5059 - accuracy: 0.7781 - val_loss: 0.5424 - val_accuracy: 0.7160\n",
      "Epoch 257/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7255 - val_loss: 0.5549 - val_accuracy: 0.6872\n",
      "Epoch 258/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5104 - accuracy: 0.7699 - val_loss: 0.5284 - val_accuracy: 0.7860\n",
      "Epoch 259/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5190 - accuracy: 0.7564 - val_loss: 0.5635 - val_accuracy: 0.6831\n",
      "Epoch 260/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.7657 - val_loss: 0.5225 - val_accuracy: 0.7819\n",
      "Epoch 261/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5110 - accuracy: 0.7482 - val_loss: 0.5225 - val_accuracy: 0.7819\n",
      "Epoch 262/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5069 - accuracy: 0.7595 - val_loss: 0.6121 - val_accuracy: 0.6379\n",
      "Epoch 263/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5954 - accuracy: 0.6646 - val_loss: 0.5275 - val_accuracy: 0.7531\n",
      "Epoch 264/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4982 - accuracy: 0.7843 - val_loss: 0.5354 - val_accuracy: 0.7078\n",
      "Epoch 265/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4908 - accuracy: 0.7853 - val_loss: 0.5193 - val_accuracy: 0.7778\n",
      "Epoch 266/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4863 - accuracy: 0.7843 - val_loss: 0.5268 - val_accuracy: 0.7119\n",
      "Epoch 267/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4847 - accuracy: 0.7926 - val_loss: 0.5326 - val_accuracy: 0.7160\n",
      "Epoch 268/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4846 - accuracy: 0.8019 - val_loss: 0.5414 - val_accuracy: 0.6914\n",
      "Epoch 269/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7255 - val_loss: 0.5217 - val_accuracy: 0.7819\n",
      "Epoch 270/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5567 - accuracy: 0.7018 - val_loss: 0.6450 - val_accuracy: 0.6296\n",
      "Epoch 271/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5530 - accuracy: 0.6976 - val_loss: 0.5133 - val_accuracy: 0.7901\n",
      "Epoch 272/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.7936 - val_loss: 0.5112 - val_accuracy: 0.7942\n",
      "Epoch 273/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4887 - accuracy: 0.7802 - val_loss: 0.5467 - val_accuracy: 0.6914\n",
      "Epoch 274/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4831 - accuracy: 0.7967 - val_loss: 0.5072 - val_accuracy: 0.7901\n",
      "Epoch 275/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5123 - accuracy: 0.7420 - val_loss: 0.5224 - val_accuracy: 0.7037\n",
      "Epoch 276/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5229 - accuracy: 0.7327 - val_loss: 0.5073 - val_accuracy: 0.7901\n",
      "Epoch 277/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4867 - accuracy: 0.7905 - val_loss: 0.5527 - val_accuracy: 0.7119\n",
      "Epoch 278/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4710 - accuracy: 0.8142 - val_loss: 0.5187 - val_accuracy: 0.7243\n",
      "Epoch 279/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4867 - accuracy: 0.7802 - val_loss: 0.5125 - val_accuracy: 0.7695\n",
      "Epoch 280/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4778 - accuracy: 0.7926 - val_loss: 0.5131 - val_accuracy: 0.7325\n",
      "Epoch 281/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4633 - accuracy: 0.8142 - val_loss: 0.4990 - val_accuracy: 0.7901\n",
      "Epoch 282/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7317 - val_loss: 0.5954 - val_accuracy: 0.6708\n",
      "Epoch 283/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4981 - accuracy: 0.7761 - val_loss: 0.6220 - val_accuracy: 0.6379\n",
      "Epoch 284/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5543 - accuracy: 0.6801 - val_loss: 0.5749 - val_accuracy: 0.6914\n",
      "Epoch 285/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5124 - accuracy: 0.7472 - val_loss: 0.5595 - val_accuracy: 0.6626\n",
      "Epoch 286/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4937 - accuracy: 0.7606 - val_loss: 0.5771 - val_accuracy: 0.6872\n",
      "Epoch 287/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4920 - accuracy: 0.7668 - val_loss: 0.4963 - val_accuracy: 0.7901\n",
      "Epoch 288/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4633 - accuracy: 0.8122 - val_loss: 0.4934 - val_accuracy: 0.7984\n",
      "Epoch 289/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.7895 - val_loss: 0.5080 - val_accuracy: 0.7325\n",
      "Epoch 290/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4515 - accuracy: 0.8163 - val_loss: 0.4856 - val_accuracy: 0.8107\n",
      "Epoch 291/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4754 - accuracy: 0.7761 - val_loss: 0.4883 - val_accuracy: 0.7942\n",
      "Epoch 292/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4466 - accuracy: 0.8246 - val_loss: 0.4864 - val_accuracy: 0.7942\n",
      "Epoch 293/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4523 - accuracy: 0.8101 - val_loss: 0.5055 - val_accuracy: 0.7613\n",
      "Epoch 294/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4520 - accuracy: 0.8132 - val_loss: 0.5300 - val_accuracy: 0.7160\n",
      "Epoch 295/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.7616 - val_loss: 0.4848 - val_accuracy: 0.7860\n",
      "Epoch 296/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5519 - accuracy: 0.7162 - val_loss: 0.5713 - val_accuracy: 0.6872\n",
      "Epoch 297/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4948 - accuracy: 0.7564 - val_loss: 0.4861 - val_accuracy: 0.8025\n",
      "Epoch 298/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4402 - accuracy: 0.8359 - val_loss: 0.4778 - val_accuracy: 0.8189\n",
      "Epoch 299/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5047 - accuracy: 0.7441 - val_loss: 0.5184 - val_accuracy: 0.7078\n",
      "Epoch 300/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8235 - val_loss: 0.4767 - val_accuracy: 0.7984\n",
      "Epoch 301/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4342 - accuracy: 0.8473 - val_loss: 0.4835 - val_accuracy: 0.7819\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4303 - accuracy: 0.8411 - val_loss: 0.4757 - val_accuracy: 0.7819\n",
      "Epoch 303/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4732 - accuracy: 0.7853 - val_loss: 0.5089 - val_accuracy: 0.7366\n",
      "Epoch 304/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.7585 - val_loss: 0.5162 - val_accuracy: 0.7243\n",
      "Epoch 305/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4271 - accuracy: 0.8349 - val_loss: 0.5165 - val_accuracy: 0.7325\n",
      "Epoch 306/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8277 - val_loss: 0.4827 - val_accuracy: 0.7613\n",
      "Epoch 307/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4744 - accuracy: 0.7781 - val_loss: 0.5493 - val_accuracy: 0.6872\n",
      "Epoch 308/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4636 - accuracy: 0.7709 - val_loss: 0.5615 - val_accuracy: 0.7037\n",
      "Epoch 309/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4318 - accuracy: 0.8328 - val_loss: 0.4625 - val_accuracy: 0.8189\n",
      "Epoch 310/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4323 - accuracy: 0.8204 - val_loss: 0.5341 - val_accuracy: 0.7202\n",
      "Epoch 311/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4977 - accuracy: 0.7451 - val_loss: 0.4685 - val_accuracy: 0.8066\n",
      "Epoch 312/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4593 - accuracy: 0.7967 - val_loss: 0.5690 - val_accuracy: 0.6872\n",
      "Epoch 313/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4218 - accuracy: 0.8390 - val_loss: 0.4592 - val_accuracy: 0.8189\n",
      "Epoch 314/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4230 - accuracy: 0.8318 - val_loss: 0.4619 - val_accuracy: 0.7984\n",
      "Epoch 315/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4231 - accuracy: 0.8338 - val_loss: 0.5966 - val_accuracy: 0.6708\n",
      "Epoch 316/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5252 - accuracy: 0.7214 - val_loss: 0.5033 - val_accuracy: 0.7407\n",
      "Epoch 317/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4577 - accuracy: 0.7936 - val_loss: 0.4881 - val_accuracy: 0.7572\n",
      "Epoch 318/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.8462 - val_loss: 0.4571 - val_accuracy: 0.7860\n",
      "Epoch 319/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4117 - accuracy: 0.8473 - val_loss: 0.4622 - val_accuracy: 0.7860\n",
      "Epoch 320/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4134 - accuracy: 0.8359 - val_loss: 0.4736 - val_accuracy: 0.7654\n",
      "Epoch 321/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4068 - accuracy: 0.8411 - val_loss: 0.4445 - val_accuracy: 0.8148\n",
      "Epoch 322/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3984 - accuracy: 0.8607 - val_loss: 0.4465 - val_accuracy: 0.8230\n",
      "Epoch 323/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3963 - accuracy: 0.8586 - val_loss: 0.4446 - val_accuracy: 0.8230\n",
      "Epoch 324/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3890 - accuracy: 0.8700 - val_loss: 0.4424 - val_accuracy: 0.8066\n",
      "Epoch 325/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.7853 - val_loss: 0.6785 - val_accuracy: 0.6255\n",
      "Epoch 326/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5494 - accuracy: 0.7049 - val_loss: 0.4691 - val_accuracy: 0.7613\n",
      "Epoch 327/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3978 - accuracy: 0.8524 - val_loss: 0.4426 - val_accuracy: 0.8066\n",
      "Epoch 328/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3882 - accuracy: 0.8689 - val_loss: 0.4372 - val_accuracy: 0.8272\n",
      "Epoch 329/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8349 - val_loss: 0.4628 - val_accuracy: 0.7860\n",
      "Epoch 330/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3877 - accuracy: 0.8576 - val_loss: 0.4771 - val_accuracy: 0.7490\n",
      "Epoch 331/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.7554 - val_loss: 0.5181 - val_accuracy: 0.7366\n",
      "Epoch 332/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4407 - accuracy: 0.7905 - val_loss: 0.4847 - val_accuracy: 0.7407\n",
      "Epoch 333/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5029 - accuracy: 0.7368 - val_loss: 0.5139 - val_accuracy: 0.7366\n",
      "Epoch 334/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4017 - accuracy: 0.8473 - val_loss: 0.5208 - val_accuracy: 0.7366\n",
      "Epoch 335/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4663 - accuracy: 0.7657 - val_loss: 0.4573 - val_accuracy: 0.7901\n",
      "Epoch 336/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4251 - accuracy: 0.8008 - val_loss: 0.5220 - val_accuracy: 0.7407\n",
      "Epoch 337/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3967 - accuracy: 0.8338 - val_loss: 0.4364 - val_accuracy: 0.7984\n",
      "Epoch 338/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3727 - accuracy: 0.8658 - val_loss: 0.4433 - val_accuracy: 0.7860\n",
      "Epoch 339/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3734 - accuracy: 0.8731 - val_loss: 0.4220 - val_accuracy: 0.8189\n",
      "Epoch 340/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3675 - accuracy: 0.8824 - val_loss: 0.4211 - val_accuracy: 0.8189\n",
      "Epoch 341/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3640 - accuracy: 0.8865 - val_loss: 0.4362 - val_accuracy: 0.7901\n",
      "Epoch 342/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3755 - accuracy: 0.8576 - val_loss: 0.4149 - val_accuracy: 0.8313\n",
      "Epoch 343/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4421 - accuracy: 0.7895 - val_loss: 0.5878 - val_accuracy: 0.6955\n",
      "Epoch 344/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5978 - accuracy: 0.6667 - val_loss: 0.4617 - val_accuracy: 0.7778\n",
      "Epoch 345/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3815 - accuracy: 0.8638 - val_loss: 0.4220 - val_accuracy: 0.8189\n",
      "Epoch 346/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3650 - accuracy: 0.8844 - val_loss: 0.4311 - val_accuracy: 0.8066\n",
      "Epoch 347/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3579 - accuracy: 0.8885 - val_loss: 0.4110 - val_accuracy: 0.8395\n",
      "Epoch 348/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3664 - accuracy: 0.8689 - val_loss: 0.4263 - val_accuracy: 0.8107\n",
      "Epoch 349/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3573 - accuracy: 0.8854 - val_loss: 0.4486 - val_accuracy: 0.7984\n",
      "Epoch 350/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4102 - accuracy: 0.8173 - val_loss: 0.5521 - val_accuracy: 0.6872\n",
      "Epoch 351/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4320 - accuracy: 0.7895 - val_loss: 0.4465 - val_accuracy: 0.7942\n",
      "Epoch 352/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3632 - accuracy: 0.8679 - val_loss: 0.4066 - val_accuracy: 0.8354\n",
      "Epoch 353/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3465 - accuracy: 0.8865 - val_loss: 0.3997 - val_accuracy: 0.8354\n",
      "Epoch 354/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.8958 - val_loss: 0.4253 - val_accuracy: 0.7942\n",
      "Epoch 355/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3492 - accuracy: 0.8700 - val_loss: 0.4285 - val_accuracy: 0.7942\n",
      "Epoch 356/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4772 - accuracy: 0.7513 - val_loss: 0.4136 - val_accuracy: 0.8189\n",
      "Epoch 357/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3805 - accuracy: 0.8483 - val_loss: 0.4255 - val_accuracy: 0.8066\n",
      "Epoch 358/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3539 - accuracy: 0.8762 - val_loss: 0.4001 - val_accuracy: 0.8395\n",
      "Epoch 359/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3381 - accuracy: 0.8958 - val_loss: 0.3952 - val_accuracy: 0.8313\n",
      "Epoch 360/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8989 - val_loss: 0.3897 - val_accuracy: 0.8436\n",
      "Epoch 361/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8927 - val_loss: 0.5124 - val_accuracy: 0.7490\n",
      "Epoch 362/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6085 - accuracy: 0.6791 - val_loss: 0.4452 - val_accuracy: 0.7860\n",
      "Epoch 363/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3476 - accuracy: 0.8824 - val_loss: 0.3941 - val_accuracy: 0.8519\n",
      "Epoch 364/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8875 - val_loss: 0.3919 - val_accuracy: 0.8436\n",
      "Epoch 365/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3488 - accuracy: 0.8824 - val_loss: 0.4182 - val_accuracy: 0.8148\n",
      "Epoch 366/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3279 - accuracy: 0.9051 - val_loss: 0.3821 - val_accuracy: 0.8560\n",
      "Epoch 367/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3347 - accuracy: 0.8896 - val_loss: 0.4380 - val_accuracy: 0.7860\n",
      "Epoch 368/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3718 - accuracy: 0.8369 - val_loss: 0.4259 - val_accuracy: 0.8066\n",
      "Epoch 369/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3313 - accuracy: 0.8720 - val_loss: 0.4618 - val_accuracy: 0.7737\n",
      "Epoch 370/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4264 - accuracy: 0.7926 - val_loss: 0.3997 - val_accuracy: 0.8272\n",
      "Epoch 371/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3396 - accuracy: 0.8720 - val_loss: 0.4413 - val_accuracy: 0.7984\n",
      "Epoch 372/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3704 - accuracy: 0.8369 - val_loss: 0.4610 - val_accuracy: 0.7695\n",
      "Epoch 373/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3624 - accuracy: 0.8535 - val_loss: 0.3908 - val_accuracy: 0.8272\n",
      "Epoch 374/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3273 - accuracy: 0.8865 - val_loss: 0.3780 - val_accuracy: 0.8477\n",
      "Epoch 375/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3075 - accuracy: 0.9133 - val_loss: 0.3732 - val_accuracy: 0.8642\n",
      "Epoch 376/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8576 - val_loss: 0.4498 - val_accuracy: 0.7942\n",
      "Epoch 377/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3890 - accuracy: 0.8204 - val_loss: 0.5567 - val_accuracy: 0.6914\n",
      "Epoch 378/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4089 - accuracy: 0.8029 - val_loss: 0.4090 - val_accuracy: 0.8148\n",
      "Epoch 379/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3060 - accuracy: 0.9061 - val_loss: 0.3802 - val_accuracy: 0.8313\n",
      "Epoch 380/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3003 - accuracy: 0.9216 - val_loss: 0.3738 - val_accuracy: 0.8354\n",
      "Epoch 381/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8999 - val_loss: 0.3628 - val_accuracy: 0.8642\n",
      "Epoch 382/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3103 - accuracy: 0.8989 - val_loss: 0.3937 - val_accuracy: 0.8272\n",
      "Epoch 383/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3767 - accuracy: 0.8235 - val_loss: 0.4459 - val_accuracy: 0.7572\n",
      "Epoch 384/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4310 - accuracy: 0.7668 - val_loss: 0.4324 - val_accuracy: 0.7984\n",
      "Epoch 385/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3151 - accuracy: 0.8906 - val_loss: 0.3661 - val_accuracy: 0.8601\n",
      "Epoch 386/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2975 - accuracy: 0.9164 - val_loss: 0.3620 - val_accuracy: 0.8477\n",
      "Epoch 387/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2906 - accuracy: 0.9205 - val_loss: 0.4407 - val_accuracy: 0.8025\n",
      "Epoch 388/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3453 - accuracy: 0.8555 - val_loss: 0.4746 - val_accuracy: 0.7572\n",
      "Epoch 389/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.7554 - val_loss: 0.5249 - val_accuracy: 0.7325\n",
      "Epoch 390/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.8916 - val_loss: 0.3528 - val_accuracy: 0.8724\n",
      "Epoch 391/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2927 - accuracy: 0.9102 - val_loss: 0.3552 - val_accuracy: 0.8519\n",
      "Epoch 392/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2841 - accuracy: 0.9154 - val_loss: 0.3538 - val_accuracy: 0.8436\n",
      "Epoch 393/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2899 - accuracy: 0.9133 - val_loss: 0.4217 - val_accuracy: 0.8107\n",
      "Epoch 394/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3862 - accuracy: 0.8142 - val_loss: 0.3780 - val_accuracy: 0.8395\n",
      "Epoch 395/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3476 - accuracy: 0.8514 - val_loss: 0.3808 - val_accuracy: 0.8313\n",
      "Epoch 396/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2842 - accuracy: 0.9143 - val_loss: 0.3846 - val_accuracy: 0.8272\n",
      "Epoch 397/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3318 - accuracy: 0.8617 - val_loss: 0.4399 - val_accuracy: 0.7984\n",
      "Epoch 398/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2775 - accuracy: 0.9236 - val_loss: 0.3350 - val_accuracy: 0.8930\n",
      "Epoch 399/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2793 - accuracy: 0.9112 - val_loss: 0.3552 - val_accuracy: 0.8519\n",
      "Epoch 400/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2849 - accuracy: 0.9112 - val_loss: 0.4418 - val_accuracy: 0.8025\n",
      "Epoch 401/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2963 - accuracy: 0.8906 - val_loss: 0.3394 - val_accuracy: 0.8930\n",
      "Epoch 402/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.9123 - val_loss: 0.3671 - val_accuracy: 0.8354\n",
      "Epoch 403/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2655 - accuracy: 0.9267 - val_loss: 0.3359 - val_accuracy: 0.8930\n",
      "Epoch 404/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3125 - accuracy: 0.8710 - val_loss: 0.6137 - val_accuracy: 0.6708\n",
      "Epoch 405/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4549 - accuracy: 0.7616 - val_loss: 0.5291 - val_accuracy: 0.7243\n",
      "Epoch 406/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3729 - accuracy: 0.8246 - val_loss: 0.3391 - val_accuracy: 0.8642\n",
      "Epoch 407/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2959 - accuracy: 0.9009 - val_loss: 0.3633 - val_accuracy: 0.8642\n",
      "Epoch 408/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2747 - accuracy: 0.9123 - val_loss: 0.3331 - val_accuracy: 0.8971\n",
      "Epoch 409/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2618 - accuracy: 0.9247 - val_loss: 0.3670 - val_accuracy: 0.8354\n",
      "Epoch 410/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2664 - accuracy: 0.9288 - val_loss: 0.4811 - val_accuracy: 0.7572\n",
      "Epoch 411/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.7915 - val_loss: 0.3723 - val_accuracy: 0.8560\n",
      "Epoch 412/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2951 - accuracy: 0.8978 - val_loss: 0.3616 - val_accuracy: 0.8395\n",
      "Epoch 413/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2734 - accuracy: 0.9082 - val_loss: 0.3274 - val_accuracy: 0.9053\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2492 - accuracy: 0.9381 - val_loss: 0.3179 - val_accuracy: 0.8807\n",
      "Epoch 415/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2831 - accuracy: 0.8885 - val_loss: 0.3305 - val_accuracy: 0.8889\n",
      "Epoch 416/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.9309 - val_loss: 0.3159 - val_accuracy: 0.8683\n",
      "Epoch 417/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2712 - accuracy: 0.9143 - val_loss: 0.5541 - val_accuracy: 0.7160\n",
      "Epoch 418/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4243 - accuracy: 0.7792 - val_loss: 0.3820 - val_accuracy: 0.8395\n",
      "Epoch 419/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2677 - accuracy: 0.9154 - val_loss: 0.3367 - val_accuracy: 0.8724\n",
      "Epoch 420/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3335 - accuracy: 0.8545 - val_loss: 0.3740 - val_accuracy: 0.8395\n",
      "Epoch 421/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2478 - accuracy: 0.9236 - val_loss: 0.3074 - val_accuracy: 0.8930\n",
      "Epoch 422/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2362 - accuracy: 0.9370 - val_loss: 0.3143 - val_accuracy: 0.8765\n",
      "Epoch 423/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2382 - accuracy: 0.9350 - val_loss: 0.3009 - val_accuracy: 0.9012\n",
      "Epoch 424/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2303 - accuracy: 0.9401 - val_loss: 0.3246 - val_accuracy: 0.8642\n",
      "Epoch 425/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3347 - accuracy: 0.8524 - val_loss: 0.3868 - val_accuracy: 0.8189\n",
      "Epoch 426/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2695 - accuracy: 0.9061 - val_loss: 0.4048 - val_accuracy: 0.8107\n",
      "Epoch 427/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2744 - accuracy: 0.8999 - val_loss: 0.3072 - val_accuracy: 0.9136\n",
      "Epoch 428/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2393 - accuracy: 0.9278 - val_loss: 0.3399 - val_accuracy: 0.8519\n",
      "Epoch 429/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3083 - accuracy: 0.8679 - val_loss: 0.3668 - val_accuracy: 0.8436\n",
      "Epoch 430/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2918 - accuracy: 0.8865 - val_loss: 0.3140 - val_accuracy: 0.8601\n",
      "Epoch 431/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2232 - accuracy: 0.9432 - val_loss: 0.2999 - val_accuracy: 0.8807\n",
      "Epoch 432/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2366 - accuracy: 0.9298 - val_loss: 0.3000 - val_accuracy: 0.9095\n",
      "Epoch 433/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2358 - accuracy: 0.9226 - val_loss: 0.2943 - val_accuracy: 0.9012\n",
      "Epoch 434/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2238 - accuracy: 0.9360 - val_loss: 0.3008 - val_accuracy: 0.9095\n",
      "Epoch 435/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2765 - accuracy: 0.8968 - val_loss: 0.5422 - val_accuracy: 0.7325\n",
      "Epoch 436/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3079 - accuracy: 0.8669 - val_loss: 0.3055 - val_accuracy: 0.9095\n",
      "Epoch 437/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2373 - accuracy: 0.9309 - val_loss: 0.2914 - val_accuracy: 0.9053\n",
      "Epoch 438/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2828 - accuracy: 0.8906 - val_loss: 0.4742 - val_accuracy: 0.7860\n",
      "Epoch 439/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4347 - accuracy: 0.7657 - val_loss: 0.3275 - val_accuracy: 0.8807\n",
      "Epoch 440/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2313 - accuracy: 0.9381 - val_loss: 0.2913 - val_accuracy: 0.9136\n",
      "Epoch 441/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9422 - val_loss: 0.3652 - val_accuracy: 0.8395\n",
      "Epoch 442/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2581 - accuracy: 0.9061 - val_loss: 0.2806 - val_accuracy: 0.9136\n",
      "Epoch 443/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2116 - accuracy: 0.9463 - val_loss: 0.2940 - val_accuracy: 0.8848\n",
      "Epoch 444/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2183 - accuracy: 0.9381 - val_loss: 0.2810 - val_accuracy: 0.9095\n",
      "Epoch 445/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2276 - accuracy: 0.9391 - val_loss: 0.3164 - val_accuracy: 0.8560\n",
      "Epoch 446/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2265 - accuracy: 0.9350 - val_loss: 0.2925 - val_accuracy: 0.9136\n",
      "Epoch 447/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2228 - accuracy: 0.9422 - val_loss: 0.3618 - val_accuracy: 0.8313\n",
      "Epoch 448/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2712 - accuracy: 0.9009 - val_loss: 0.4446 - val_accuracy: 0.7572\n",
      "Epoch 449/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3716 - accuracy: 0.8080 - val_loss: 0.3573 - val_accuracy: 0.8477\n",
      "Epoch 450/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2297 - accuracy: 0.9298 - val_loss: 0.2806 - val_accuracy: 0.9136\n",
      "Epoch 451/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2080 - accuracy: 0.9401 - val_loss: 0.2815 - val_accuracy: 0.9136\n",
      "Epoch 452/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2047 - accuracy: 0.9463 - val_loss: 0.3171 - val_accuracy: 0.8683\n",
      "Epoch 453/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2194 - accuracy: 0.9401 - val_loss: 0.2769 - val_accuracy: 0.9095\n",
      "Epoch 454/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2026 - accuracy: 0.9453 - val_loss: 0.2665 - val_accuracy: 0.9136\n",
      "Epoch 455/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2119 - accuracy: 0.9350 - val_loss: 0.3852 - val_accuracy: 0.8272\n",
      "Epoch 456/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3774 - accuracy: 0.8111 - val_loss: 0.3920 - val_accuracy: 0.8148\n",
      "Epoch 457/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2630 - accuracy: 0.8937 - val_loss: 0.2777 - val_accuracy: 0.9053\n",
      "Epoch 458/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1939 - accuracy: 0.9494 - val_loss: 0.2606 - val_accuracy: 0.9177\n",
      "Epoch 459/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2106 - accuracy: 0.9453 - val_loss: 0.3045 - val_accuracy: 0.8807\n",
      "Epoch 460/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9505 - val_loss: 0.2518 - val_accuracy: 0.9259\n",
      "Epoch 461/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1840 - accuracy: 0.9536 - val_loss: 0.2494 - val_accuracy: 0.9300\n",
      "Epoch 462/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1844 - accuracy: 0.9505 - val_loss: 0.2477 - val_accuracy: 0.9300\n",
      "Epoch 463/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2281 - accuracy: 0.9226 - val_loss: 0.3440 - val_accuracy: 0.8601\n",
      "Epoch 464/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3809 - accuracy: 0.8039 - val_loss: 0.3784 - val_accuracy: 0.8313\n",
      "Epoch 465/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2172 - accuracy: 0.9370 - val_loss: 0.2663 - val_accuracy: 0.9218\n",
      "Epoch 466/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1806 - accuracy: 0.9546 - val_loss: 0.2532 - val_accuracy: 0.9300\n",
      "Epoch 467/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1799 - accuracy: 0.9525 - val_loss: 0.2518 - val_accuracy: 0.9136\n",
      "Epoch 468/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1881 - accuracy: 0.9432 - val_loss: 0.3394 - val_accuracy: 0.8519\n",
      "Epoch 469/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2114 - accuracy: 0.9370 - val_loss: 0.2400 - val_accuracy: 0.9342\n",
      "Epoch 470/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1760 - accuracy: 0.9556 - val_loss: 0.2557 - val_accuracy: 0.9012\n",
      "Epoch 471/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2054 - accuracy: 0.9453 - val_loss: 0.3215 - val_accuracy: 0.8642\n",
      "Epoch 472/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2068 - accuracy: 0.9401 - val_loss: 0.3426 - val_accuracy: 0.8519\n",
      "Epoch 473/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4990 - accuracy: 0.7534 - val_loss: 0.6606 - val_accuracy: 0.6872\n",
      "Epoch 474/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2933 - accuracy: 0.8875 - val_loss: 0.2601 - val_accuracy: 0.9259\n",
      "Epoch 475/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1838 - accuracy: 0.9505 - val_loss: 0.2613 - val_accuracy: 0.9136\n",
      "Epoch 476/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9463 - val_loss: 0.2522 - val_accuracy: 0.9218\n",
      "Epoch 477/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1858 - accuracy: 0.9474 - val_loss: 0.2534 - val_accuracy: 0.9177\n",
      "Epoch 478/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1723 - accuracy: 0.9546 - val_loss: 0.2416 - val_accuracy: 0.9300\n",
      "Epoch 479/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1699 - accuracy: 0.9556 - val_loss: 0.2398 - val_accuracy: 0.9300\n",
      "Epoch 480/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1635 - accuracy: 0.9577 - val_loss: 0.2395 - val_accuracy: 0.9259\n",
      "Epoch 481/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1716 - accuracy: 0.9556 - val_loss: 0.2500 - val_accuracy: 0.9218\n",
      "Epoch 482/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1607 - accuracy: 0.9598 - val_loss: 0.2480 - val_accuracy: 0.9300\n",
      "Epoch 483/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1688 - accuracy: 0.9546 - val_loss: 0.2367 - val_accuracy: 0.9300\n",
      "Epoch 484/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1609 - accuracy: 0.9587 - val_loss: 0.2981 - val_accuracy: 0.9012\n",
      "Epoch 485/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2038 - accuracy: 0.9340 - val_loss: 0.3087 - val_accuracy: 0.8642\n",
      "Epoch 486/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2064 - accuracy: 0.9226 - val_loss: 0.2757 - val_accuracy: 0.9053\n",
      "Epoch 487/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1874 - accuracy: 0.9484 - val_loss: 0.2325 - val_accuracy: 0.9177\n",
      "Epoch 488/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.9071 - val_loss: 0.5695 - val_accuracy: 0.7531\n",
      "Epoch 489/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2209 - accuracy: 0.9195 - val_loss: 0.2496 - val_accuracy: 0.9259\n",
      "Epoch 490/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1690 - accuracy: 0.9494 - val_loss: 0.2322 - val_accuracy: 0.9259\n",
      "Epoch 491/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9505 - val_loss: 0.2545 - val_accuracy: 0.9218\n",
      "Epoch 492/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1741 - accuracy: 0.9453 - val_loss: 0.2259 - val_accuracy: 0.9259\n",
      "Epoch 493/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1556 - accuracy: 0.9628 - val_loss: 0.2539 - val_accuracy: 0.9177\n",
      "Epoch 494/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2406 - accuracy: 0.9082 - val_loss: 0.3638 - val_accuracy: 0.8354\n",
      "Epoch 495/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3585 - accuracy: 0.8287 - val_loss: 0.3698 - val_accuracy: 0.8436\n",
      "Epoch 496/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1734 - accuracy: 0.9546 - val_loss: 0.2332 - val_accuracy: 0.9259\n",
      "Epoch 497/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.9598 - val_loss: 0.2293 - val_accuracy: 0.9259\n",
      "Epoch 498/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1646 - accuracy: 0.9567 - val_loss: 0.2290 - val_accuracy: 0.9177\n",
      "Epoch 499/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1525 - accuracy: 0.9649 - val_loss: 0.2474 - val_accuracy: 0.9300\n",
      "Epoch 500/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1911 - accuracy: 0.9443 - val_loss: 0.3264 - val_accuracy: 0.8560\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sleepy       0.76      0.98      0.86       152\n",
      "    vigilant       0.97      0.69      0.81       151\n",
      "\n",
      "    accuracy                           0.83       303\n",
      "   macro avg       0.87      0.83      0.83       303\n",
      "weighted avg       0.87      0.83      0.83       303\n",
      "\n",
      "[INFO] compiling model fold4.....\n",
      "[INFO] training network...\n",
      "(969, 28, 28, 1) (303, 28, 28, 1) (969, 2) (303, 2)\n",
      "Train on 969 samples, validate on 243 samples\n",
      "Epoch 1/500\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.6955 - accuracy: 0.4985 - val_loss: 0.6970 - val_accuracy: 0.4650\n",
      "Epoch 2/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6949 - accuracy: 0.5015 - val_loss: 0.6960 - val_accuracy: 0.4650\n",
      "Epoch 3/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6940 - accuracy: 0.5026 - val_loss: 0.6953 - val_accuracy: 0.4691\n",
      "Epoch 4/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6934 - accuracy: 0.5026 - val_loss: 0.6947 - val_accuracy: 0.4691\n",
      "Epoch 5/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6941 - val_accuracy: 0.4691\n",
      "Epoch 6/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6923 - accuracy: 0.5046 - val_loss: 0.6933 - val_accuracy: 0.4691\n",
      "Epoch 7/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6916 - accuracy: 0.5098 - val_loss: 0.6928 - val_accuracy: 0.4733\n",
      "Epoch 8/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6912 - accuracy: 0.5088 - val_loss: 0.6923 - val_accuracy: 0.4733\n",
      "Epoch 9/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6906 - accuracy: 0.5108 - val_loss: 0.6917 - val_accuracy: 0.4733\n",
      "Epoch 10/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.5108 - val_loss: 0.6912 - val_accuracy: 0.4733\n",
      "Epoch 11/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6896 - accuracy: 0.5108 - val_loss: 0.6909 - val_accuracy: 0.4733\n",
      "Epoch 12/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6892 - accuracy: 0.5088 - val_loss: 0.6902 - val_accuracy: 0.4856\n",
      "Epoch 13/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6886 - accuracy: 0.5181 - val_loss: 0.6898 - val_accuracy: 0.4979\n",
      "Epoch 14/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5191 - val_loss: 0.6893 - val_accuracy: 0.5062\n",
      "Epoch 15/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6877 - accuracy: 0.5222 - val_loss: 0.6889 - val_accuracy: 0.5062\n",
      "Epoch 16/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.5253 - val_loss: 0.6885 - val_accuracy: 0.5062\n",
      "Epoch 17/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5191 - val_loss: 0.6880 - val_accuracy: 0.5062\n",
      "Epoch 18/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5428 - val_loss: 0.6877 - val_accuracy: 0.5062\n",
      "Epoch 19/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5201 - val_loss: 0.6872 - val_accuracy: 0.5103\n",
      "Epoch 20/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5335 - val_loss: 0.6865 - val_accuracy: 0.5185\n",
      "Epoch 21/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5470 - val_loss: 0.6860 - val_accuracy: 0.5432\n",
      "Epoch 22/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5697 - val_loss: 0.6856 - val_accuracy: 0.5473\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5728 - val_loss: 0.6851 - val_accuracy: 0.5638\n",
      "Epoch 24/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.5862 - val_loss: 0.6847 - val_accuracy: 0.5638\n",
      "Epoch 25/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6832 - accuracy: 0.5769 - val_loss: 0.6842 - val_accuracy: 0.5597\n",
      "Epoch 26/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6827 - accuracy: 0.5831 - val_loss: 0.6837 - val_accuracy: 0.5679\n",
      "Epoch 27/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6827 - accuracy: 0.5759 - val_loss: 0.6834 - val_accuracy: 0.5556\n",
      "Epoch 28/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6817 - accuracy: 0.5924 - val_loss: 0.6829 - val_accuracy: 0.5597\n",
      "Epoch 29/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6815 - accuracy: 0.5831 - val_loss: 0.6824 - val_accuracy: 0.5597\n",
      "Epoch 30/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6811 - accuracy: 0.5913 - val_loss: 0.6822 - val_accuracy: 0.5556\n",
      "Epoch 31/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6804 - accuracy: 0.5903 - val_loss: 0.6817 - val_accuracy: 0.5597\n",
      "Epoch 32/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6800 - accuracy: 0.5882 - val_loss: 0.6811 - val_accuracy: 0.5391\n",
      "Epoch 33/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6796 - accuracy: 0.5810 - val_loss: 0.6807 - val_accuracy: 0.5391\n",
      "Epoch 34/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6792 - accuracy: 0.5841 - val_loss: 0.6800 - val_accuracy: 0.5473\n",
      "Epoch 35/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6788 - accuracy: 0.5872 - val_loss: 0.6798 - val_accuracy: 0.5432\n",
      "Epoch 36/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6782 - accuracy: 0.5779 - val_loss: 0.6792 - val_accuracy: 0.5432\n",
      "Epoch 37/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6777 - accuracy: 0.5831 - val_loss: 0.6787 - val_accuracy: 0.5432\n",
      "Epoch 38/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6773 - accuracy: 0.5779 - val_loss: 0.6783 - val_accuracy: 0.5391\n",
      "Epoch 39/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6769 - accuracy: 0.5862 - val_loss: 0.6781 - val_accuracy: 0.5350\n",
      "Epoch 40/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6764 - accuracy: 0.5789 - val_loss: 0.6773 - val_accuracy: 0.5556\n",
      "Epoch 41/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6758 - accuracy: 0.5841 - val_loss: 0.6769 - val_accuracy: 0.5556\n",
      "Epoch 42/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6756 - accuracy: 0.5800 - val_loss: 0.6763 - val_accuracy: 0.5679\n",
      "Epoch 43/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6751 - accuracy: 0.5955 - val_loss: 0.6761 - val_accuracy: 0.5473\n",
      "Epoch 44/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6744 - accuracy: 0.5779 - val_loss: 0.6754 - val_accuracy: 0.5638\n",
      "Epoch 45/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6740 - accuracy: 0.5903 - val_loss: 0.6749 - val_accuracy: 0.5720\n",
      "Epoch 46/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6735 - accuracy: 0.5893 - val_loss: 0.6744 - val_accuracy: 0.5844\n",
      "Epoch 47/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6730 - accuracy: 0.5996 - val_loss: 0.6740 - val_accuracy: 0.5885\n",
      "Epoch 48/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6726 - accuracy: 0.6006 - val_loss: 0.6736 - val_accuracy: 0.5802\n",
      "Epoch 49/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.5924 - val_loss: 0.6729 - val_accuracy: 0.6049\n",
      "Epoch 50/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6717 - accuracy: 0.6202 - val_loss: 0.6728 - val_accuracy: 0.5802\n",
      "Epoch 51/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6711 - accuracy: 0.6017 - val_loss: 0.6722 - val_accuracy: 0.6008\n",
      "Epoch 52/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6709 - accuracy: 0.6192 - val_loss: 0.6723 - val_accuracy: 0.5638\n",
      "Epoch 53/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6705 - accuracy: 0.5944 - val_loss: 0.6716 - val_accuracy: 0.5967\n",
      "Epoch 54/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6702 - accuracy: 0.6068 - val_loss: 0.6710 - val_accuracy: 0.6008\n",
      "Epoch 55/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6692 - accuracy: 0.6037 - val_loss: 0.6701 - val_accuracy: 0.6132\n",
      "Epoch 56/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.6130 - val_loss: 0.6695 - val_accuracy: 0.6255\n",
      "Epoch 57/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6685 - accuracy: 0.6130 - val_loss: 0.6692 - val_accuracy: 0.6173\n",
      "Epoch 58/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6678 - accuracy: 0.6223 - val_loss: 0.6688 - val_accuracy: 0.6091\n",
      "Epoch 59/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6673 - accuracy: 0.6151 - val_loss: 0.6683 - val_accuracy: 0.6214\n",
      "Epoch 60/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6669 - accuracy: 0.6120 - val_loss: 0.6676 - val_accuracy: 0.6296\n",
      "Epoch 61/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6664 - accuracy: 0.6213 - val_loss: 0.6670 - val_accuracy: 0.6379\n",
      "Epoch 62/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6661 - accuracy: 0.6202 - val_loss: 0.6665 - val_accuracy: 0.6379\n",
      "Epoch 63/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6661 - accuracy: 0.6192 - val_loss: 0.6660 - val_accuracy: 0.6296\n",
      "Epoch 64/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6652 - accuracy: 0.6233 - val_loss: 0.6661 - val_accuracy: 0.6255\n",
      "Epoch 65/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6647 - accuracy: 0.6264 - val_loss: 0.6658 - val_accuracy: 0.6091\n",
      "Epoch 66/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6642 - accuracy: 0.6244 - val_loss: 0.6654 - val_accuracy: 0.6132\n",
      "Epoch 67/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6635 - accuracy: 0.6254 - val_loss: 0.6647 - val_accuracy: 0.6296\n",
      "Epoch 68/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6633 - accuracy: 0.6305 - val_loss: 0.6650 - val_accuracy: 0.6132\n",
      "Epoch 69/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6629 - accuracy: 0.6192 - val_loss: 0.6644 - val_accuracy: 0.6091\n",
      "Epoch 70/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6623 - accuracy: 0.6109 - val_loss: 0.6627 - val_accuracy: 0.6420\n",
      "Epoch 71/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6616 - accuracy: 0.6295 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
      "Epoch 72/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6613 - accuracy: 0.6233 - val_loss: 0.6615 - val_accuracy: 0.6461\n",
      "Epoch 73/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6608 - accuracy: 0.6244 - val_loss: 0.6612 - val_accuracy: 0.6337\n",
      "Epoch 74/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6606 - accuracy: 0.6182 - val_loss: 0.6604 - val_accuracy: 0.6502\n",
      "Epoch 75/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.6285 - val_loss: 0.6605 - val_accuracy: 0.6461\n",
      "Epoch 76/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6595 - accuracy: 0.6316 - val_loss: 0.6602 - val_accuracy: 0.6461\n",
      "Epoch 77/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6591 - accuracy: 0.6244 - val_loss: 0.6598 - val_accuracy: 0.6420\n",
      "Epoch 78/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6587 - accuracy: 0.6182 - val_loss: 0.6588 - val_accuracy: 0.6420\n",
      "Epoch 79/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6582 - accuracy: 0.6223 - val_loss: 0.6584 - val_accuracy: 0.6420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6579 - accuracy: 0.6378 - val_loss: 0.6591 - val_accuracy: 0.6337\n",
      "Epoch 81/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6577 - accuracy: 0.6244 - val_loss: 0.6588 - val_accuracy: 0.6337\n",
      "Epoch 82/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6571 - accuracy: 0.6202 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
      "Epoch 83/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6568 - accuracy: 0.6233 - val_loss: 0.6572 - val_accuracy: 0.6502\n",
      "Epoch 84/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6572 - accuracy: 0.6254 - val_loss: 0.6586 - val_accuracy: 0.6255\n",
      "Epoch 85/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6562 - accuracy: 0.6171 - val_loss: 0.6554 - val_accuracy: 0.6543\n",
      "Epoch 86/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6552 - accuracy: 0.6316 - val_loss: 0.6546 - val_accuracy: 0.6543\n",
      "Epoch 87/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6564 - accuracy: 0.6264 - val_loss: 0.6557 - val_accuracy: 0.6502\n",
      "Epoch 88/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6543 - accuracy: 0.6316 - val_loss: 0.6549 - val_accuracy: 0.6461\n",
      "Epoch 89/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6539 - accuracy: 0.6305 - val_loss: 0.6540 - val_accuracy: 0.6461\n",
      "Epoch 90/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6535 - accuracy: 0.6409 - val_loss: 0.6559 - val_accuracy: 0.6379\n",
      "Epoch 91/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6532 - accuracy: 0.6244 - val_loss: 0.6530 - val_accuracy: 0.6502\n",
      "Epoch 92/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6538 - accuracy: 0.6336 - val_loss: 0.6531 - val_accuracy: 0.6420\n",
      "Epoch 93/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6535 - accuracy: 0.6285 - val_loss: 0.6519 - val_accuracy: 0.6543\n",
      "Epoch 94/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6520 - accuracy: 0.6347 - val_loss: 0.6519 - val_accuracy: 0.6502\n",
      "Epoch 95/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6532 - accuracy: 0.6460 - val_loss: 0.6525 - val_accuracy: 0.6543\n",
      "Epoch 96/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6514 - accuracy: 0.6316 - val_loss: 0.6518 - val_accuracy: 0.6543\n",
      "Epoch 97/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6512 - accuracy: 0.6285 - val_loss: 0.6501 - val_accuracy: 0.6543\n",
      "Epoch 98/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6518 - accuracy: 0.6316 - val_loss: 0.6507 - val_accuracy: 0.6420\n",
      "Epoch 99/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6500 - accuracy: 0.6347 - val_loss: 0.6495 - val_accuracy: 0.6543\n",
      "Epoch 100/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6494 - accuracy: 0.6367 - val_loss: 0.6496 - val_accuracy: 0.6502\n",
      "Epoch 101/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6497 - accuracy: 0.6244 - val_loss: 0.6475 - val_accuracy: 0.6584\n",
      "Epoch 102/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6487 - accuracy: 0.6367 - val_loss: 0.6479 - val_accuracy: 0.6626\n",
      "Epoch 103/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6484 - accuracy: 0.6378 - val_loss: 0.6479 - val_accuracy: 0.6543\n",
      "Epoch 104/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6478 - accuracy: 0.6336 - val_loss: 0.6490 - val_accuracy: 0.6584\n",
      "Epoch 105/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6481 - accuracy: 0.6388 - val_loss: 0.6495 - val_accuracy: 0.6584\n",
      "Epoch 106/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6469 - accuracy: 0.6367 - val_loss: 0.6462 - val_accuracy: 0.6667\n",
      "Epoch 107/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6472 - accuracy: 0.6429 - val_loss: 0.6461 - val_accuracy: 0.6584\n",
      "Epoch 108/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6475 - accuracy: 0.6316 - val_loss: 0.6464 - val_accuracy: 0.6584\n",
      "Epoch 109/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6464 - accuracy: 0.6440 - val_loss: 0.6475 - val_accuracy: 0.6626\n",
      "Epoch 110/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6459 - accuracy: 0.6450 - val_loss: 0.6450 - val_accuracy: 0.6584\n",
      "Epoch 111/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6454 - accuracy: 0.6388 - val_loss: 0.6464 - val_accuracy: 0.6626\n",
      "Epoch 112/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6444 - accuracy: 0.6409 - val_loss: 0.6431 - val_accuracy: 0.6667\n",
      "Epoch 113/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6442 - accuracy: 0.6533 - val_loss: 0.6446 - val_accuracy: 0.6708\n",
      "Epoch 114/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6438 - accuracy: 0.6367 - val_loss: 0.6432 - val_accuracy: 0.6584\n",
      "Epoch 115/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6432 - accuracy: 0.6460 - val_loss: 0.6451 - val_accuracy: 0.6626\n",
      "Epoch 116/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6429 - val_loss: 0.6429 - val_accuracy: 0.6708\n",
      "Epoch 117/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6425 - accuracy: 0.6367 - val_loss: 0.6401 - val_accuracy: 0.6626\n",
      "Epoch 118/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6429 - accuracy: 0.6574 - val_loss: 0.6414 - val_accuracy: 0.6584\n",
      "Epoch 119/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6433 - accuracy: 0.6347 - val_loss: 0.6419 - val_accuracy: 0.6708\n",
      "Epoch 120/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6413 - accuracy: 0.6502 - val_loss: 0.6403 - val_accuracy: 0.6626\n",
      "Epoch 121/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6409 - accuracy: 0.6471 - val_loss: 0.6398 - val_accuracy: 0.6626\n",
      "Epoch 122/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6401 - accuracy: 0.6481 - val_loss: 0.6381 - val_accuracy: 0.6708\n",
      "Epoch 123/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6396 - accuracy: 0.6522 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
      "Epoch 124/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6393 - accuracy: 0.6522 - val_loss: 0.6416 - val_accuracy: 0.6749\n",
      "Epoch 125/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6397 - accuracy: 0.6450 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 126/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6384 - accuracy: 0.6481 - val_loss: 0.6358 - val_accuracy: 0.6708\n",
      "Epoch 127/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6398 - accuracy: 0.6563 - val_loss: 0.6371 - val_accuracy: 0.6708\n",
      "Epoch 128/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6374 - accuracy: 0.6574 - val_loss: 0.6421 - val_accuracy: 0.6708\n",
      "Epoch 129/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6389 - accuracy: 0.6440 - val_loss: 0.6367 - val_accuracy: 0.6749\n",
      "Epoch 130/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6377 - accuracy: 0.6460 - val_loss: 0.6371 - val_accuracy: 0.6831\n",
      "Epoch 131/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6389 - accuracy: 0.6460 - val_loss: 0.6346 - val_accuracy: 0.6667\n",
      "Epoch 132/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6363 - accuracy: 0.6543 - val_loss: 0.6353 - val_accuracy: 0.6749\n",
      "Epoch 133/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6363 - accuracy: 0.6553 - val_loss: 0.6328 - val_accuracy: 0.6749\n",
      "Epoch 134/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6360 - accuracy: 0.6584 - val_loss: 0.6319 - val_accuracy: 0.6708\n",
      "Epoch 135/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6375 - accuracy: 0.6615 - val_loss: 0.6373 - val_accuracy: 0.6708\n",
      "Epoch 136/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6344 - accuracy: 0.6563 - val_loss: 0.6324 - val_accuracy: 0.6749\n",
      "Epoch 137/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6359 - accuracy: 0.6563 - val_loss: 0.6314 - val_accuracy: 0.6749\n",
      "Epoch 138/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6333 - accuracy: 0.6594 - val_loss: 0.6352 - val_accuracy: 0.6790\n",
      "Epoch 139/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6324 - accuracy: 0.6512 - val_loss: 0.6302 - val_accuracy: 0.6914\n",
      "Epoch 140/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6327 - accuracy: 0.6584 - val_loss: 0.6310 - val_accuracy: 0.6790\n",
      "Epoch 141/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6316 - accuracy: 0.6563 - val_loss: 0.6316 - val_accuracy: 0.6831\n",
      "Epoch 142/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6314 - accuracy: 0.6656 - val_loss: 0.6310 - val_accuracy: 0.6831\n",
      "Epoch 143/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6302 - accuracy: 0.6656 - val_loss: 0.6275 - val_accuracy: 0.6872\n",
      "Epoch 144/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6328 - accuracy: 0.6615 - val_loss: 0.6281 - val_accuracy: 0.6872\n",
      "Epoch 145/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6310 - accuracy: 0.6646 - val_loss: 0.6287 - val_accuracy: 0.6872\n",
      "Epoch 146/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6295 - accuracy: 0.6553 - val_loss: 0.6258 - val_accuracy: 0.6914\n",
      "Epoch 147/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6286 - accuracy: 0.6594 - val_loss: 0.6262 - val_accuracy: 0.6872\n",
      "Epoch 148/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6294 - accuracy: 0.6584 - val_loss: 0.6258 - val_accuracy: 0.6872\n",
      "Epoch 149/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6299 - accuracy: 0.6615 - val_loss: 0.6264 - val_accuracy: 0.6914\n",
      "Epoch 150/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6272 - accuracy: 0.6646 - val_loss: 0.6247 - val_accuracy: 0.6831\n",
      "Epoch 151/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6265 - accuracy: 0.6698 - val_loss: 0.6253 - val_accuracy: 0.6955\n",
      "Epoch 152/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6280 - accuracy: 0.6698 - val_loss: 0.6257 - val_accuracy: 0.6955\n",
      "Epoch 153/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6267 - accuracy: 0.6584 - val_loss: 0.6218 - val_accuracy: 0.6749\n",
      "Epoch 154/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6281 - accuracy: 0.6749 - val_loss: 0.6219 - val_accuracy: 0.7037\n",
      "Epoch 155/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6256 - accuracy: 0.6646 - val_loss: 0.6209 - val_accuracy: 0.6996\n",
      "Epoch 156/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6257 - accuracy: 0.6698 - val_loss: 0.6349 - val_accuracy: 0.6420\n",
      "Epoch 157/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6246 - accuracy: 0.6522 - val_loss: 0.6207 - val_accuracy: 0.6831\n",
      "Epoch 158/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.6687 - val_loss: 0.6190 - val_accuracy: 0.6914\n",
      "Epoch 159/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6235 - accuracy: 0.6656 - val_loss: 0.6184 - val_accuracy: 0.6996\n",
      "Epoch 160/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6228 - accuracy: 0.6708 - val_loss: 0.6187 - val_accuracy: 0.6914\n",
      "Epoch 161/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6222 - accuracy: 0.6584 - val_loss: 0.6174 - val_accuracy: 0.6955\n",
      "Epoch 162/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6222 - accuracy: 0.6739 - val_loss: 0.6189 - val_accuracy: 0.7037\n",
      "Epoch 163/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6222 - accuracy: 0.6687 - val_loss: 0.6169 - val_accuracy: 0.7037\n",
      "Epoch 164/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6197 - accuracy: 0.6729 - val_loss: 0.6160 - val_accuracy: 0.6955\n",
      "Epoch 165/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6203 - accuracy: 0.6718 - val_loss: 0.6154 - val_accuracy: 0.6955\n",
      "Epoch 166/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6190 - accuracy: 0.6770 - val_loss: 0.6167 - val_accuracy: 0.7078\n",
      "Epoch 167/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6202 - accuracy: 0.6512 - val_loss: 0.6135 - val_accuracy: 0.6996\n",
      "Epoch 168/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6177 - accuracy: 0.6677 - val_loss: 0.6140 - val_accuracy: 0.7037\n",
      "Epoch 169/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6173 - accuracy: 0.6729 - val_loss: 0.6136 - val_accuracy: 0.6996\n",
      "Epoch 170/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6159 - accuracy: 0.6718 - val_loss: 0.6115 - val_accuracy: 0.6996\n",
      "Epoch 171/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6166 - accuracy: 0.6842 - val_loss: 0.6134 - val_accuracy: 0.6996\n",
      "Epoch 172/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6152 - accuracy: 0.6780 - val_loss: 0.6212 - val_accuracy: 0.6584\n",
      "Epoch 173/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6144 - accuracy: 0.6636 - val_loss: 0.6132 - val_accuracy: 0.7078\n",
      "Epoch 174/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6146 - accuracy: 0.6605 - val_loss: 0.6115 - val_accuracy: 0.7037\n",
      "Epoch 175/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6132 - accuracy: 0.6718 - val_loss: 0.6117 - val_accuracy: 0.7078\n",
      "Epoch 176/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6127 - accuracy: 0.6801 - val_loss: 0.6078 - val_accuracy: 0.7160\n",
      "Epoch 177/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6157 - accuracy: 0.6615 - val_loss: 0.6067 - val_accuracy: 0.7037\n",
      "Epoch 178/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6121 - accuracy: 0.6791 - val_loss: 0.6098 - val_accuracy: 0.6996\n",
      "Epoch 179/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6129 - accuracy: 0.6656 - val_loss: 0.6052 - val_accuracy: 0.7037\n",
      "Epoch 180/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6237 - accuracy: 0.6574 - val_loss: 0.6048 - val_accuracy: 0.7078\n",
      "Epoch 181/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6097 - accuracy: 0.6791 - val_loss: 0.6041 - val_accuracy: 0.7160\n",
      "Epoch 182/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6102 - accuracy: 0.6760 - val_loss: 0.6044 - val_accuracy: 0.7119\n",
      "Epoch 183/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6086 - accuracy: 0.6873 - val_loss: 0.6036 - val_accuracy: 0.7160\n",
      "Epoch 184/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6162 - accuracy: 0.6770 - val_loss: 0.6175 - val_accuracy: 0.6667\n",
      "Epoch 185/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6082 - accuracy: 0.6780 - val_loss: 0.6061 - val_accuracy: 0.6996\n",
      "Epoch 186/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6098 - accuracy: 0.6667 - val_loss: 0.6021 - val_accuracy: 0.6914\n",
      "Epoch 187/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6080 - accuracy: 0.6811 - val_loss: 0.6033 - val_accuracy: 0.6872\n",
      "Epoch 188/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6070 - accuracy: 0.6739 - val_loss: 0.6075 - val_accuracy: 0.6831\n",
      "Epoch 189/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6108 - accuracy: 0.6605 - val_loss: 0.5995 - val_accuracy: 0.7284\n",
      "Epoch 190/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6072 - accuracy: 0.6760 - val_loss: 0.5985 - val_accuracy: 0.7202\n",
      "Epoch 191/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6023 - accuracy: 0.6863 - val_loss: 0.5986 - val_accuracy: 0.7243\n",
      "Epoch 192/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6036 - accuracy: 0.6935 - val_loss: 0.6054 - val_accuracy: 0.6831\n",
      "Epoch 193/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6023 - accuracy: 0.6842 - val_loss: 0.6068 - val_accuracy: 0.6749\n",
      "Epoch 194/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6012 - accuracy: 0.6656 - val_loss: 0.5948 - val_accuracy: 0.7078\n",
      "Epoch 195/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6031 - accuracy: 0.6739 - val_loss: 0.5951 - val_accuracy: 0.7243\n",
      "Epoch 196/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5992 - accuracy: 0.6863 - val_loss: 0.5928 - val_accuracy: 0.7202\n",
      "Epoch 197/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6034 - accuracy: 0.6718 - val_loss: 0.5920 - val_accuracy: 0.7202\n",
      "Epoch 198/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5983 - accuracy: 0.6914 - val_loss: 0.5973 - val_accuracy: 0.7037\n",
      "Epoch 199/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5966 - accuracy: 0.6852 - val_loss: 0.5937 - val_accuracy: 0.7037\n",
      "Epoch 200/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5956 - accuracy: 0.6791 - val_loss: 0.5963 - val_accuracy: 0.6955\n",
      "Epoch 201/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6018 - accuracy: 0.6791 - val_loss: 0.5901 - val_accuracy: 0.7284\n",
      "Epoch 202/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5941 - accuracy: 0.6914 - val_loss: 0.5887 - val_accuracy: 0.7284\n",
      "Epoch 203/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5932 - accuracy: 0.6873 - val_loss: 0.5884 - val_accuracy: 0.7078\n",
      "Epoch 204/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6048 - accuracy: 0.6563 - val_loss: 0.5938 - val_accuracy: 0.6996\n",
      "Epoch 205/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6046 - accuracy: 0.6646 - val_loss: 0.5886 - val_accuracy: 0.7160\n",
      "Epoch 206/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5989 - accuracy: 0.6883 - val_loss: 0.5855 - val_accuracy: 0.7284\n",
      "Epoch 207/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5984 - accuracy: 0.6739 - val_loss: 0.6013 - val_accuracy: 0.6749\n",
      "Epoch 208/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5922 - accuracy: 0.6956 - val_loss: 0.5834 - val_accuracy: 0.7366\n",
      "Epoch 209/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5933 - accuracy: 0.6894 - val_loss: 0.5829 - val_accuracy: 0.7284\n",
      "Epoch 210/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5915 - accuracy: 0.7059 - val_loss: 0.5825 - val_accuracy: 0.7202\n",
      "Epoch 211/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5941 - accuracy: 0.6821 - val_loss: 0.5855 - val_accuracy: 0.7202\n",
      "Epoch 212/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5874 - accuracy: 0.6873 - val_loss: 0.5861 - val_accuracy: 0.7284\n",
      "Epoch 213/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5863 - accuracy: 0.7069 - val_loss: 0.6078 - val_accuracy: 0.6708\n",
      "Epoch 214/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5908 - accuracy: 0.6863 - val_loss: 0.6217 - val_accuracy: 0.6420\n",
      "Epoch 215/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5911 - accuracy: 0.6821 - val_loss: 0.5824 - val_accuracy: 0.7284\n",
      "Epoch 216/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5869 - accuracy: 0.7028 - val_loss: 0.5765 - val_accuracy: 0.7449\n",
      "Epoch 217/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5853 - accuracy: 0.6945 - val_loss: 0.5808 - val_accuracy: 0.7325\n",
      "Epoch 218/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5967 - accuracy: 0.6677 - val_loss: 0.5752 - val_accuracy: 0.7449\n",
      "Epoch 219/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5876 - accuracy: 0.6894 - val_loss: 0.5830 - val_accuracy: 0.7078\n",
      "Epoch 220/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5815 - accuracy: 0.7049 - val_loss: 0.5731 - val_accuracy: 0.7366\n",
      "Epoch 221/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5779 - accuracy: 0.7121 - val_loss: 0.5780 - val_accuracy: 0.7243\n",
      "Epoch 222/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6031 - accuracy: 0.6749 - val_loss: 0.5912 - val_accuracy: 0.6872\n",
      "Epoch 223/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5926 - accuracy: 0.6821 - val_loss: 0.5711 - val_accuracy: 0.7325\n",
      "Epoch 224/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5761 - accuracy: 0.7007 - val_loss: 0.5696 - val_accuracy: 0.7366\n",
      "Epoch 225/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.6925 - val_loss: 0.5730 - val_accuracy: 0.7160\n",
      "Epoch 226/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5824 - accuracy: 0.6987 - val_loss: 0.5921 - val_accuracy: 0.6831\n",
      "Epoch 227/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5750 - accuracy: 0.6883 - val_loss: 0.5692 - val_accuracy: 0.7325\n",
      "Epoch 228/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5748 - accuracy: 0.7110 - val_loss: 0.5963 - val_accuracy: 0.6790\n",
      "Epoch 229/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.6914 - val_loss: 0.5912 - val_accuracy: 0.6831\n",
      "Epoch 230/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.6914 - val_loss: 0.5888 - val_accuracy: 0.6831\n",
      "Epoch 231/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6046 - accuracy: 0.6605 - val_loss: 0.5951 - val_accuracy: 0.6749\n",
      "Epoch 232/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5800 - accuracy: 0.6904 - val_loss: 0.5646 - val_accuracy: 0.7366\n",
      "Epoch 233/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.6956 - val_loss: 0.5756 - val_accuracy: 0.7037\n",
      "Epoch 234/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7038 - val_loss: 0.5607 - val_accuracy: 0.7449\n",
      "Epoch 235/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7141 - val_loss: 0.5632 - val_accuracy: 0.7284\n",
      "Epoch 236/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5693 - accuracy: 0.7183 - val_loss: 0.5590 - val_accuracy: 0.7490\n",
      "Epoch 237/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.6914 - val_loss: 0.5652 - val_accuracy: 0.7366\n",
      "Epoch 238/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5650 - accuracy: 0.7069 - val_loss: 0.5576 - val_accuracy: 0.7449\n",
      "Epoch 239/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5604 - accuracy: 0.7172 - val_loss: 0.5565 - val_accuracy: 0.7490\n",
      "Epoch 240/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5592 - accuracy: 0.7121 - val_loss: 0.5596 - val_accuracy: 0.7325\n",
      "Epoch 241/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7307 - val_loss: 0.5559 - val_accuracy: 0.7490\n",
      "Epoch 242/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5709 - accuracy: 0.7079 - val_loss: 0.6609 - val_accuracy: 0.6091\n",
      "Epoch 243/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5746 - accuracy: 0.7152 - val_loss: 0.5533 - val_accuracy: 0.7531\n",
      "Epoch 244/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5557 - accuracy: 0.7234 - val_loss: 0.5520 - val_accuracy: 0.7531\n",
      "Epoch 245/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5606 - accuracy: 0.7131 - val_loss: 0.5592 - val_accuracy: 0.7366\n",
      "Epoch 246/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5811 - accuracy: 0.6791 - val_loss: 0.6491 - val_accuracy: 0.6132\n",
      "Epoch 247/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5890 - accuracy: 0.6832 - val_loss: 0.5480 - val_accuracy: 0.7613\n",
      "Epoch 248/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7337 - val_loss: 0.5577 - val_accuracy: 0.7366\n",
      "Epoch 249/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5501 - accuracy: 0.7317 - val_loss: 0.5584 - val_accuracy: 0.7325\n",
      "Epoch 250/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6145 - accuracy: 0.6367 - val_loss: 0.5842 - val_accuracy: 0.6543\n",
      "Epoch 251/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5608 - accuracy: 0.7110 - val_loss: 0.5447 - val_accuracy: 0.7654\n",
      "Epoch 252/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7286 - val_loss: 0.5425 - val_accuracy: 0.7654\n",
      "Epoch 253/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7317 - val_loss: 0.5410 - val_accuracy: 0.7654\n",
      "Epoch 254/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7059 - val_loss: 0.5809 - val_accuracy: 0.6831\n",
      "Epoch 255/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7441 - val_loss: 0.5717 - val_accuracy: 0.6914\n",
      "Epoch 256/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7348 - val_loss: 0.5471 - val_accuracy: 0.7449\n",
      "Epoch 257/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7348 - val_loss: 0.5360 - val_accuracy: 0.7737\n",
      "Epoch 258/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7337 - val_loss: 0.5355 - val_accuracy: 0.7654\n",
      "Epoch 259/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7389 - val_loss: 0.5391 - val_accuracy: 0.7449\n",
      "Epoch 260/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7399 - val_loss: 0.5318 - val_accuracy: 0.7778\n",
      "Epoch 261/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7286 - val_loss: 0.5821 - val_accuracy: 0.6461\n",
      "Epoch 262/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6346 - accuracy: 0.6130 - val_loss: 0.6436 - val_accuracy: 0.6214\n",
      "Epoch 263/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5751 - accuracy: 0.6925 - val_loss: 0.5407 - val_accuracy: 0.7490\n",
      "Epoch 264/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5553 - accuracy: 0.7183 - val_loss: 0.5780 - val_accuracy: 0.6872\n",
      "Epoch 265/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5607 - accuracy: 0.7028 - val_loss: 0.5326 - val_accuracy: 0.7778\n",
      "Epoch 266/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5575 - accuracy: 0.7090 - val_loss: 0.6033 - val_accuracy: 0.6337\n",
      "Epoch 267/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5514 - accuracy: 0.7193 - val_loss: 0.5360 - val_accuracy: 0.7449\n",
      "Epoch 268/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7368 - val_loss: 0.5697 - val_accuracy: 0.6872\n",
      "Epoch 269/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7420 - val_loss: 0.6030 - val_accuracy: 0.6379\n",
      "Epoch 270/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7451 - val_loss: 0.5267 - val_accuracy: 0.7695\n",
      "Epoch 271/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5259 - accuracy: 0.7761 - val_loss: 0.5504 - val_accuracy: 0.7119\n",
      "Epoch 272/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7162 - val_loss: 0.5630 - val_accuracy: 0.6872\n",
      "Epoch 273/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.6976 - val_loss: 0.5990 - val_accuracy: 0.6379\n",
      "Epoch 274/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7276 - val_loss: 0.5228 - val_accuracy: 0.7737\n",
      "Epoch 275/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5252 - accuracy: 0.7523 - val_loss: 0.5212 - val_accuracy: 0.7654\n",
      "Epoch 276/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5927 - accuracy: 0.6708 - val_loss: 0.6516 - val_accuracy: 0.6132\n",
      "Epoch 277/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.6976 - val_loss: 0.5232 - val_accuracy: 0.7737\n",
      "Epoch 278/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5181 - accuracy: 0.7616 - val_loss: 0.5228 - val_accuracy: 0.7613\n",
      "Epoch 279/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5209 - accuracy: 0.7616 - val_loss: 0.5156 - val_accuracy: 0.8025\n",
      "Epoch 280/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5304 - accuracy: 0.7472 - val_loss: 0.5416 - val_accuracy: 0.7243\n",
      "Epoch 281/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5252 - accuracy: 0.7430 - val_loss: 0.5134 - val_accuracy: 0.7984\n",
      "Epoch 282/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.5232 - accuracy: 0.7616 - val_loss: 0.5289 - val_accuracy: 0.7572\n",
      "Epoch 283/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5118 - accuracy: 0.7575 - val_loss: 0.5180 - val_accuracy: 0.7613\n",
      "Epoch 284/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7121 - val_loss: 0.5854 - val_accuracy: 0.6626\n",
      "Epoch 285/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.6945 - val_loss: 0.5598 - val_accuracy: 0.6749\n",
      "Epoch 286/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7399 - val_loss: 0.5268 - val_accuracy: 0.7572\n",
      "Epoch 287/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5097 - accuracy: 0.7688 - val_loss: 0.5830 - val_accuracy: 0.6708\n",
      "Epoch 288/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5286 - accuracy: 0.7286 - val_loss: 0.5086 - val_accuracy: 0.7654\n",
      "Epoch 289/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5307 - accuracy: 0.7379 - val_loss: 0.6909 - val_accuracy: 0.6008\n",
      "Epoch 290/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6093 - accuracy: 0.6656 - val_loss: 0.5122 - val_accuracy: 0.7778\n",
      "Epoch 291/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5033 - accuracy: 0.7895 - val_loss: 0.5037 - val_accuracy: 0.8107\n",
      "Epoch 292/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5013 - accuracy: 0.7895 - val_loss: 0.5068 - val_accuracy: 0.7778\n",
      "Epoch 293/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5047 - accuracy: 0.7709 - val_loss: 0.5157 - val_accuracy: 0.7572\n",
      "Epoch 294/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5018 - accuracy: 0.7792 - val_loss: 0.5177 - val_accuracy: 0.7572\n",
      "Epoch 295/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5240 - accuracy: 0.7379 - val_loss: 0.5431 - val_accuracy: 0.6996\n",
      "Epoch 296/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5137 - accuracy: 0.7482 - val_loss: 0.4961 - val_accuracy: 0.8107\n",
      "Epoch 297/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5016 - accuracy: 0.7874 - val_loss: 0.5357 - val_accuracy: 0.7119\n",
      "Epoch 298/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4955 - accuracy: 0.7822 - val_loss: 0.5099 - val_accuracy: 0.7654\n",
      "Epoch 299/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4872 - accuracy: 0.7915 - val_loss: 0.5037 - val_accuracy: 0.7654\n",
      "Epoch 300/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7307 - val_loss: 0.6478 - val_accuracy: 0.6255\n",
      "Epoch 301/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.6801 - val_loss: 0.4963 - val_accuracy: 0.8189\n",
      "Epoch 302/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4923 - accuracy: 0.7822 - val_loss: 0.5386 - val_accuracy: 0.7037\n",
      "Epoch 303/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.6729 - val_loss: 0.5874 - val_accuracy: 0.6461\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7162 - val_loss: 0.4972 - val_accuracy: 0.7819\n",
      "Epoch 305/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5050 - accuracy: 0.7595 - val_loss: 0.5052 - val_accuracy: 0.7737\n",
      "Epoch 306/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7678 - val_loss: 0.5014 - val_accuracy: 0.7490\n",
      "Epoch 307/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7957 - val_loss: 0.5061 - val_accuracy: 0.7654\n",
      "Epoch 308/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5247 - accuracy: 0.7276 - val_loss: 0.5002 - val_accuracy: 0.7449\n",
      "Epoch 309/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4819 - accuracy: 0.8008 - val_loss: 0.4839 - val_accuracy: 0.8272\n",
      "Epoch 310/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4731 - accuracy: 0.8194 - val_loss: 0.4881 - val_accuracy: 0.8025\n",
      "Epoch 311/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4801 - accuracy: 0.7926 - val_loss: 0.5095 - val_accuracy: 0.7407\n",
      "Epoch 312/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.6718 - val_loss: 0.5471 - val_accuracy: 0.6790\n",
      "Epoch 313/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5290 - accuracy: 0.7265 - val_loss: 0.5256 - val_accuracy: 0.7202\n",
      "Epoch 314/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4745 - accuracy: 0.8039 - val_loss: 0.4906 - val_accuracy: 0.7984\n",
      "Epoch 315/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4829 - accuracy: 0.7874 - val_loss: 0.4776 - val_accuracy: 0.7984\n",
      "Epoch 316/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5165 - accuracy: 0.7420 - val_loss: 0.6422 - val_accuracy: 0.6296\n",
      "Epoch 317/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5162 - accuracy: 0.7513 - val_loss: 0.4781 - val_accuracy: 0.8107\n",
      "Epoch 318/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4662 - accuracy: 0.8204 - val_loss: 0.4753 - val_accuracy: 0.8107\n",
      "Epoch 319/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4803 - accuracy: 0.7730 - val_loss: 0.4999 - val_accuracy: 0.7449\n",
      "Epoch 320/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4751 - accuracy: 0.7988 - val_loss: 0.4950 - val_accuracy: 0.7490\n",
      "Epoch 321/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4790 - accuracy: 0.7750 - val_loss: 0.4658 - val_accuracy: 0.8354\n",
      "Epoch 322/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4582 - accuracy: 0.8163 - val_loss: 0.4728 - val_accuracy: 0.7654\n",
      "Epoch 323/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4938 - accuracy: 0.7595 - val_loss: 0.5483 - val_accuracy: 0.6914\n",
      "Epoch 324/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7007 - val_loss: 0.4867 - val_accuracy: 0.7449\n",
      "Epoch 325/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4828 - accuracy: 0.7668 - val_loss: 0.5512 - val_accuracy: 0.6790\n",
      "Epoch 326/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5150 - accuracy: 0.7224 - val_loss: 0.4821 - val_accuracy: 0.7490\n",
      "Epoch 327/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4532 - accuracy: 0.8194 - val_loss: 0.4604 - val_accuracy: 0.8395\n",
      "Epoch 328/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4637 - accuracy: 0.8101 - val_loss: 0.4913 - val_accuracy: 0.7490\n",
      "Epoch 329/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4839 - accuracy: 0.7740 - val_loss: 0.5084 - val_accuracy: 0.7325\n",
      "Epoch 330/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5022 - accuracy: 0.7245 - val_loss: 0.4580 - val_accuracy: 0.8313\n",
      "Epoch 331/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4483 - accuracy: 0.8318 - val_loss: 0.4540 - val_accuracy: 0.8436\n",
      "Epoch 332/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4499 - accuracy: 0.8184 - val_loss: 0.4776 - val_accuracy: 0.7531\n",
      "Epoch 333/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4984 - accuracy: 0.7472 - val_loss: 0.4535 - val_accuracy: 0.8436\n",
      "Epoch 334/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4548 - accuracy: 0.8287 - val_loss: 0.4566 - val_accuracy: 0.8025\n",
      "Epoch 335/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4428 - accuracy: 0.8204 - val_loss: 0.4474 - val_accuracy: 0.8477\n",
      "Epoch 336/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4372 - accuracy: 0.8215 - val_loss: 0.4472 - val_accuracy: 0.8272\n",
      "Epoch 337/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4833 - accuracy: 0.7585 - val_loss: 0.5785 - val_accuracy: 0.6708\n",
      "Epoch 338/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.6883 - val_loss: 0.4600 - val_accuracy: 0.7819\n",
      "Epoch 339/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.8132 - val_loss: 0.4493 - val_accuracy: 0.8189\n",
      "Epoch 340/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4328 - accuracy: 0.8452 - val_loss: 0.4458 - val_accuracy: 0.8107\n",
      "Epoch 341/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4454 - accuracy: 0.8091 - val_loss: 0.4661 - val_accuracy: 0.8148\n",
      "Epoch 342/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4522 - accuracy: 0.8039 - val_loss: 0.4399 - val_accuracy: 0.8230\n",
      "Epoch 343/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4308 - accuracy: 0.8204 - val_loss: 0.4433 - val_accuracy: 0.7984\n",
      "Epoch 344/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4245 - accuracy: 0.8380 - val_loss: 0.4321 - val_accuracy: 0.8560\n",
      "Epoch 345/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.7595 - val_loss: 0.6060 - val_accuracy: 0.6543\n",
      "Epoch 346/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4961 - accuracy: 0.7472 - val_loss: 0.4789 - val_accuracy: 0.7490\n",
      "Epoch 347/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4676 - accuracy: 0.7668 - val_loss: 0.4849 - val_accuracy: 0.7778\n",
      "Epoch 348/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4240 - accuracy: 0.8462 - val_loss: 0.4403 - val_accuracy: 0.8313\n",
      "Epoch 349/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4167 - accuracy: 0.8535 - val_loss: 0.4279 - val_accuracy: 0.8354\n",
      "Epoch 350/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4570 - accuracy: 0.7792 - val_loss: 0.6467 - val_accuracy: 0.6420\n",
      "Epoch 351/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.7792 - val_loss: 0.4288 - val_accuracy: 0.8477\n",
      "Epoch 352/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4108 - accuracy: 0.8596 - val_loss: 0.4401 - val_accuracy: 0.8313\n",
      "Epoch 353/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4257 - accuracy: 0.8204 - val_loss: 0.4203 - val_accuracy: 0.8477\n",
      "Epoch 354/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4040 - accuracy: 0.8545 - val_loss: 0.4176 - val_accuracy: 0.8477\n",
      "Epoch 355/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4386 - accuracy: 0.8019 - val_loss: 0.5433 - val_accuracy: 0.6872\n",
      "Epoch 356/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.7255 - val_loss: 0.4700 - val_accuracy: 0.7490\n",
      "Epoch 357/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.7544 - val_loss: 0.4622 - val_accuracy: 0.7984\n",
      "Epoch 358/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4084 - accuracy: 0.8524 - val_loss: 0.4566 - val_accuracy: 0.8025\n",
      "Epoch 359/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4542 - accuracy: 0.7895 - val_loss: 0.4274 - val_accuracy: 0.8025\n",
      "Epoch 360/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4234 - accuracy: 0.8235 - val_loss: 0.4200 - val_accuracy: 0.8683\n",
      "Epoch 361/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3986 - accuracy: 0.8700 - val_loss: 0.4416 - val_accuracy: 0.8230\n",
      "Epoch 362/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4276 - accuracy: 0.8142 - val_loss: 0.5356 - val_accuracy: 0.6914\n",
      "Epoch 363/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4420 - accuracy: 0.8008 - val_loss: 0.4318 - val_accuracy: 0.8354\n",
      "Epoch 364/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4010 - accuracy: 0.8411 - val_loss: 0.4140 - val_accuracy: 0.8189\n",
      "Epoch 365/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4102 - accuracy: 0.8328 - val_loss: 0.4262 - val_accuracy: 0.8395\n",
      "Epoch 366/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.8297 - val_loss: 0.4158 - val_accuracy: 0.8107\n",
      "Epoch 367/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8524 - val_loss: 0.4243 - val_accuracy: 0.8354\n",
      "Epoch 368/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3813 - accuracy: 0.8762 - val_loss: 0.4032 - val_accuracy: 0.8230\n",
      "Epoch 369/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3881 - accuracy: 0.8524 - val_loss: 0.4384 - val_accuracy: 0.8148\n",
      "Epoch 370/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3758 - accuracy: 0.8731 - val_loss: 0.3919 - val_accuracy: 0.8724\n",
      "Epoch 371/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.8256 - val_loss: 0.4909 - val_accuracy: 0.7531\n",
      "Epoch 372/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4967 - accuracy: 0.7131 - val_loss: 0.4480 - val_accuracy: 0.7572\n",
      "Epoch 373/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4229 - accuracy: 0.7977 - val_loss: 0.3952 - val_accuracy: 0.8889\n",
      "Epoch 374/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3704 - accuracy: 0.8958 - val_loss: 0.3998 - val_accuracy: 0.8642\n",
      "Epoch 375/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3796 - accuracy: 0.8421 - val_loss: 0.3968 - val_accuracy: 0.8724\n",
      "Epoch 376/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3847 - accuracy: 0.8586 - val_loss: 0.4072 - val_accuracy: 0.8066\n",
      "Epoch 377/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3995 - accuracy: 0.8308 - val_loss: 0.4294 - val_accuracy: 0.8272\n",
      "Epoch 378/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3599 - accuracy: 0.8937 - val_loss: 0.4019 - val_accuracy: 0.8025\n",
      "Epoch 379/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3738 - accuracy: 0.8555 - val_loss: 0.4502 - val_accuracy: 0.7942\n",
      "Epoch 380/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4912 - accuracy: 0.7482 - val_loss: 0.6688 - val_accuracy: 0.6337\n",
      "Epoch 381/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4088 - accuracy: 0.8442 - val_loss: 0.3856 - val_accuracy: 0.8642\n",
      "Epoch 382/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3749 - accuracy: 0.8679 - val_loss: 0.5291 - val_accuracy: 0.7202\n",
      "Epoch 383/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8204 - val_loss: 0.3859 - val_accuracy: 0.8272\n",
      "Epoch 384/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3620 - accuracy: 0.8710 - val_loss: 0.3735 - val_accuracy: 0.8848\n",
      "Epoch 385/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3517 - accuracy: 0.8916 - val_loss: 0.4002 - val_accuracy: 0.8395\n",
      "Epoch 386/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3915 - accuracy: 0.8411 - val_loss: 0.6666 - val_accuracy: 0.6379\n",
      "Epoch 387/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5232 - accuracy: 0.7059 - val_loss: 0.6037 - val_accuracy: 0.6708\n",
      "Epoch 388/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4211 - accuracy: 0.8122 - val_loss: 0.3783 - val_accuracy: 0.8807\n",
      "Epoch 389/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3697 - accuracy: 0.8762 - val_loss: 0.4336 - val_accuracy: 0.8148\n",
      "Epoch 390/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3795 - accuracy: 0.8400 - val_loss: 0.3723 - val_accuracy: 0.9053\n",
      "Epoch 391/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.8937 - val_loss: 0.3663 - val_accuracy: 0.9053\n",
      "Epoch 392/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3545 - accuracy: 0.8803 - val_loss: 0.3887 - val_accuracy: 0.8066\n",
      "Epoch 393/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3689 - accuracy: 0.8576 - val_loss: 0.3657 - val_accuracy: 0.9218\n",
      "Epoch 394/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.8844 - val_loss: 0.3992 - val_accuracy: 0.8025\n",
      "Epoch 395/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4299 - accuracy: 0.7771 - val_loss: 0.5145 - val_accuracy: 0.7243\n",
      "Epoch 396/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8369 - val_loss: 0.3626 - val_accuracy: 0.9177\n",
      "Epoch 397/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.9092 - val_loss: 0.3570 - val_accuracy: 0.8930\n",
      "Epoch 398/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.9030 - val_loss: 0.3560 - val_accuracy: 0.8848\n",
      "Epoch 399/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3472 - accuracy: 0.8669 - val_loss: 0.4488 - val_accuracy: 0.7778\n",
      "Epoch 400/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3915 - accuracy: 0.8060 - val_loss: 0.3734 - val_accuracy: 0.8230\n",
      "Epoch 401/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3678 - accuracy: 0.8462 - val_loss: 0.4876 - val_accuracy: 0.7531\n",
      "Epoch 402/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8524 - val_loss: 0.3661 - val_accuracy: 0.8313\n",
      "Epoch 403/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.8741 - val_loss: 0.3875 - val_accuracy: 0.8395\n",
      "Epoch 404/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3290 - accuracy: 0.8803 - val_loss: 0.4385 - val_accuracy: 0.7942\n",
      "Epoch 405/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4295 - accuracy: 0.7668 - val_loss: 0.3903 - val_accuracy: 0.8025\n",
      "Epoch 406/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4014 - accuracy: 0.8111 - val_loss: 0.3546 - val_accuracy: 0.9259\n",
      "Epoch 407/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3133 - accuracy: 0.9205 - val_loss: 0.3470 - val_accuracy: 0.9342\n",
      "Epoch 408/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3113 - accuracy: 0.9164 - val_loss: 0.3397 - val_accuracy: 0.9095\n",
      "Epoch 409/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3197 - accuracy: 0.8947 - val_loss: 0.3734 - val_accuracy: 0.8436\n",
      "Epoch 410/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3092 - accuracy: 0.9092 - val_loss: 0.3793 - val_accuracy: 0.8395\n",
      "Epoch 411/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4236 - accuracy: 0.7884 - val_loss: 0.4449 - val_accuracy: 0.7407\n",
      "Epoch 412/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8173 - val_loss: 0.3975 - val_accuracy: 0.8354\n",
      "Epoch 413/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3176 - accuracy: 0.8927 - val_loss: 0.3440 - val_accuracy: 0.8724\n",
      "Epoch 414/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3060 - accuracy: 0.9051 - val_loss: 0.3435 - val_accuracy: 0.8519\n",
      "Epoch 415/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3261 - accuracy: 0.8803 - val_loss: 0.4360 - val_accuracy: 0.7901\n",
      "Epoch 416/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4553 - accuracy: 0.7575 - val_loss: 0.4248 - val_accuracy: 0.7572\n",
      "Epoch 417/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3467 - accuracy: 0.8669 - val_loss: 0.3523 - val_accuracy: 0.8848\n",
      "Epoch 418/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3014 - accuracy: 0.9143 - val_loss: 0.3276 - val_accuracy: 0.9383\n",
      "Epoch 419/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3033 - accuracy: 0.9102 - val_loss: 0.3252 - val_accuracy: 0.9383\n",
      "Epoch 420/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3057 - accuracy: 0.9030 - val_loss: 0.3365 - val_accuracy: 0.9053\n",
      "Epoch 421/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2919 - accuracy: 0.9226 - val_loss: 0.3271 - val_accuracy: 0.8724\n",
      "Epoch 422/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3375 - accuracy: 0.8658 - val_loss: 0.5026 - val_accuracy: 0.7407\n",
      "Epoch 423/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3666 - accuracy: 0.8256 - val_loss: 0.3360 - val_accuracy: 0.8560\n",
      "Epoch 424/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2908 - accuracy: 0.9247 - val_loss: 0.3183 - val_accuracy: 0.9383\n",
      "Epoch 425/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2800 - accuracy: 0.9257 - val_loss: 0.3309 - val_accuracy: 0.8971\n",
      "Epoch 426/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2991 - accuracy: 0.9040 - val_loss: 0.4411 - val_accuracy: 0.7407\n",
      "Epoch 427/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3905 - accuracy: 0.7895 - val_loss: 0.4922 - val_accuracy: 0.7572\n",
      "Epoch 428/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3832 - accuracy: 0.8215 - val_loss: 0.3695 - val_accuracy: 0.8230\n",
      "Epoch 429/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3597 - accuracy: 0.8349 - val_loss: 0.3757 - val_accuracy: 0.8354\n",
      "Epoch 430/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2931 - accuracy: 0.9133 - val_loss: 0.3272 - val_accuracy: 0.8560\n",
      "Epoch 431/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3154 - accuracy: 0.8865 - val_loss: 0.3786 - val_accuracy: 0.8395\n",
      "Epoch 432/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3048 - accuracy: 0.8854 - val_loss: 0.3139 - val_accuracy: 0.9177\n",
      "Epoch 433/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2751 - accuracy: 0.9236 - val_loss: 0.3243 - val_accuracy: 0.8560\n",
      "Epoch 434/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2998 - accuracy: 0.8844 - val_loss: 0.3076 - val_accuracy: 0.9465\n",
      "Epoch 435/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3092 - accuracy: 0.8896 - val_loss: 0.5810 - val_accuracy: 0.7160\n",
      "Epoch 436/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4734 - accuracy: 0.7482 - val_loss: 0.3454 - val_accuracy: 0.8560\n",
      "Epoch 437/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2889 - accuracy: 0.9133 - val_loss: 0.4128 - val_accuracy: 0.8107\n",
      "Epoch 438/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2882 - accuracy: 0.9020 - val_loss: 0.3205 - val_accuracy: 0.9053\n",
      "Epoch 439/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2674 - accuracy: 0.9309 - val_loss: 0.3010 - val_accuracy: 0.9588\n",
      "Epoch 440/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2572 - accuracy: 0.9422 - val_loss: 0.3037 - val_accuracy: 0.9383\n",
      "Epoch 441/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2539 - accuracy: 0.9422 - val_loss: 0.2967 - val_accuracy: 0.9588\n",
      "Epoch 442/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2522 - accuracy: 0.9391 - val_loss: 0.3191 - val_accuracy: 0.8807\n",
      "Epoch 443/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2784 - accuracy: 0.9092 - val_loss: 0.4145 - val_accuracy: 0.7531\n",
      "Epoch 444/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4140 - accuracy: 0.7853 - val_loss: 0.3901 - val_accuracy: 0.8313\n",
      "Epoch 445/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2864 - accuracy: 0.8978 - val_loss: 0.3026 - val_accuracy: 0.8971\n",
      "Epoch 446/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2556 - accuracy: 0.9329 - val_loss: 0.3077 - val_accuracy: 0.8848\n",
      "Epoch 447/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2927 - accuracy: 0.8885 - val_loss: 0.3139 - val_accuracy: 0.8889\n",
      "Epoch 448/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2590 - accuracy: 0.9370 - val_loss: 0.3506 - val_accuracy: 0.8436\n",
      "Epoch 449/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3382 - accuracy: 0.8421 - val_loss: 0.4453 - val_accuracy: 0.7490\n",
      "Epoch 450/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3775 - accuracy: 0.7915 - val_loss: 0.3417 - val_accuracy: 0.8601\n",
      "Epoch 451/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2599 - accuracy: 0.9278 - val_loss: 0.2992 - val_accuracy: 0.8930\n",
      "Epoch 452/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2610 - accuracy: 0.9298 - val_loss: 0.2927 - val_accuracy: 0.9424\n",
      "Epoch 453/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2380 - accuracy: 0.9484 - val_loss: 0.2783 - val_accuracy: 0.9506\n",
      "Epoch 454/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2663 - accuracy: 0.9143 - val_loss: 0.3329 - val_accuracy: 0.8560\n",
      "Epoch 455/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2620 - accuracy: 0.9082 - val_loss: 0.2849 - val_accuracy: 0.9177\n",
      "Epoch 456/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.9370 - val_loss: 0.2722 - val_accuracy: 0.9588\n",
      "Epoch 457/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2292 - accuracy: 0.9505 - val_loss: 0.2753 - val_accuracy: 0.9300\n",
      "Epoch 458/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3095 - accuracy: 0.8875 - val_loss: 0.7332 - val_accuracy: 0.6584\n",
      "Epoch 459/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.2838 - val_accuracy: 0.9300\n",
      "Epoch 460/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.9267 - val_loss: 0.3279 - val_accuracy: 0.8683\n",
      "Epoch 461/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3161 - accuracy: 0.8689 - val_loss: 0.3981 - val_accuracy: 0.7695\n",
      "Epoch 462/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3271 - accuracy: 0.8596 - val_loss: 0.2967 - val_accuracy: 0.9177\n",
      "Epoch 463/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2511 - accuracy: 0.9278 - val_loss: 0.2759 - val_accuracy: 0.9259\n",
      "Epoch 464/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2330 - accuracy: 0.9515 - val_loss: 0.2942 - val_accuracy: 0.9095\n",
      "Epoch 465/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2379 - accuracy: 0.9412 - val_loss: 0.2828 - val_accuracy: 0.9012\n",
      "Epoch 466/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2975 - accuracy: 0.8627 - val_loss: 0.3632 - val_accuracy: 0.8436\n",
      "Epoch 467/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2864 - accuracy: 0.8844 - val_loss: 0.2666 - val_accuracy: 0.9630\n",
      "Epoch 468/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2235 - accuracy: 0.9505 - val_loss: 0.2620 - val_accuracy: 0.9506\n",
      "Epoch 469/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2214 - accuracy: 0.9525 - val_loss: 0.2609 - val_accuracy: 0.9588\n",
      "Epoch 470/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2125 - accuracy: 0.9546 - val_loss: 0.2614 - val_accuracy: 0.9342\n",
      "Epoch 471/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2168 - accuracy: 0.9443 - val_loss: 0.3039 - val_accuracy: 0.8807\n",
      "Epoch 472/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.8741 - val_loss: 0.4873 - val_accuracy: 0.7243\n",
      "Epoch 473/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3379 - accuracy: 0.8421 - val_loss: 0.4111 - val_accuracy: 0.8107\n",
      "Epoch 474/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2872 - accuracy: 0.8824 - val_loss: 0.3231 - val_accuracy: 0.8601\n",
      "Epoch 475/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2396 - accuracy: 0.9360 - val_loss: 0.2716 - val_accuracy: 0.9383\n",
      "Epoch 476/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2215 - accuracy: 0.9484 - val_loss: 0.2723 - val_accuracy: 0.9012\n",
      "Epoch 477/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2505 - accuracy: 0.9185 - val_loss: 0.2995 - val_accuracy: 0.8930\n",
      "Epoch 478/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2122 - accuracy: 0.9484 - val_loss: 0.2510 - val_accuracy: 0.9630\n",
      "Epoch 479/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2017 - accuracy: 0.9577 - val_loss: 0.2898 - val_accuracy: 0.9012\n",
      "Epoch 480/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2972 - accuracy: 0.8586 - val_loss: 0.3820 - val_accuracy: 0.7860\n",
      "Epoch 481/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2509 - accuracy: 0.9236 - val_loss: 0.2850 - val_accuracy: 0.9012\n",
      "Epoch 482/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1983 - accuracy: 0.9598 - val_loss: 0.2532 - val_accuracy: 0.9588\n",
      "Epoch 483/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1968 - accuracy: 0.9587 - val_loss: 0.2450 - val_accuracy: 0.9506\n",
      "Epoch 484/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2271 - accuracy: 0.9309 - val_loss: 0.3518 - val_accuracy: 0.8436\n",
      "Epoch 485/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2636 - accuracy: 0.9051 - val_loss: 0.4498 - val_accuracy: 0.7490\n",
      "Epoch 486/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3511 - accuracy: 0.8204 - val_loss: 0.3269 - val_accuracy: 0.8642\n",
      "Epoch 487/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2175 - accuracy: 0.9474 - val_loss: 0.2552 - val_accuracy: 0.9218\n",
      "Epoch 488/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2234 - accuracy: 0.9370 - val_loss: 0.2893 - val_accuracy: 0.9012\n",
      "Epoch 489/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1965 - accuracy: 0.9515 - val_loss: 0.2447 - val_accuracy: 0.9383\n",
      "Epoch 490/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1962 - accuracy: 0.9567 - val_loss: 0.2797 - val_accuracy: 0.9053\n",
      "Epoch 491/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1878 - accuracy: 0.9628 - val_loss: 0.2797 - val_accuracy: 0.9012\n",
      "Epoch 492/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2408 - accuracy: 0.9236 - val_loss: 0.3029 - val_accuracy: 0.8560\n",
      "Epoch 493/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2545 - accuracy: 0.8958 - val_loss: 0.3091 - val_accuracy: 0.8724\n",
      "Epoch 494/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.8338 - val_loss: 0.5460 - val_accuracy: 0.6872\n",
      "Epoch 495/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.8008 - val_loss: 0.2500 - val_accuracy: 0.9547\n",
      "Epoch 496/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1912 - accuracy: 0.9628 - val_loss: 0.2617 - val_accuracy: 0.9342\n",
      "Epoch 497/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1921 - accuracy: 0.9556 - val_loss: 0.2353 - val_accuracy: 0.9588\n",
      "Epoch 498/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1886 - accuracy: 0.9608 - val_loss: 0.2412 - val_accuracy: 0.9547\n",
      "Epoch 499/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1797 - accuracy: 0.9659 - val_loss: 0.2690 - val_accuracy: 0.9177\n",
      "Epoch 500/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1904 - accuracy: 0.9587 - val_loss: 0.2317 - val_accuracy: 0.9506\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sleepy       0.94      0.99      0.96       151\n",
      "    vigilant       0.99      0.93      0.96       152\n",
      "\n",
      "    accuracy                           0.96       303\n",
      "   macro avg       0.96      0.96      0.96       303\n",
      "weighted avg       0.96      0.96      0.96       303\n",
      "\n",
      "[INFO] compiling model fold5.....\n",
      "[INFO] training network...\n",
      "(969, 28, 28, 1) (303, 28, 28, 1) (969, 2) (303, 2)\n",
      "Train on 969 samples, validate on 243 samples\n",
      "Epoch 1/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.6979 - accuracy: 0.4665 - val_loss: 0.6941 - val_accuracy: 0.5144\n",
      "Epoch 2/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6954 - accuracy: 0.4407 - val_loss: 0.6935 - val_accuracy: 0.4568\n",
      "Epoch 3/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6937 - accuracy: 0.5057 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
      "Epoch 4/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6923 - accuracy: 0.5428 - val_loss: 0.6924 - val_accuracy: 0.4979\n",
      "Epoch 5/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6916 - val_accuracy: 0.4897\n",
      "Epoch 6/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6900 - accuracy: 0.5212 - val_loss: 0.6907 - val_accuracy: 0.4979\n",
      "Epoch 7/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6890 - accuracy: 0.5253 - val_loss: 0.6899 - val_accuracy: 0.5021\n",
      "Epoch 8/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6879 - accuracy: 0.5253 - val_loss: 0.6892 - val_accuracy: 0.5021\n",
      "Epoch 9/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5418 - val_loss: 0.6886 - val_accuracy: 0.5021\n",
      "Epoch 10/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5346 - val_loss: 0.6878 - val_accuracy: 0.5309\n",
      "Epoch 11/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5707 - val_loss: 0.6874 - val_accuracy: 0.5226\n",
      "Epoch 12/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5511 - val_loss: 0.6867 - val_accuracy: 0.5226\n",
      "Epoch 13/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5593 - val_loss: 0.6860 - val_accuracy: 0.5350\n",
      "Epoch 14/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6830 - accuracy: 0.5831 - val_loss: 0.6856 - val_accuracy: 0.5267\n",
      "Epoch 15/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6822 - accuracy: 0.5707 - val_loss: 0.6846 - val_accuracy: 0.5350\n",
      "Epoch 16/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6817 - accuracy: 0.5934 - val_loss: 0.6842 - val_accuracy: 0.5391\n",
      "Epoch 17/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6808 - accuracy: 0.5862 - val_loss: 0.6836 - val_accuracy: 0.5556\n",
      "Epoch 18/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6802 - accuracy: 0.5986 - val_loss: 0.6833 - val_accuracy: 0.5473\n",
      "Epoch 19/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6793 - accuracy: 0.5820 - val_loss: 0.6825 - val_accuracy: 0.5761\n",
      "Epoch 20/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6788 - accuracy: 0.6058 - val_loss: 0.6825 - val_accuracy: 0.5391\n",
      "Epoch 21/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6779 - accuracy: 0.5810 - val_loss: 0.6816 - val_accuracy: 0.5802\n",
      "Epoch 22/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6781 - accuracy: 0.6027 - val_loss: 0.6814 - val_accuracy: 0.5679\n",
      "Epoch 23/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6767 - accuracy: 0.6130 - val_loss: 0.6811 - val_accuracy: 0.5720\n",
      "Epoch 24/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6760 - accuracy: 0.6078 - val_loss: 0.6805 - val_accuracy: 0.5761\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6753 - accuracy: 0.6058 - val_loss: 0.6798 - val_accuracy: 0.5761\n",
      "Epoch 26/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6746 - accuracy: 0.6130 - val_loss: 0.6791 - val_accuracy: 0.5761\n",
      "Epoch 27/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6739 - accuracy: 0.6171 - val_loss: 0.6787 - val_accuracy: 0.5638\n",
      "Epoch 28/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6734 - accuracy: 0.6120 - val_loss: 0.6779 - val_accuracy: 0.5802\n",
      "Epoch 29/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6725 - accuracy: 0.6223 - val_loss: 0.6773 - val_accuracy: 0.5844\n",
      "Epoch 30/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6720 - accuracy: 0.6151 - val_loss: 0.6769 - val_accuracy: 0.5802\n",
      "Epoch 31/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6714 - accuracy: 0.6130 - val_loss: 0.6762 - val_accuracy: 0.5967\n",
      "Epoch 32/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6705 - accuracy: 0.6182 - val_loss: 0.6756 - val_accuracy: 0.6008\n",
      "Epoch 33/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6700 - accuracy: 0.6213 - val_loss: 0.6749 - val_accuracy: 0.6008\n",
      "Epoch 34/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6695 - accuracy: 0.6233 - val_loss: 0.6752 - val_accuracy: 0.5885\n",
      "Epoch 35/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6684 - accuracy: 0.6182 - val_loss: 0.6746 - val_accuracy: 0.5926\n",
      "Epoch 36/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6680 - accuracy: 0.6171 - val_loss: 0.6738 - val_accuracy: 0.5926\n",
      "Epoch 37/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6672 - accuracy: 0.6182 - val_loss: 0.6730 - val_accuracy: 0.5967\n",
      "Epoch 38/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6665 - accuracy: 0.6140 - val_loss: 0.6725 - val_accuracy: 0.6008\n",
      "Epoch 39/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6657 - accuracy: 0.6161 - val_loss: 0.6720 - val_accuracy: 0.6008\n",
      "Epoch 40/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6653 - accuracy: 0.6120 - val_loss: 0.6713 - val_accuracy: 0.6049\n",
      "Epoch 41/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6648 - accuracy: 0.6120 - val_loss: 0.6704 - val_accuracy: 0.5967\n",
      "Epoch 42/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6644 - accuracy: 0.6078 - val_loss: 0.6706 - val_accuracy: 0.5967\n",
      "Epoch 43/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6629 - accuracy: 0.6140 - val_loss: 0.6702 - val_accuracy: 0.5926\n",
      "Epoch 44/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6621 - accuracy: 0.6140 - val_loss: 0.6694 - val_accuracy: 0.5967\n",
      "Epoch 45/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6614 - accuracy: 0.6151 - val_loss: 0.6691 - val_accuracy: 0.5967\n",
      "Epoch 46/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6607 - accuracy: 0.6120 - val_loss: 0.6686 - val_accuracy: 0.5967\n",
      "Epoch 47/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6601 - accuracy: 0.6109 - val_loss: 0.6683 - val_accuracy: 0.5926\n",
      "Epoch 48/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6599 - accuracy: 0.6151 - val_loss: 0.6680 - val_accuracy: 0.5926\n",
      "Epoch 49/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6591 - accuracy: 0.6213 - val_loss: 0.6664 - val_accuracy: 0.5967\n",
      "Epoch 50/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6582 - accuracy: 0.6068 - val_loss: 0.6668 - val_accuracy: 0.5844\n",
      "Epoch 51/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6575 - accuracy: 0.6151 - val_loss: 0.6657 - val_accuracy: 0.5844\n",
      "Epoch 52/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6571 - accuracy: 0.6120 - val_loss: 0.6651 - val_accuracy: 0.5926\n",
      "Epoch 53/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6182 - val_loss: 0.6652 - val_accuracy: 0.5844\n",
      "Epoch 54/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.6151 - val_loss: 0.6653 - val_accuracy: 0.5844\n",
      "Epoch 55/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.6120 - val_loss: 0.6650 - val_accuracy: 0.5926\n",
      "Epoch 56/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6545 - accuracy: 0.6078 - val_loss: 0.6642 - val_accuracy: 0.5844\n",
      "Epoch 57/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6534 - accuracy: 0.6099 - val_loss: 0.6648 - val_accuracy: 0.5967\n",
      "Epoch 58/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6529 - accuracy: 0.6202 - val_loss: 0.6633 - val_accuracy: 0.5844\n",
      "Epoch 59/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6522 - accuracy: 0.6151 - val_loss: 0.6627 - val_accuracy: 0.5802\n",
      "Epoch 60/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6513 - accuracy: 0.6120 - val_loss: 0.6617 - val_accuracy: 0.5885\n",
      "Epoch 61/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6507 - accuracy: 0.6182 - val_loss: 0.6612 - val_accuracy: 0.5885\n",
      "Epoch 62/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.6151 - val_loss: 0.6612 - val_accuracy: 0.5802\n",
      "Epoch 63/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6494 - accuracy: 0.6140 - val_loss: 0.6600 - val_accuracy: 0.5885\n",
      "Epoch 64/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.6140 - val_loss: 0.6598 - val_accuracy: 0.5885\n",
      "Epoch 65/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.6171 - val_loss: 0.6597 - val_accuracy: 0.5802\n",
      "Epoch 66/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6491 - accuracy: 0.6140 - val_loss: 0.6593 - val_accuracy: 0.5844\n",
      "Epoch 67/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6471 - accuracy: 0.6244 - val_loss: 0.6605 - val_accuracy: 0.5967\n",
      "Epoch 68/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6469 - accuracy: 0.6182 - val_loss: 0.6584 - val_accuracy: 0.5844\n",
      "Epoch 69/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6461 - accuracy: 0.6213 - val_loss: 0.6575 - val_accuracy: 0.5885\n",
      "Epoch 70/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6466 - accuracy: 0.6171 - val_loss: 0.6572 - val_accuracy: 0.5926\n",
      "Epoch 71/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6450 - accuracy: 0.6254 - val_loss: 0.6615 - val_accuracy: 0.5967\n",
      "Epoch 72/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6461 - accuracy: 0.6171 - val_loss: 0.6584 - val_accuracy: 0.5967\n",
      "Epoch 73/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6443 - accuracy: 0.6244 - val_loss: 0.6554 - val_accuracy: 0.6091\n",
      "Epoch 74/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6435 - accuracy: 0.6192 - val_loss: 0.6554 - val_accuracy: 0.6008\n",
      "Epoch 75/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6426 - accuracy: 0.6275 - val_loss: 0.6568 - val_accuracy: 0.5926\n",
      "Epoch 76/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6254 - val_loss: 0.6548 - val_accuracy: 0.5967\n",
      "Epoch 77/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6433 - accuracy: 0.6213 - val_loss: 0.6551 - val_accuracy: 0.5802\n",
      "Epoch 78/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6411 - accuracy: 0.6254 - val_loss: 0.6540 - val_accuracy: 0.5885\n",
      "Epoch 79/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6410 - accuracy: 0.6223 - val_loss: 0.6524 - val_accuracy: 0.6255\n",
      "Epoch 80/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6408 - accuracy: 0.6367 - val_loss: 0.6525 - val_accuracy: 0.6008\n",
      "Epoch 81/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6396 - accuracy: 0.6254 - val_loss: 0.6519 - val_accuracy: 0.6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6392 - accuracy: 0.6347 - val_loss: 0.6511 - val_accuracy: 0.6214\n",
      "Epoch 83/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6391 - accuracy: 0.6336 - val_loss: 0.6506 - val_accuracy: 0.6379\n",
      "Epoch 84/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6376 - accuracy: 0.6491 - val_loss: 0.6522 - val_accuracy: 0.5885\n",
      "Epoch 85/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6372 - accuracy: 0.6305 - val_loss: 0.6500 - val_accuracy: 0.6008\n",
      "Epoch 86/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6366 - accuracy: 0.6347 - val_loss: 0.6495 - val_accuracy: 0.6049\n",
      "Epoch 87/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6360 - accuracy: 0.6264 - val_loss: 0.6490 - val_accuracy: 0.6049\n",
      "Epoch 88/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6364 - accuracy: 0.6398 - val_loss: 0.6525 - val_accuracy: 0.5926\n",
      "Epoch 89/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6375 - accuracy: 0.6275 - val_loss: 0.6506 - val_accuracy: 0.5967\n",
      "Epoch 90/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6344 - accuracy: 0.6378 - val_loss: 0.6477 - val_accuracy: 0.6049\n",
      "Epoch 91/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6337 - accuracy: 0.6357 - val_loss: 0.6496 - val_accuracy: 0.5967\n",
      "Epoch 92/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6345 - accuracy: 0.6305 - val_loss: 0.6475 - val_accuracy: 0.6008\n",
      "Epoch 93/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6329 - accuracy: 0.6378 - val_loss: 0.6462 - val_accuracy: 0.6049\n",
      "Epoch 94/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6388 - val_loss: 0.6471 - val_accuracy: 0.6008\n",
      "Epoch 95/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6310 - accuracy: 0.6367 - val_loss: 0.6464 - val_accuracy: 0.5967\n",
      "Epoch 96/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6311 - accuracy: 0.6378 - val_loss: 0.6444 - val_accuracy: 0.6337\n",
      "Epoch 97/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6299 - accuracy: 0.6533 - val_loss: 0.6454 - val_accuracy: 0.5967\n",
      "Epoch 98/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6300 - accuracy: 0.6450 - val_loss: 0.6440 - val_accuracy: 0.6173\n",
      "Epoch 99/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6296 - accuracy: 0.6378 - val_loss: 0.6439 - val_accuracy: 0.6049\n",
      "Epoch 100/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6281 - accuracy: 0.6409 - val_loss: 0.6422 - val_accuracy: 0.6379\n",
      "Epoch 101/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6276 - accuracy: 0.6481 - val_loss: 0.6416 - val_accuracy: 0.6379\n",
      "Epoch 102/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6274 - accuracy: 0.6419 - val_loss: 0.6410 - val_accuracy: 0.6461\n",
      "Epoch 103/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6270 - accuracy: 0.6460 - val_loss: 0.6406 - val_accuracy: 0.6379\n",
      "Epoch 104/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6268 - accuracy: 0.6553 - val_loss: 0.6398 - val_accuracy: 0.6461\n",
      "Epoch 105/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6272 - accuracy: 0.6481 - val_loss: 0.6409 - val_accuracy: 0.6214\n",
      "Epoch 106/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6251 - accuracy: 0.6512 - val_loss: 0.6408 - val_accuracy: 0.6214\n",
      "Epoch 107/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6239 - accuracy: 0.6512 - val_loss: 0.6392 - val_accuracy: 0.6255\n",
      "Epoch 108/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6237 - accuracy: 0.6533 - val_loss: 0.6379 - val_accuracy: 0.6337\n",
      "Epoch 109/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6242 - accuracy: 0.6512 - val_loss: 0.6379 - val_accuracy: 0.6296\n",
      "Epoch 110/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6229 - accuracy: 0.6471 - val_loss: 0.6371 - val_accuracy: 0.6379\n",
      "Epoch 111/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6235 - accuracy: 0.6646 - val_loss: 0.6364 - val_accuracy: 0.6296\n",
      "Epoch 112/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6217 - accuracy: 0.6502 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 113/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6204 - accuracy: 0.6574 - val_loss: 0.6386 - val_accuracy: 0.6049\n",
      "Epoch 114/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6196 - accuracy: 0.6605 - val_loss: 0.6338 - val_accuracy: 0.6461\n",
      "Epoch 115/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6183 - accuracy: 0.6574 - val_loss: 0.6358 - val_accuracy: 0.6255\n",
      "Epoch 116/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.6605 - val_loss: 0.6335 - val_accuracy: 0.6337\n",
      "Epoch 117/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6197 - accuracy: 0.6605 - val_loss: 0.6353 - val_accuracy: 0.6255\n",
      "Epoch 118/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6178 - accuracy: 0.6615 - val_loss: 0.6327 - val_accuracy: 0.6379\n",
      "Epoch 119/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6158 - accuracy: 0.6594 - val_loss: 0.6330 - val_accuracy: 0.6296\n",
      "Epoch 120/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6150 - accuracy: 0.6533 - val_loss: 0.6317 - val_accuracy: 0.6337\n",
      "Epoch 121/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6154 - accuracy: 0.6636 - val_loss: 0.6298 - val_accuracy: 0.6420\n",
      "Epoch 122/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6141 - accuracy: 0.6667 - val_loss: 0.6302 - val_accuracy: 0.6379\n",
      "Epoch 123/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6146 - accuracy: 0.6594 - val_loss: 0.6279 - val_accuracy: 0.6543\n",
      "Epoch 124/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6138 - accuracy: 0.6729 - val_loss: 0.6298 - val_accuracy: 0.6337\n",
      "Epoch 125/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6133 - accuracy: 0.6605 - val_loss: 0.6270 - val_accuracy: 0.6626\n",
      "Epoch 126/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6108 - accuracy: 0.6594 - val_loss: 0.6295 - val_accuracy: 0.6214\n",
      "Epoch 127/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6122 - accuracy: 0.6677 - val_loss: 0.6265 - val_accuracy: 0.6461\n",
      "Epoch 128/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6111 - accuracy: 0.6687 - val_loss: 0.6273 - val_accuracy: 0.6296\n",
      "Epoch 129/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6092 - accuracy: 0.6698 - val_loss: 0.6257 - val_accuracy: 0.6379\n",
      "Epoch 130/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6071 - accuracy: 0.6636 - val_loss: 0.6245 - val_accuracy: 0.6461\n",
      "Epoch 131/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6098 - accuracy: 0.6667 - val_loss: 0.6225 - val_accuracy: 0.6502\n",
      "Epoch 132/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6080 - accuracy: 0.6667 - val_loss: 0.6223 - val_accuracy: 0.6584\n",
      "Epoch 133/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6059 - accuracy: 0.6729 - val_loss: 0.6206 - val_accuracy: 0.6584\n",
      "Epoch 134/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6043 - accuracy: 0.6698 - val_loss: 0.6247 - val_accuracy: 0.6337\n",
      "Epoch 135/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6090 - accuracy: 0.6729 - val_loss: 0.6239 - val_accuracy: 0.6337\n",
      "Epoch 136/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6042 - accuracy: 0.6791 - val_loss: 0.6240 - val_accuracy: 0.6337\n",
      "Epoch 137/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6037 - accuracy: 0.6801 - val_loss: 0.6200 - val_accuracy: 0.6749\n",
      "Epoch 138/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6027 - accuracy: 0.6718 - val_loss: 0.6197 - val_accuracy: 0.6379\n",
      "Epoch 139/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6001 - accuracy: 0.6729 - val_loss: 0.6266 - val_accuracy: 0.6420\n",
      "Epoch 140/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6066 - accuracy: 0.6801 - val_loss: 0.6160 - val_accuracy: 0.6667\n",
      "Epoch 141/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5989 - accuracy: 0.6791 - val_loss: 0.6144 - val_accuracy: 0.6749\n",
      "Epoch 142/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5998 - accuracy: 0.6749 - val_loss: 0.6157 - val_accuracy: 0.6420\n",
      "Epoch 143/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5968 - accuracy: 0.6873 - val_loss: 0.6135 - val_accuracy: 0.6831\n",
      "Epoch 144/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5948 - accuracy: 0.6904 - val_loss: 0.6173 - val_accuracy: 0.6379\n",
      "Epoch 145/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5939 - accuracy: 0.6925 - val_loss: 0.6254 - val_accuracy: 0.6543\n",
      "Epoch 146/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5985 - accuracy: 0.6914 - val_loss: 0.6102 - val_accuracy: 0.6790\n",
      "Epoch 147/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5939 - accuracy: 0.6873 - val_loss: 0.6111 - val_accuracy: 0.6584\n",
      "Epoch 148/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5956 - accuracy: 0.6863 - val_loss: 0.6176 - val_accuracy: 0.6584\n",
      "Epoch 149/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5985 - accuracy: 0.6625 - val_loss: 0.6094 - val_accuracy: 0.6831\n",
      "Epoch 150/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5913 - accuracy: 0.6935 - val_loss: 0.6069 - val_accuracy: 0.6872\n",
      "Epoch 151/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5895 - accuracy: 0.6852 - val_loss: 0.6077 - val_accuracy: 0.6584\n",
      "Epoch 152/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5899 - accuracy: 0.6966 - val_loss: 0.6070 - val_accuracy: 0.6584\n",
      "Epoch 153/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5908 - accuracy: 0.6966 - val_loss: 0.6050 - val_accuracy: 0.6667\n",
      "Epoch 154/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5857 - accuracy: 0.6935 - val_loss: 0.6072 - val_accuracy: 0.6626\n",
      "Epoch 155/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5870 - accuracy: 0.7038 - val_loss: 0.6035 - val_accuracy: 0.6667\n",
      "Epoch 156/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5834 - accuracy: 0.6945 - val_loss: 0.6017 - val_accuracy: 0.6708\n",
      "Epoch 157/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5855 - accuracy: 0.6945 - val_loss: 0.6006 - val_accuracy: 0.6955\n",
      "Epoch 158/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5823 - accuracy: 0.6883 - val_loss: 0.5997 - val_accuracy: 0.6831\n",
      "Epoch 159/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5805 - accuracy: 0.6987 - val_loss: 0.6008 - val_accuracy: 0.6790\n",
      "Epoch 160/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5790 - accuracy: 0.7038 - val_loss: 0.5975 - val_accuracy: 0.6790\n",
      "Epoch 161/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.6935 - val_loss: 0.6158 - val_accuracy: 0.6502\n",
      "Epoch 162/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6019 - accuracy: 0.6646 - val_loss: 0.5987 - val_accuracy: 0.6872\n",
      "Epoch 163/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5809 - accuracy: 0.7059 - val_loss: 0.5950 - val_accuracy: 0.6914\n",
      "Epoch 164/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6154 - accuracy: 0.6553 - val_loss: 0.6365 - val_accuracy: 0.6296\n",
      "Epoch 165/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5883 - accuracy: 0.6935 - val_loss: 0.6127 - val_accuracy: 0.6379\n",
      "Epoch 166/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5777 - accuracy: 0.7131 - val_loss: 0.5930 - val_accuracy: 0.6955\n",
      "Epoch 167/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5715 - accuracy: 0.7214 - val_loss: 0.5970 - val_accuracy: 0.6790\n",
      "Epoch 168/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5755 - accuracy: 0.7152 - val_loss: 0.6184 - val_accuracy: 0.6132\n",
      "Epoch 169/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5837 - accuracy: 0.7069 - val_loss: 0.6066 - val_accuracy: 0.6708\n",
      "Epoch 170/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5733 - accuracy: 0.7141 - val_loss: 0.5950 - val_accuracy: 0.6914\n",
      "Epoch 171/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.7265 - val_loss: 0.5951 - val_accuracy: 0.6872\n",
      "Epoch 172/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5698 - accuracy: 0.7286 - val_loss: 0.5936 - val_accuracy: 0.6914\n",
      "Epoch 173/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5734 - accuracy: 0.7131 - val_loss: 0.5860 - val_accuracy: 0.6955\n",
      "Epoch 174/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5730 - accuracy: 0.6904 - val_loss: 0.5875 - val_accuracy: 0.6872\n",
      "Epoch 175/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5768 - accuracy: 0.6904 - val_loss: 0.5841 - val_accuracy: 0.6996\n",
      "Epoch 176/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7100 - val_loss: 0.5834 - val_accuracy: 0.6955\n",
      "Epoch 177/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5761 - accuracy: 0.7028 - val_loss: 0.5872 - val_accuracy: 0.6996\n",
      "Epoch 178/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7296 - val_loss: 0.6080 - val_accuracy: 0.6584\n",
      "Epoch 179/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5751 - accuracy: 0.6873 - val_loss: 0.5801 - val_accuracy: 0.7037\n",
      "Epoch 180/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5781 - accuracy: 0.6832 - val_loss: 0.5841 - val_accuracy: 0.7037\n",
      "Epoch 181/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5727 - accuracy: 0.6976 - val_loss: 0.5783 - val_accuracy: 0.6996\n",
      "Epoch 182/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.7389 - val_loss: 0.5784 - val_accuracy: 0.7078\n",
      "Epoch 183/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5566 - accuracy: 0.7410 - val_loss: 0.5768 - val_accuracy: 0.7037\n",
      "Epoch 184/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5907 - accuracy: 0.6708 - val_loss: 0.6685 - val_accuracy: 0.5885\n",
      "Epoch 185/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6217 - accuracy: 0.6460 - val_loss: 0.5769 - val_accuracy: 0.6955\n",
      "Epoch 186/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.7203 - val_loss: 0.6083 - val_accuracy: 0.6667\n",
      "Epoch 187/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5570 - accuracy: 0.7307 - val_loss: 0.5797 - val_accuracy: 0.7037\n",
      "Epoch 188/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5567 - accuracy: 0.7410 - val_loss: 0.5855 - val_accuracy: 0.6955\n",
      "Epoch 189/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5622 - accuracy: 0.7172 - val_loss: 0.6000 - val_accuracy: 0.6667\n",
      "Epoch 190/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5660 - accuracy: 0.7007 - val_loss: 0.6603 - val_accuracy: 0.6214\n",
      "Epoch 191/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6048 - accuracy: 0.6687 - val_loss: 0.5766 - val_accuracy: 0.7037\n",
      "Epoch 192/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5556 - accuracy: 0.7255 - val_loss: 0.5703 - val_accuracy: 0.7160\n",
      "Epoch 193/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7410 - val_loss: 0.5845 - val_accuracy: 0.6955\n",
      "Epoch 194/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7399 - val_loss: 0.6050 - val_accuracy: 0.6626\n",
      "Epoch 195/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7399 - val_loss: 0.5663 - val_accuracy: 0.7037\n",
      "Epoch 196/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7554 - val_loss: 0.5647 - val_accuracy: 0.7037\n",
      "Epoch 197/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5678 - accuracy: 0.6914 - val_loss: 0.5647 - val_accuracy: 0.6955\n",
      "Epoch 198/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7451 - val_loss: 0.6014 - val_accuracy: 0.6708\n",
      "Epoch 199/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5934 - accuracy: 0.6367 - val_loss: 0.5836 - val_accuracy: 0.6584\n",
      "Epoch 200/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5586 - accuracy: 0.7038 - val_loss: 0.5826 - val_accuracy: 0.6955\n",
      "Epoch 201/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7368 - val_loss: 0.5652 - val_accuracy: 0.7037\n",
      "Epoch 202/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7430 - val_loss: 0.5596 - val_accuracy: 0.7284\n",
      "Epoch 203/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.6987 - val_loss: 0.6466 - val_accuracy: 0.6132\n",
      "Epoch 204/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5573 - accuracy: 0.7276 - val_loss: 0.6233 - val_accuracy: 0.6420\n",
      "Epoch 205/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.7110 - val_loss: 0.5709 - val_accuracy: 0.7119\n",
      "Epoch 206/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7482 - val_loss: 0.5678 - val_accuracy: 0.7078\n",
      "Epoch 207/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5660 - accuracy: 0.6976 - val_loss: 0.5740 - val_accuracy: 0.6996\n",
      "Epoch 208/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5315 - accuracy: 0.7585 - val_loss: 0.5542 - val_accuracy: 0.7119\n",
      "Epoch 209/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7461 - val_loss: 0.5954 - val_accuracy: 0.6379\n",
      "Epoch 210/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5297 - accuracy: 0.7626 - val_loss: 0.5714 - val_accuracy: 0.6955\n",
      "Epoch 211/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5321 - accuracy: 0.7420 - val_loss: 0.5774 - val_accuracy: 0.6872\n",
      "Epoch 212/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5225 - accuracy: 0.7668 - val_loss: 0.5541 - val_accuracy: 0.7366\n",
      "Epoch 213/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7038 - val_loss: 0.5502 - val_accuracy: 0.7037\n",
      "Epoch 214/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7472 - val_loss: 0.5484 - val_accuracy: 0.7037\n",
      "Epoch 215/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.5255 - accuracy: 0.7554 - val_loss: 0.5529 - val_accuracy: 0.7325\n",
      "Epoch 216/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7379 - val_loss: 0.5479 - val_accuracy: 0.7119\n",
      "Epoch 217/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.6925 - val_loss: 0.5950 - val_accuracy: 0.6790\n",
      "Epoch 218/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.7368 - val_loss: 0.5468 - val_accuracy: 0.7449\n",
      "Epoch 219/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5297 - accuracy: 0.7368 - val_loss: 0.5624 - val_accuracy: 0.6708\n",
      "Epoch 220/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5854 - accuracy: 0.6543 - val_loss: 0.5718 - val_accuracy: 0.6996\n",
      "Epoch 221/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7761 - val_loss: 0.5425 - val_accuracy: 0.7078\n",
      "Epoch 222/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5534 - accuracy: 0.7100 - val_loss: 0.5631 - val_accuracy: 0.6708\n",
      "Epoch 223/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5753 - accuracy: 0.6698 - val_loss: 0.6483 - val_accuracy: 0.6296\n",
      "Epoch 224/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7234 - val_loss: 0.5558 - val_accuracy: 0.7119\n",
      "Epoch 225/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5199 - accuracy: 0.7564 - val_loss: 0.5455 - val_accuracy: 0.7490\n",
      "Epoch 226/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5086 - accuracy: 0.7936 - val_loss: 0.5702 - val_accuracy: 0.7037\n",
      "Epoch 227/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5203 - accuracy: 0.7492 - val_loss: 0.5649 - val_accuracy: 0.7037\n",
      "Epoch 228/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7203 - val_loss: 0.5645 - val_accuracy: 0.6626\n",
      "Epoch 229/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.6904 - val_loss: 0.5643 - val_accuracy: 0.7037\n",
      "Epoch 230/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5089 - accuracy: 0.7771 - val_loss: 0.5918 - val_accuracy: 0.6667\n",
      "Epoch 231/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5200 - accuracy: 0.7410 - val_loss: 0.5331 - val_accuracy: 0.7531\n",
      "Epoch 232/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4987 - accuracy: 0.8029 - val_loss: 0.5465 - val_accuracy: 0.7366\n",
      "Epoch 233/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5034 - accuracy: 0.7853 - val_loss: 0.5407 - val_accuracy: 0.7284\n",
      "Epoch 234/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4958 - accuracy: 0.7864 - val_loss: 0.5309 - val_accuracy: 0.7490\n",
      "Epoch 235/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4991 - accuracy: 0.7781 - val_loss: 0.5506 - val_accuracy: 0.7037\n",
      "Epoch 236/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7214 - val_loss: 0.5689 - val_accuracy: 0.6502\n",
      "Epoch 237/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7131 - val_loss: 0.5641 - val_accuracy: 0.6955\n",
      "Epoch 238/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7678 - val_loss: 0.5858 - val_accuracy: 0.6749\n",
      "Epoch 239/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5189 - accuracy: 0.7368 - val_loss: 0.5245 - val_accuracy: 0.7366\n",
      "Epoch 240/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4891 - accuracy: 0.7895 - val_loss: 0.5235 - val_accuracy: 0.7531\n",
      "Epoch 241/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5102 - accuracy: 0.7595 - val_loss: 0.5484 - val_accuracy: 0.6749\n",
      "Epoch 242/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5232 - accuracy: 0.7286 - val_loss: 0.5912 - val_accuracy: 0.6708\n",
      "Epoch 243/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5263 - accuracy: 0.7038 - val_loss: 0.5202 - val_accuracy: 0.7490\n",
      "Epoch 244/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4857 - accuracy: 0.7998 - val_loss: 0.5268 - val_accuracy: 0.7202\n",
      "Epoch 245/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4930 - accuracy: 0.7864 - val_loss: 0.5200 - val_accuracy: 0.7531\n",
      "Epoch 246/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4866 - accuracy: 0.7884 - val_loss: 0.5506 - val_accuracy: 0.7119\n",
      "Epoch 247/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5017 - accuracy: 0.7626 - val_loss: 0.5443 - val_accuracy: 0.6790\n",
      "Epoch 248/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5117 - accuracy: 0.7296 - val_loss: 0.5213 - val_accuracy: 0.7695\n",
      "Epoch 249/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4864 - accuracy: 0.7926 - val_loss: 0.5089 - val_accuracy: 0.7613\n",
      "Epoch 250/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4790 - accuracy: 0.8029 - val_loss: 0.5656 - val_accuracy: 0.7037\n",
      "Epoch 251/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5254 - accuracy: 0.7203 - val_loss: 0.5907 - val_accuracy: 0.6420\n",
      "Epoch 252/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.6925 - val_loss: 0.5494 - val_accuracy: 0.7119\n",
      "Epoch 253/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4916 - accuracy: 0.7699 - val_loss: 0.5130 - val_accuracy: 0.7243\n",
      "Epoch 254/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4855 - accuracy: 0.7843 - val_loss: 0.5204 - val_accuracy: 0.7613\n",
      "Epoch 255/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4672 - accuracy: 0.8235 - val_loss: 0.5162 - val_accuracy: 0.7284\n",
      "Epoch 256/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4982 - accuracy: 0.7492 - val_loss: 0.5309 - val_accuracy: 0.7284\n",
      "Epoch 257/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4912 - accuracy: 0.7699 - val_loss: 0.5263 - val_accuracy: 0.6996\n",
      "Epoch 258/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4876 - accuracy: 0.7668 - val_loss: 0.5100 - val_accuracy: 0.7695\n",
      "Epoch 259/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4965 - accuracy: 0.7637 - val_loss: 0.4981 - val_accuracy: 0.7695\n",
      "Epoch 260/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4765 - accuracy: 0.7843 - val_loss: 0.5072 - val_accuracy: 0.7325\n",
      "Epoch 261/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4576 - accuracy: 0.8235 - val_loss: 0.5075 - val_accuracy: 0.7654\n",
      "Epoch 262/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.8204 - val_loss: 0.5114 - val_accuracy: 0.7654\n",
      "Epoch 263/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4558 - accuracy: 0.8266 - val_loss: 0.5121 - val_accuracy: 0.7490\n",
      "Epoch 264/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4572 - accuracy: 0.8050 - val_loss: 0.5552 - val_accuracy: 0.6996\n",
      "Epoch 265/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4615 - accuracy: 0.8008 - val_loss: 0.4926 - val_accuracy: 0.7449\n",
      "Epoch 266/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4464 - accuracy: 0.8390 - val_loss: 0.6005 - val_accuracy: 0.6708\n",
      "Epoch 267/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5526 - accuracy: 0.6863 - val_loss: 0.5298 - val_accuracy: 0.6955\n",
      "Epoch 268/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4743 - accuracy: 0.7957 - val_loss: 0.4857 - val_accuracy: 0.7819\n",
      "Epoch 269/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4548 - accuracy: 0.8204 - val_loss: 0.4826 - val_accuracy: 0.7778\n",
      "Epoch 270/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4416 - accuracy: 0.8338 - val_loss: 0.4967 - val_accuracy: 0.7407\n",
      "Epoch 271/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.7853 - val_loss: 0.4804 - val_accuracy: 0.7860\n",
      "Epoch 272/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7121 - val_loss: 0.6646 - val_accuracy: 0.6379\n",
      "Epoch 273/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5070 - accuracy: 0.7368 - val_loss: 0.4874 - val_accuracy: 0.7737\n",
      "Epoch 274/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4405 - accuracy: 0.8380 - val_loss: 0.5166 - val_accuracy: 0.7243\n",
      "Epoch 275/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4398 - accuracy: 0.8421 - val_loss: 0.4817 - val_accuracy: 0.7984\n",
      "Epoch 276/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4448 - accuracy: 0.8184 - val_loss: 0.4929 - val_accuracy: 0.7819\n",
      "Epoch 277/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4645 - accuracy: 0.7884 - val_loss: 0.5076 - val_accuracy: 0.7037\n",
      "Epoch 278/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5109 - accuracy: 0.7368 - val_loss: 0.4777 - val_accuracy: 0.7901\n",
      "Epoch 279/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4315 - accuracy: 0.8431 - val_loss: 0.4909 - val_accuracy: 0.7737\n",
      "Epoch 280/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4446 - accuracy: 0.8235 - val_loss: 0.4669 - val_accuracy: 0.7942\n",
      "Epoch 281/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4723 - accuracy: 0.7822 - val_loss: 0.5069 - val_accuracy: 0.6996\n",
      "Epoch 282/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4456 - accuracy: 0.7957 - val_loss: 0.4706 - val_accuracy: 0.7984\n",
      "Epoch 283/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4258 - accuracy: 0.8411 - val_loss: 0.4789 - val_accuracy: 0.7860\n",
      "Epoch 284/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.8029 - val_loss: 0.4750 - val_accuracy: 0.7531\n",
      "Epoch 285/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4827 - accuracy: 0.7564 - val_loss: 0.4747 - val_accuracy: 0.7984\n",
      "Epoch 286/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4439 - accuracy: 0.8070 - val_loss: 0.4600 - val_accuracy: 0.8066\n",
      "Epoch 287/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4491 - accuracy: 0.8070 - val_loss: 0.5667 - val_accuracy: 0.6996\n",
      "Epoch 288/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5284 - accuracy: 0.7079 - val_loss: 0.4876 - val_accuracy: 0.7531\n",
      "Epoch 289/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.4357 - accuracy: 0.8194 - val_loss: 0.4794 - val_accuracy: 0.7860\n",
      "Epoch 290/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4313 - accuracy: 0.8277 - val_loss: 0.4655 - val_accuracy: 0.7942\n",
      "Epoch 291/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4316 - accuracy: 0.8215 - val_loss: 0.4768 - val_accuracy: 0.7325\n",
      "Epoch 292/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4251 - accuracy: 0.8173 - val_loss: 0.4759 - val_accuracy: 0.7325\n",
      "Epoch 293/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4157 - accuracy: 0.8246 - val_loss: 0.4501 - val_accuracy: 0.7942\n",
      "Epoch 294/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4142 - accuracy: 0.8411 - val_loss: 0.4928 - val_accuracy: 0.7572\n",
      "Epoch 295/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4525 - accuracy: 0.7874 - val_loss: 0.4512 - val_accuracy: 0.7819\n",
      "Epoch 296/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4193 - accuracy: 0.8318 - val_loss: 0.4924 - val_accuracy: 0.7490\n",
      "Epoch 297/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4181 - accuracy: 0.8277 - val_loss: 0.4693 - val_accuracy: 0.7407\n",
      "Epoch 298/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4701 - accuracy: 0.7523 - val_loss: 0.4729 - val_accuracy: 0.7901\n",
      "Epoch 299/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4074 - accuracy: 0.8411 - val_loss: 0.4422 - val_accuracy: 0.8272\n",
      "Epoch 300/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8648 - val_loss: 0.4502 - val_accuracy: 0.8066\n",
      "Epoch 301/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3935 - accuracy: 0.8648 - val_loss: 0.4339 - val_accuracy: 0.8313\n",
      "Epoch 302/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5042 - accuracy: 0.7472 - val_loss: 0.6328 - val_accuracy: 0.6543\n",
      "Epoch 303/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4652 - accuracy: 0.7750 - val_loss: 0.4378 - val_accuracy: 0.8313\n",
      "Epoch 304/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3968 - accuracy: 0.8658 - val_loss: 0.4359 - val_accuracy: 0.7942\n",
      "Epoch 305/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3913 - accuracy: 0.8648 - val_loss: 0.4307 - val_accuracy: 0.8107\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8483 - val_loss: 0.4339 - val_accuracy: 0.8354\n",
      "Epoch 307/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4237 - accuracy: 0.8091 - val_loss: 0.5744 - val_accuracy: 0.6831\n",
      "Epoch 308/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7379 - val_loss: 0.4334 - val_accuracy: 0.8148\n",
      "Epoch 309/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3898 - accuracy: 0.8607 - val_loss: 0.4333 - val_accuracy: 0.7860\n",
      "Epoch 310/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4032 - accuracy: 0.8400 - val_loss: 0.4676 - val_accuracy: 0.7778\n",
      "Epoch 311/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8493 - val_loss: 0.4358 - val_accuracy: 0.8025\n",
      "Epoch 312/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3784 - accuracy: 0.8638 - val_loss: 0.4179 - val_accuracy: 0.8477\n",
      "Epoch 313/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3727 - accuracy: 0.8710 - val_loss: 0.4274 - val_accuracy: 0.8189\n",
      "Epoch 314/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4272 - accuracy: 0.8132 - val_loss: 0.4959 - val_accuracy: 0.6996\n",
      "Epoch 315/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5164 - accuracy: 0.6976 - val_loss: 0.4551 - val_accuracy: 0.8066\n",
      "Epoch 316/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3763 - accuracy: 0.8689 - val_loss: 0.4151 - val_accuracy: 0.8354\n",
      "Epoch 317/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3837 - accuracy: 0.8576 - val_loss: 0.4615 - val_accuracy: 0.7366\n",
      "Epoch 318/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4104 - accuracy: 0.8318 - val_loss: 0.4294 - val_accuracy: 0.8148\n",
      "Epoch 319/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8844 - val_loss: 0.4118 - val_accuracy: 0.8519\n",
      "Epoch 320/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3607 - accuracy: 0.8844 - val_loss: 0.4146 - val_accuracy: 0.8436\n",
      "Epoch 321/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3839 - accuracy: 0.8390 - val_loss: 0.4554 - val_accuracy: 0.7407\n",
      "Epoch 322/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4048 - accuracy: 0.8060 - val_loss: 0.4104 - val_accuracy: 0.8477\n",
      "Epoch 323/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3596 - accuracy: 0.8834 - val_loss: 0.4564 - val_accuracy: 0.7860\n",
      "Epoch 324/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8142 - val_loss: 0.4197 - val_accuracy: 0.7819\n",
      "Epoch 325/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3882 - accuracy: 0.8442 - val_loss: 0.4952 - val_accuracy: 0.7449\n",
      "Epoch 326/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5059 - accuracy: 0.7079 - val_loss: 0.4401 - val_accuracy: 0.7778\n",
      "Epoch 327/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3662 - accuracy: 0.8720 - val_loss: 0.4079 - val_accuracy: 0.7942\n",
      "Epoch 328/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3795 - accuracy: 0.8421 - val_loss: 0.4566 - val_accuracy: 0.7860\n",
      "Epoch 329/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3740 - accuracy: 0.8576 - val_loss: 0.4070 - val_accuracy: 0.8025\n",
      "Epoch 330/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8235 - val_loss: 0.4632 - val_accuracy: 0.7860\n",
      "Epoch 331/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3637 - accuracy: 0.8617 - val_loss: 0.3888 - val_accuracy: 0.8683\n",
      "Epoch 332/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3424 - accuracy: 0.9020 - val_loss: 0.4104 - val_accuracy: 0.8354\n",
      "Epoch 333/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3685 - accuracy: 0.8545 - val_loss: 0.5063 - val_accuracy: 0.7243\n",
      "Epoch 334/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.7719 - val_loss: 0.4391 - val_accuracy: 0.7613\n",
      "Epoch 335/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3531 - accuracy: 0.8813 - val_loss: 0.3934 - val_accuracy: 0.8601\n",
      "Epoch 336/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3407 - accuracy: 0.8916 - val_loss: 0.3825 - val_accuracy: 0.8724\n",
      "Epoch 337/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.9030 - val_loss: 0.3782 - val_accuracy: 0.8724\n",
      "Epoch 338/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3296 - accuracy: 0.9030 - val_loss: 0.4066 - val_accuracy: 0.8354\n",
      "Epoch 339/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3866 - accuracy: 0.8277 - val_loss: 0.5566 - val_accuracy: 0.6872\n",
      "Epoch 340/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5135 - accuracy: 0.7327 - val_loss: 0.3895 - val_accuracy: 0.8642\n",
      "Epoch 341/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.8937 - val_loss: 0.3769 - val_accuracy: 0.8601\n",
      "Epoch 342/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3388 - accuracy: 0.8947 - val_loss: 0.4342 - val_accuracy: 0.7942\n",
      "Epoch 343/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8885 - val_loss: 0.3722 - val_accuracy: 0.8724\n",
      "Epoch 344/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3371 - accuracy: 0.8834 - val_loss: 0.3889 - val_accuracy: 0.8025\n",
      "Epoch 345/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4224 - accuracy: 0.7761 - val_loss: 0.4548 - val_accuracy: 0.7778\n",
      "Epoch 346/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3270 - accuracy: 0.8896 - val_loss: 0.3676 - val_accuracy: 0.8683\n",
      "Epoch 347/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8865 - val_loss: 0.3828 - val_accuracy: 0.8601\n",
      "Epoch 348/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.8731 - val_loss: 0.4014 - val_accuracy: 0.7778\n",
      "Epoch 349/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4189 - accuracy: 0.7946 - val_loss: 0.4899 - val_accuracy: 0.7490\n",
      "Epoch 350/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4051 - accuracy: 0.8111 - val_loss: 0.3661 - val_accuracy: 0.8519\n",
      "Epoch 351/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3165 - accuracy: 0.9123 - val_loss: 0.3819 - val_accuracy: 0.8765\n",
      "Epoch 352/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3252 - accuracy: 0.8978 - val_loss: 0.3572 - val_accuracy: 0.8601\n",
      "Epoch 353/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3590 - accuracy: 0.8524 - val_loss: 0.5045 - val_accuracy: 0.7243\n",
      "Epoch 354/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3722 - accuracy: 0.8369 - val_loss: 0.3602 - val_accuracy: 0.8477\n",
      "Epoch 355/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8617 - val_loss: 0.3837 - val_accuracy: 0.8601\n",
      "Epoch 356/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3144 - accuracy: 0.8927 - val_loss: 0.3714 - val_accuracy: 0.8189\n",
      "Epoch 357/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3375 - accuracy: 0.8617 - val_loss: 0.3868 - val_accuracy: 0.8477\n",
      "Epoch 358/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3682 - accuracy: 0.8411 - val_loss: 0.3642 - val_accuracy: 0.8189\n",
      "Epoch 359/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3110 - accuracy: 0.8999 - val_loss: 0.3985 - val_accuracy: 0.8272\n",
      "Epoch 360/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3146 - accuracy: 0.8896 - val_loss: 0.3942 - val_accuracy: 0.7778\n",
      "Epoch 361/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4173 - accuracy: 0.7822 - val_loss: 0.4016 - val_accuracy: 0.8313\n",
      "Epoch 362/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3071 - accuracy: 0.9082 - val_loss: 0.3380 - val_accuracy: 0.8930\n",
      "Epoch 363/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3043 - accuracy: 0.9020 - val_loss: 0.3513 - val_accuracy: 0.8765\n",
      "Epoch 364/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3063 - accuracy: 0.8958 - val_loss: 0.3477 - val_accuracy: 0.8436\n",
      "Epoch 365/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3134 - accuracy: 0.8834 - val_loss: 0.3520 - val_accuracy: 0.8889\n",
      "Epoch 366/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2855 - accuracy: 0.9154 - val_loss: 0.3692 - val_accuracy: 0.8519\n",
      "Epoch 367/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3204 - accuracy: 0.8824 - val_loss: 0.3388 - val_accuracy: 0.8601\n",
      "Epoch 368/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3002 - accuracy: 0.8927 - val_loss: 0.4198 - val_accuracy: 0.8025\n",
      "Epoch 369/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3797 - accuracy: 0.8256 - val_loss: 0.4777 - val_accuracy: 0.7366\n",
      "Epoch 370/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8080 - val_loss: 0.3893 - val_accuracy: 0.8354\n",
      "Epoch 371/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3168 - accuracy: 0.8793 - val_loss: 0.3362 - val_accuracy: 0.8765\n",
      "Epoch 372/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2845 - accuracy: 0.9247 - val_loss: 0.3216 - val_accuracy: 0.8930\n",
      "Epoch 373/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2783 - accuracy: 0.9309 - val_loss: 0.3187 - val_accuracy: 0.8930\n",
      "Epoch 374/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2695 - accuracy: 0.9319 - val_loss: 0.3179 - val_accuracy: 0.8848\n",
      "Epoch 375/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2891 - accuracy: 0.9051 - val_loss: 0.4876 - val_accuracy: 0.7160\n",
      "Epoch 376/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4585 - accuracy: 0.7585 - val_loss: 0.3655 - val_accuracy: 0.8560\n",
      "Epoch 377/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2879 - accuracy: 0.9154 - val_loss: 0.3184 - val_accuracy: 0.8889\n",
      "Epoch 378/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3113 - accuracy: 0.8927 - val_loss: 0.4257 - val_accuracy: 0.7572\n",
      "Epoch 379/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3949 - accuracy: 0.8173 - val_loss: 0.3264 - val_accuracy: 0.8889\n",
      "Epoch 380/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2684 - accuracy: 0.9401 - val_loss: 0.3125 - val_accuracy: 0.8930\n",
      "Epoch 381/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2667 - accuracy: 0.9298 - val_loss: 0.3081 - val_accuracy: 0.9053\n",
      "Epoch 382/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2598 - accuracy: 0.9412 - val_loss: 0.3046 - val_accuracy: 0.8930\n",
      "Epoch 383/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2682 - accuracy: 0.9267 - val_loss: 0.3207 - val_accuracy: 0.8765\n",
      "Epoch 384/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3096 - accuracy: 0.8834 - val_loss: 0.5118 - val_accuracy: 0.7119\n",
      "Epoch 385/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4478 - accuracy: 0.7740 - val_loss: 0.3403 - val_accuracy: 0.8477\n",
      "Epoch 386/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2827 - accuracy: 0.9102 - val_loss: 0.3277 - val_accuracy: 0.8971\n",
      "Epoch 387/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2625 - accuracy: 0.9340 - val_loss: 0.3445 - val_accuracy: 0.8807\n",
      "Epoch 388/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2543 - accuracy: 0.9329 - val_loss: 0.2946 - val_accuracy: 0.8930\n",
      "Epoch 389/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2752 - accuracy: 0.9020 - val_loss: 0.3013 - val_accuracy: 0.9053\n",
      "Epoch 390/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2560 - accuracy: 0.9298 - val_loss: 0.3619 - val_accuracy: 0.8477\n",
      "Epoch 391/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3513 - accuracy: 0.8483 - val_loss: 0.4738 - val_accuracy: 0.7490\n",
      "Epoch 392/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3579 - accuracy: 0.8318 - val_loss: 0.3224 - val_accuracy: 0.9012\n",
      "Epoch 393/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2536 - accuracy: 0.9309 - val_loss: 0.3337 - val_accuracy: 0.8848\n",
      "Epoch 394/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2682 - accuracy: 0.9123 - val_loss: 0.2971 - val_accuracy: 0.8930\n",
      "Epoch 395/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2669 - accuracy: 0.9185 - val_loss: 0.3348 - val_accuracy: 0.8395\n",
      "Epoch 396/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2623 - accuracy: 0.9102 - val_loss: 0.3067 - val_accuracy: 0.8930\n",
      "Epoch 397/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2537 - accuracy: 0.9298 - val_loss: 0.3936 - val_accuracy: 0.7654\n",
      "Epoch 398/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.8896 - val_loss: 0.2830 - val_accuracy: 0.9012\n",
      "Epoch 399/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2323 - accuracy: 0.9484 - val_loss: 0.2831 - val_accuracy: 0.9053\n",
      "Epoch 400/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2287 - accuracy: 0.9515 - val_loss: 0.2756 - val_accuracy: 0.8971\n",
      "Epoch 401/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3099 - accuracy: 0.8710 - val_loss: 0.7751 - val_accuracy: 0.6255\n",
      "Epoch 402/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4731 - accuracy: 0.7585 - val_loss: 0.2985 - val_accuracy: 0.9012\n",
      "Epoch 403/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2394 - accuracy: 0.9453 - val_loss: 0.2795 - val_accuracy: 0.9053\n",
      "Epoch 404/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2311 - accuracy: 0.9474 - val_loss: 0.2747 - val_accuracy: 0.9095\n",
      "Epoch 405/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2408 - accuracy: 0.9309 - val_loss: 0.3440 - val_accuracy: 0.8189\n",
      "Epoch 406/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4502 - accuracy: 0.7564 - val_loss: 0.3178 - val_accuracy: 0.8930\n",
      "Epoch 407/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2354 - accuracy: 0.9474 - val_loss: 0.2743 - val_accuracy: 0.9218\n",
      "Epoch 408/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2481 - accuracy: 0.9412 - val_loss: 0.2749 - val_accuracy: 0.9136\n",
      "Epoch 409/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2347 - accuracy: 0.9401 - val_loss: 0.3343 - val_accuracy: 0.8765\n",
      "Epoch 410/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2326 - accuracy: 0.9360 - val_loss: 0.2766 - val_accuracy: 0.9012\n",
      "Epoch 411/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2173 - accuracy: 0.9515 - val_loss: 0.2813 - val_accuracy: 0.9053\n",
      "Epoch 412/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2361 - accuracy: 0.9360 - val_loss: 0.2652 - val_accuracy: 0.9177\n",
      "Epoch 413/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2252 - accuracy: 0.9463 - val_loss: 0.3108 - val_accuracy: 0.8807\n",
      "Epoch 414/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2845 - accuracy: 0.8762 - val_loss: 0.4218 - val_accuracy: 0.7737\n",
      "Epoch 415/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3202 - accuracy: 0.8442 - val_loss: 0.2837 - val_accuracy: 0.9136\n",
      "Epoch 416/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2220 - accuracy: 0.9505 - val_loss: 0.2607 - val_accuracy: 0.9177\n",
      "Epoch 417/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2173 - accuracy: 0.9474 - val_loss: 0.2632 - val_accuracy: 0.9053\n",
      "Epoch 418/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2049 - accuracy: 0.9577 - val_loss: 0.2511 - val_accuracy: 0.9259\n",
      "Epoch 419/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2547 - accuracy: 0.9216 - val_loss: 0.5312 - val_accuracy: 0.7119\n",
      "Epoch 420/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3743 - accuracy: 0.8163 - val_loss: 0.2592 - val_accuracy: 0.9218\n",
      "Epoch 421/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2095 - accuracy: 0.9546 - val_loss: 0.2680 - val_accuracy: 0.9136\n",
      "Epoch 422/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2082 - accuracy: 0.9484 - val_loss: 0.2588 - val_accuracy: 0.9095\n",
      "Epoch 423/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2043 - accuracy: 0.9536 - val_loss: 0.2482 - val_accuracy: 0.9136\n",
      "Epoch 424/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2009 - accuracy: 0.9546 - val_loss: 0.2410 - val_accuracy: 0.9259\n",
      "Epoch 425/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1946 - accuracy: 0.9567 - val_loss: 0.2397 - val_accuracy: 0.9177\n",
      "Epoch 426/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2889 - accuracy: 0.8772 - val_loss: 0.5089 - val_accuracy: 0.7284\n",
      "Epoch 427/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5026 - accuracy: 0.7368 - val_loss: 0.2709 - val_accuracy: 0.9218\n",
      "Epoch 428/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2179 - accuracy: 0.9453 - val_loss: 0.2471 - val_accuracy: 0.9300\n",
      "Epoch 429/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2087 - accuracy: 0.9484 - val_loss: 0.2417 - val_accuracy: 0.9342\n",
      "Epoch 430/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1991 - accuracy: 0.9546 - val_loss: 0.2415 - val_accuracy: 0.9259\n",
      "Epoch 431/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1935 - accuracy: 0.9577 - val_loss: 0.2520 - val_accuracy: 0.9218\n",
      "Epoch 432/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1885 - accuracy: 0.9577 - val_loss: 0.2415 - val_accuracy: 0.9177\n",
      "Epoch 433/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1853 - accuracy: 0.9628 - val_loss: 0.2366 - val_accuracy: 0.9136\n",
      "Epoch 434/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2493 - accuracy: 0.9061 - val_loss: 0.3856 - val_accuracy: 0.7984\n",
      "Epoch 435/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5112 - accuracy: 0.7307 - val_loss: 0.3576 - val_accuracy: 0.8395\n",
      "Epoch 436/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2241 - accuracy: 0.9350 - val_loss: 0.2787 - val_accuracy: 0.9095\n",
      "Epoch 437/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1960 - accuracy: 0.9577 - val_loss: 0.2436 - val_accuracy: 0.9218\n",
      "Epoch 438/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1936 - accuracy: 0.9567 - val_loss: 0.2754 - val_accuracy: 0.9053\n",
      "Epoch 439/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1974 - accuracy: 0.9463 - val_loss: 0.2435 - val_accuracy: 0.9177\n",
      "Epoch 440/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9567 - val_loss: 0.2253 - val_accuracy: 0.9259\n",
      "Epoch 441/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1806 - accuracy: 0.9649 - val_loss: 0.2304 - val_accuracy: 0.9259\n",
      "Epoch 442/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2024 - accuracy: 0.9432 - val_loss: 0.3605 - val_accuracy: 0.7942\n",
      "Epoch 443/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3625 - accuracy: 0.8163 - val_loss: 0.2803 - val_accuracy: 0.8930\n",
      "Epoch 444/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2014 - accuracy: 0.9515 - val_loss: 0.2286 - val_accuracy: 0.9342\n",
      "Epoch 445/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1775 - accuracy: 0.9628 - val_loss: 0.2632 - val_accuracy: 0.9053\n",
      "Epoch 446/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1749 - accuracy: 0.9649 - val_loss: 0.2238 - val_accuracy: 0.9342\n",
      "Epoch 447/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1853 - accuracy: 0.9525 - val_loss: 0.2458 - val_accuracy: 0.9136\n",
      "Epoch 448/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2250 - accuracy: 0.9216 - val_loss: 0.2879 - val_accuracy: 0.8930\n",
      "Epoch 449/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2396 - accuracy: 0.9092 - val_loss: 0.2441 - val_accuracy: 0.9300\n",
      "Epoch 450/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1821 - accuracy: 0.9598 - val_loss: 0.2438 - val_accuracy: 0.9053\n",
      "Epoch 451/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1738 - accuracy: 0.9628 - val_loss: 0.2445 - val_accuracy: 0.9095\n",
      "Epoch 452/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.9505 - val_loss: 0.2305 - val_accuracy: 0.9300\n",
      "Epoch 453/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2033 - accuracy: 0.9412 - val_loss: 0.4508 - val_accuracy: 0.7778\n",
      "Epoch 454/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3909 - accuracy: 0.7905 - val_loss: 0.2582 - val_accuracy: 0.8971\n",
      "Epoch 455/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2126 - accuracy: 0.9309 - val_loss: 0.2426 - val_accuracy: 0.9053\n",
      "Epoch 456/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1695 - accuracy: 0.9649 - val_loss: 0.2109 - val_accuracy: 0.9300\n",
      "Epoch 457/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1685 - accuracy: 0.9639 - val_loss: 0.2068 - val_accuracy: 0.9300\n",
      "Epoch 458/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1652 - accuracy: 0.9670 - val_loss: 0.2341 - val_accuracy: 0.9136\n",
      "Epoch 459/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1657 - accuracy: 0.9608 - val_loss: 0.2014 - val_accuracy: 0.9383\n",
      "Epoch 460/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2574 - accuracy: 0.8875 - val_loss: 0.4504 - val_accuracy: 0.7778\n",
      "Epoch 461/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2864 - accuracy: 0.8617 - val_loss: 0.2348 - val_accuracy: 0.9218\n",
      "Epoch 462/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1693 - accuracy: 0.9639 - val_loss: 0.2012 - val_accuracy: 0.9424\n",
      "Epoch 463/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1694 - accuracy: 0.9587 - val_loss: 0.2490 - val_accuracy: 0.9095\n",
      "Epoch 464/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1718 - accuracy: 0.9587 - val_loss: 0.2020 - val_accuracy: 0.9342\n",
      "Epoch 465/500\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1537 - accuracy: 0.9690 - val_loss: 0.1949 - val_accuracy: 0.9424\n",
      "Epoch 466/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1511 - accuracy: 0.9680 - val_loss: 0.1924 - val_accuracy: 0.9383\n",
      "Epoch 467/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2727 - accuracy: 0.8927 - val_loss: 0.6920 - val_accuracy: 0.6584\n",
      "Epoch 468/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3886 - accuracy: 0.8019 - val_loss: 0.2129 - val_accuracy: 0.9465\n",
      "Epoch 469/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1611 - accuracy: 0.9701 - val_loss: 0.2050 - val_accuracy: 0.9300\n",
      "Epoch 470/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1527 - accuracy: 0.9711 - val_loss: 0.1926 - val_accuracy: 0.9424\n",
      "Epoch 471/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1811 - accuracy: 0.9484 - val_loss: 0.2801 - val_accuracy: 0.8889\n",
      "Epoch 472/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1807 - accuracy: 0.9494 - val_loss: 0.1909 - val_accuracy: 0.9547\n",
      "Epoch 473/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1477 - accuracy: 0.9721 - val_loss: 0.1897 - val_accuracy: 0.9465\n",
      "Epoch 474/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1435 - accuracy: 0.9711 - val_loss: 0.1974 - val_accuracy: 0.9342\n",
      "Epoch 475/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1412 - accuracy: 0.9711 - val_loss: 0.1941 - val_accuracy: 0.9342\n",
      "Epoch 476/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1572 - accuracy: 0.9618 - val_loss: 0.1874 - val_accuracy: 0.9547\n",
      "Epoch 477/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1462 - accuracy: 0.9670 - val_loss: 0.2269 - val_accuracy: 0.9136\n",
      "Epoch 478/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2443 - accuracy: 0.9061 - val_loss: 0.4394 - val_accuracy: 0.7531\n",
      "Epoch 479/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2761 - accuracy: 0.8813 - val_loss: 0.2492 - val_accuracy: 0.9012\n",
      "Epoch 480/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1610 - accuracy: 0.9649 - val_loss: 0.1878 - val_accuracy: 0.9465\n",
      "Epoch 481/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1442 - accuracy: 0.9690 - val_loss: 0.1817 - val_accuracy: 0.9506\n",
      "Epoch 482/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1368 - accuracy: 0.9742 - val_loss: 0.1851 - val_accuracy: 0.9383\n",
      "Epoch 483/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1344 - accuracy: 0.9721 - val_loss: 0.1773 - val_accuracy: 0.9465\n",
      "Epoch 484/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1313 - accuracy: 0.9732 - val_loss: 0.1820 - val_accuracy: 0.9424\n",
      "Epoch 485/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1309 - accuracy: 0.9732 - val_loss: 0.1822 - val_accuracy: 0.9547\n",
      "Epoch 486/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1719 - accuracy: 0.9494 - val_loss: 0.3068 - val_accuracy: 0.8642\n",
      "Epoch 487/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4308 - accuracy: 0.7988 - val_loss: 0.7108 - val_accuracy: 0.6543\n",
      "Epoch 488/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2796 - accuracy: 0.8875 - val_loss: 0.1970 - val_accuracy: 0.9424\n",
      "Epoch 489/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1448 - accuracy: 0.9680 - val_loss: 0.1927 - val_accuracy: 0.9342\n",
      "Epoch 490/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1386 - accuracy: 0.9680 - val_loss: 0.1776 - val_accuracy: 0.9506\n",
      "Epoch 491/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1350 - accuracy: 0.9732 - val_loss: 0.1867 - val_accuracy: 0.9383\n",
      "Epoch 492/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1333 - accuracy: 0.9721 - val_loss: 0.1929 - val_accuracy: 0.9342\n",
      "Epoch 493/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1835 - accuracy: 0.9505 - val_loss: 0.2485 - val_accuracy: 0.9053\n",
      "Epoch 494/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1547 - accuracy: 0.9618 - val_loss: 0.1839 - val_accuracy: 0.9506\n",
      "Epoch 495/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1358 - accuracy: 0.9752 - val_loss: 0.2152 - val_accuracy: 0.9136\n",
      "Epoch 496/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1276 - accuracy: 0.9721 - val_loss: 0.1716 - val_accuracy: 0.9506\n",
      "Epoch 497/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1348 - accuracy: 0.9721 - val_loss: 0.1916 - val_accuracy: 0.9342\n",
      "Epoch 498/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1385 - accuracy: 0.9732 - val_loss: 0.1653 - val_accuracy: 0.9588\n",
      "Epoch 499/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1295 - accuracy: 0.9763 - val_loss: 0.2261 - val_accuracy: 0.9136\n",
      "Epoch 500/500\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1292 - accuracy: 0.9721 - val_loss: 0.1678 - val_accuracy: 0.9506\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sleepy       0.88      0.96      0.92       152\n",
      "    vigilant       0.96      0.87      0.91       151\n",
      "\n",
      "    accuracy                           0.91       303\n",
      "   macro avg       0.92      0.91      0.91       303\n",
      "weighted avg       0.92      0.91      0.91       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 30 23:26:24 2019\n",
    "\n",
    "@author: Programmer\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 23 23:57:53 2019\n",
    "\n",
    "@author: Programmer\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from lenet import LeNet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "datatrain = []\n",
    "labelstrain = []\n",
    "itrain=0\n",
    "jtrain=0\n",
    "\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "itest=0\n",
    "jtest=0\n",
    "\n",
    "# read through the sleepy images and append the image data and labels\n",
    "directory = \"./sleepy/\"\n",
    "for imagePath in os.listdir(directory):\n",
    "    if imagePath.endswith(\"_30.jpg\"): \n",
    "\n",
    "        image = cv2.imread(directory + imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        #image = imutils.resize(image, width=28)\n",
    "        #image = imutils.resize(image, height=28)\n",
    "        #cv2.resize(image,(28,28))\n",
    "        image = cv2.resize(image, (28, 28), interpolation = cv2.INTER_AREA)\n",
    "        print (image.shape)\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        label.append(\"sleepy\")\n",
    "        itrain+=1\n",
    "        print(\"i\",itrain)\n",
    "\n",
    "# read through the no sleepy images and append the image data and labels\n",
    "directory = \"./vigilant/\"\n",
    "for imagePath in os.listdir(directory):\n",
    "    if imagePath.endswith(\"_30.jpg\"): \n",
    "        image = cv2.imread(directory  + imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        #image = imutils.resize(image, width=28)\n",
    "        image = cv2.resize(image, (28, 28), interpolation = cv2.INTER_AREA)\n",
    "        print (image.shape)\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        label.append(\"vigilant\")\n",
    "        jtrain+=1\n",
    "        print(\"j\",jtrain)\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "#labelstrain = np.array(label)\n",
    "label=np.array(label)\n",
    "\n",
    "le = LabelEncoder().fit(label)\n",
    "label = np_utils.to_categorical(le.transform(label), 2)\n",
    "\n",
    "classTotals = label.sum(axis=0)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(data,label)\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, random_state=0)\n",
    "myfol=0\n",
    "\n",
    "for trainindex, testindex in mskf.split(data,label):\n",
    "    trainX,testX=data[trainindex],data[testindex]\n",
    "    trainY,testY=label[trainindex],label[testindex] \n",
    "    myfol = myfol+1\n",
    "    (trainX, ValidX, trainY, ValidY) = train_test_split(trainX, trainY, test_size=0.20, random_state=1)\n",
    "    \n",
    "\n",
    "\n",
    "#classWeight = classTotals.max() / classTotals\n",
    "#  using 80% for training and 20% for testing\n",
    "#(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, random_state=1)\n",
    "# initialize the model\n",
    "    print(\"[INFO] compiling model fold\"+str(myfol)+'.....')\n",
    "    model = LeNet.build(width=28, height=28, depth=1, classes=2)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "# compile the model\n",
    "    print(\"[INFO] training network...\")\n",
    "    print(trainX.shape, testX.shape, trainY.shape, testY.shape)\n",
    "    H = model.fit(trainX, trainY, validation_data=(ValidX, ValidY), batch_size=200, epochs=500, verbose=1)\n",
    "    \n",
    "\n",
    "    model.save_weights('my_model_weights'+str(myfol)+'.h5')\n",
    "# evaluate the network\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    predictions = model.predict(testX, batch_size=64)\n",
    "    print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=le.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/79/9ba64c8c07b07b8b45d80725b2ebd7b7884701c1da34f70d4749f7b45f9a/iterative_stratification-0.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /home/reza/anaconda3/lib/python3.7/site-packages (from iterative-stratification) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/reza/anaconda3/lib/python3.7/site-packages (from iterative-stratification) (0.21.3)\n",
      "Requirement already satisfied: numpy in /home/reza/anaconda3/lib/python3.7/site-packages (from iterative-stratification) (1.17.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/reza/anaconda3/lib/python3.7/site-packages (from scikit-learn->iterative-stratification) (0.13.2)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
